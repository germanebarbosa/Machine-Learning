{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 08 RNN & NLP - Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedagogy\n",
    "\n",
    "This notebook serves as an instruction for implementing RNNs using PyTorch for NLP tasks.\n",
    "\n",
    "Please use this notebook as a reference and guide to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-configure\n",
    "\n",
    "In this notebook, we will use the following new libraries:\n",
    "- `nltk`: the Natural Language Toolkit that provides most of the basic tools you need for NLP\n",
    "\n",
    "Please install the new libraries before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/germanesteban/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Data Analitics/Machine Learning/.venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/germanesteban/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Data Analitics/Machine Learning/.venv/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/germanesteban/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Data Analitics/Machine Learning/.venv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/germanesteban/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Data Analitics/Machine Learning/.venv/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/germanesteban/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Data Analitics/Machine Learning/.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pgGythbg82Pj"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# for padding a list of variable length tensors to equal length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# for packing a tensor containing padded sequences of variable length\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import nltk\n",
    "# for removing stop words like 'the', 'and', etc\n",
    "# stop words don't provide useful information\n",
    "from nltk.corpus import stopwords\n",
    "# for tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# for counting the number of unique tokens\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MP_xAP-f8pRL"
   },
   "outputs": [],
   "source": [
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDEQnYfG8-1M",
    "outputId": "0e0af0e2-6117-45f4-aaec-31a2c2819193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for computation\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    "In this notebook, we will build a text classification model using RNN, more specifically, LSTM.\n",
    "\n",
    "The problem to be solved is to classify different news into one of the 4 pre-defined classes:\n",
    "\n",
    "|Class|Example news|\n",
    "|-|-|\n",
    "|World|France marks the 'other D-Day' Two days of celebrations to honour the Allied veterans who liberated southern France near a climax...|\n",
    "|Sports|Galaxy, Crew Play to 0-0 Tie (AP) AP - Kevin Hartman made seven saves for Los Angeles, and Jon Busch had two saves for Columbus as the Galaxy and Crew played to a 0-0 tie Saturday night...|\n",
    "|Business|Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again...|\n",
    "|Sci/Tech|Apple to open second Japanese retail store this month (MacCentral) MacCentral - Apple Computer Inc. will open its second Japanese retail store later this month in the western Japanese city of Osaka, it said Thursday...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Build the data pipeline\n",
    "\n",
    "We will use the [AG News Dataset](http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html) which is a collection of news articles.\n",
    "\n",
    "Each news article is classified into one of the 4 pre-defined classes: world, sports, business, and sci/tech.\n",
    "\n",
    "In this step, we need to:\n",
    "- Load the dataset from the `ag_news_dataset.csv` file\n",
    "- Pre-process the text\n",
    "    - Tokenization\n",
    "    - Remove stop words (like 'and', 'the') that don't provide useful information\n",
    "    - Remove non-alphabetic tokens (optional)\n",
    "- Create the vocabulary\n",
    "- Encode the tokens\n",
    "- Create the Dataset and the Dataloader\n",
    "    - Pad the tensors with variable lengths to equal length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1 Load the dataset\n",
    "\n",
    "You can download the `ag_news_dataset.csv` file from the Learn platform.\n",
    "\n",
    "If you are using Google Colab, you need to upload this file to Colab manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('ag_news_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2 Pre-process the text\n",
    "\n",
    "- Tokenization\n",
    "- Remove stop words\n",
    "- Remove non-alphabetic tokens (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "wuhOvBc_9bv0",
    "outputId": "8490d426-60d6-438d-ef04-60d791e04ae5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/germanesteban/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/germanesteban/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/germanesteban/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "      <td>[wall, bears, claw, back, black, reuters, reut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[carlyle, looks, toward, commercial, aerospace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "      <td>[oil, economy, cloud, stocks, outlook, reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "      <td>[iraq, halts, oil, exports, main, southern, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "      <td>[oil, prices, soar, record, posing, new, menac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2   \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2   \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2   \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2   \n",
       "4  Oil prices soar to all-time record, posing new...      2   \n",
       "\n",
       "                                              tokens  \n",
       "0  [wall, bears, claw, back, black, reuters, reut...  \n",
       "1  [carlyle, looks, toward, commercial, aerospace...  \n",
       "2  [oil, economy, cloud, stocks, outlook, reuters...  \n",
       "3  [iraq, halts, oil, exports, main, southern, pi...  \n",
       "4  [oil, prices, soar, record, posing, new, menac...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# set the stop words to the English mode\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# define a function for pre-processing\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords and non-alphabetic tokens\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# apply preprocessing to the 'text' column\n",
    "df['tokens'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# show the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3 Create the vocabulary\n",
    "\n",
    "We first count the frequency of all unique tokens in the dataset.\n",
    "\n",
    "Then we select 20,000 most common tokens and put them into the vocabulary.\n",
    "\n",
    "You can increase the vocabulary size by including more unique tokens.\n",
    "\n",
    "Simply adding all unique tokens to the vocabulary is not recommended because you lose control over the size of the vocabulary.\n",
    "\n",
    "We also add two special tokens to the vocabulary:\n",
    "- `<PAD>`:\n",
    "    - Represent the padding tokens added at the end of the original sequence\n",
    "    - It's common to pad sequences of different lengths to the same length.\n",
    "- `<UNK>`:\n",
    "    - Represent the unknown tokens\n",
    "    - It might be the less frequent token that is not included in the vocabulary\n",
    "    - Or the unknown token from the unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipoMDiAz9pnJ",
    "outputId": "e9e4f710-cad2-41f4-a6cc-267986f51fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the vocabulary: 61165\n",
      "The number of most common tokens preserved: 20000\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "all_tokens = [token for tokens in df['tokens'] for token in tokens]\n",
    "token_counts = Counter(all_tokens)\n",
    "print('The number of unique tokens in the vocabulary:', len(token_counts))\n",
    "\n",
    "# keep the most common token\n",
    "vocab_size = 20000\n",
    "common_tokens = token_counts.most_common(vocab_size - 2)  # Reserve two spots for PAD and UNK tokens\n",
    "print('The number of most common tokens preserved:', vocab_size)\n",
    "\n",
    "# create token to index mapping\n",
    "token_to_idx = {token: idx+2 for idx, (token, _) in enumerate(common_tokens)}\n",
    "# '<PAD>' is used to represent padding tokens at the end of text\n",
    "token_to_idx['<PAD>'] = 0\n",
    "# '<UNK>' is used to represent unknown tokens that are not included in the vocabulary\n",
    "token_to_idx['<UNK>'] = 1\n",
    "\n",
    "# create index to token mapping\n",
    "idx_to_token = {idx: token for token, idx in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4 Encode the tokens\n",
    "\n",
    "- Convert a sequence of tokens to a sequence of numbers\n",
    "- Each unique token is assigned with a unique number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ZdepkdPb-et9",
    "outputId": "6c966318-9770-408c-af83-2cf49ad31ca8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoded_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "      <td>[wall, bears, claw, back, black, reuters, reut...</td>\n",
       "      <td>[313, 1399, 13796, 52, 705, 4, 4, 313, 264, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[carlyle, looks, toward, commercial, aerospace...</td>\n",
       "      <td>[14689, 908, 692, 1120, 3954, 4, 4, 759, 643, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "      <td>[oil, economy, cloud, stocks, outlook, reuters...</td>\n",
       "      <td>[17, 245, 4140, 84, 594, 4, 4, 2153, 335, 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "      <td>[iraq, halts, oil, exports, main, southern, pi...</td>\n",
       "      <td>[22, 6703, 17, 1550, 749, 402, 2545, 4, 4, 677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "      <td>[oil, prices, soar, record, posing, new, menac...</td>\n",
       "      <td>[17, 35, 3955, 75, 6983, 2, 11416, 8, 245, 45,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2   \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2   \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2   \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2   \n",
       "4  Oil prices soar to all-time record, posing new...      2   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [wall, bears, claw, back, black, reuters, reut...   \n",
       "1  [carlyle, looks, toward, commercial, aerospace...   \n",
       "2  [oil, economy, cloud, stocks, outlook, reuters...   \n",
       "3  [iraq, halts, oil, exports, main, southern, pi...   \n",
       "4  [oil, prices, soar, record, posing, new, menac...   \n",
       "\n",
       "                                      encoded_tokens  \n",
       "0  [313, 1399, 13796, 52, 705, 4, 4, 313, 264, 36...  \n",
       "1  [14689, 908, 692, 1120, 3954, 4, 4, 759, 643, ...  \n",
       "2  [17, 245, 4140, 84, 594, 4, 4, 2153, 335, 35, ...  \n",
       "3  [22, 6703, 17, 1550, 749, 402, 2545, 4, 4, 677...  \n",
       "4  [17, 35, 3955, 75, 6983, 2, 11416, 8, 245, 45,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for encoding\n",
    "def encode_tokens(tokens):\n",
    "    return [token_to_idx.get(token, token_to_idx['<UNK>']) for token in tokens]\n",
    "\n",
    "# apply the encoding function to the 'tokens' column\n",
    "df['encoded_tokens'] = df['tokens'].apply(encode_tokens)\n",
    "\n",
    "# show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "fuU_v-q1-zEj",
    "outputId": "34625863-34d8-4ea0-8fc6-93f4a2279d5d"
   },
   "source": [
    "#### Step 1.5 Create `Dataset` and `DataLoader`\n",
    "\n",
    "Now the text is converted to a sequence of encoded tokens.\n",
    "\n",
    "The resulting sequences from different texts can have different lengths.\n",
    "\n",
    "We cannot directly convert a list of sequences of variable length into a `tensor` using the `TensorDataset()` API.\n",
    "\n",
    "Instead, we need to define a custom `Dataset` class to store the data as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VDpDTF4G-7Ri"
   },
   "outputs": [],
   "source": [
    "# define a custom Dataset class to store the data as tensors\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, encoded_tokens_list, labels):\n",
    "        self.encoded_tokens_list = encoded_tokens_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_tokens_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.encoded_tokens_list[idx]\n",
    "        y = self.labels[idx]\n",
    "        X = torch.tensor(X, dtype=torch.long)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aFfHX4Un_TGX"
   },
   "outputs": [],
   "source": [
    "# create the training, test and validation dataset\n",
    "ds = AGNewsDataset(df['encoded_tokens'].values, df['label'].values)\n",
    "train_val_ds, test_ds = random_split(ds, [0.7, 0.3])\n",
    "train_ds, val_ds = random_split(train_val_ds, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, when we create the `DataLoader` object, we can specify a collate function for the following purposes:\n",
    "- The sequences in the batch have different lengths. We use the `collate_batch` function to pad all sequences to the same length\n",
    "- We want to preserve the information about the length of the original sequence before padding. So we use the `collate_batch` function to record this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a collate function to pad the sequences in the same batch to equal length\n",
    "# in addition to the padded_X and y, also return the length of X before padding\n",
    "def collate_batch(batch):\n",
    "    batch_X, batch_y, batch_length = [], [], []\n",
    "    for (X, y) in batch:\n",
    "        batch_X.append(X)\n",
    "        batch_y.append(y)\n",
    "        batch_length.append(len(X))\n",
    "    batch_length = torch.tensor(batch_length, dtype=torch.int64)\n",
    "    batch_y = torch.tensor(batch_y, dtype=torch.int64)\n",
    "    # pad sequences to equal length\n",
    "    batch_X = pad_sequence(batch_X, batch_first = True)\n",
    "    return batch_X, batch_y, batch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e_8smkBg_pNP"
   },
   "outputs": [],
   "source": [
    "# create the training, validation, and test data loaders\n",
    "batch_size = 512 # usually set to 2 to the nth power\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True, collate_fn = collate_batch)\n",
    "val_dl = DataLoader(val_ds, batch_size = batch_size, shuffle = False, collate_fn = collate_batch)\n",
    "test_dl = DataLoader(test_ds, batch_size = batch_size, shuffle = False, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying this `collate_batch` function to each batch, we have three components per batch instead of two:\n",
    "- A batch of `padded_X`:\n",
    "    - A batch of sequences of encoded tokens padded to the same length\n",
    "- A batch of `y`:\n",
    "    - A batch of labels\n",
    "- A batch of `length`:\n",
    "    - A batch of lengths of the original sequences before padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 61])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# get one batch and print its shape\n",
    "for batch in test_dl:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[2].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create the LSTM-based text classifier\n",
    "\n",
    "For text classification task, the input is a sequence of tokens, the output is a class. So we need to use the many-to-one architecture of RNN, as shown in the following figure:\n",
    "\n",
    "![](https://i.imgur.com/C5Pgwyn.jpeg)\n",
    "\n",
    "In this step, we need to:\n",
    "- Define a custom class for the text classifier\n",
    "    - Specify the network structure\n",
    "        - The first layer is `nn.Embedding()`\n",
    "        - There is recurrent processes, so we can't use `nn.Sequential()` container anymore\n",
    "    - Specify the forward method\n",
    "        - Without using `nn.Sequential()`, we need to specify the forward process step by step\n",
    "            1. Word embedding\n",
    "            2. Pack the batch of padded sequences for sequential processing\n",
    "            3. Sequential processing with LSTM layer\n",
    "            4. Make prediction using the final hidden state\n",
    "- Create an instance of the network and move it to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iCZm_PSI_wsu"
   },
   "outputs": [],
   "source": [
    "# define a custom neural network class\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        packed_x = pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        out, (h, c) = self.lstm(packed_x)\n",
    "        return self.fc(h[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the following parameters to determine the network structure:\n",
    "- `vocab_size` is the number of unique tokens to embed, the size of the vocabulary\n",
    "- `embed_size` is the number of embedded features to represent the tokens\n",
    "- `hidden_size` is the number of hidden features of LSTM\n",
    "- `num_class` is the number of classes in the dataset\n",
    "\n",
    "In the `forward()` method, we can see the forward process has four steps:\n",
    "1. `x = self.embedding(x)` performs word embedding\n",
    "    - Take a batch of sequences of encoded tokens\n",
    "    - Convert the sequence of encoded tokens to the sequence of embedded tokens\n",
    "    - Each embedded token is represented by multiple embeded features\n",
    "2. `packed_x = pack_padded_sequence(x, lengths ...)` packs the batch of padded sequences for sequential processing\n",
    "   - We provide the information of the length of the original sequence before padding\n",
    "   - This lets the network know when the sequence ends and ignore the remaining padding tokens.\n",
    "   - Understanding the purpose of this operation is enough.\n",
    "   - The actual implementation can be complex. If you are interested, you can follow a informative discussion on stack overflow from this [link](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch).\n",
    "4. `out, (h, c) = self.lstm(packed_x)` use the LSTM layer to process the sequence of embedded tokens\n",
    "    - `out` is the sequence of all hidden state at each timestep\n",
    "    - `h` is the final hidden state\n",
    "    - `c` is the final cell state\n",
    "5. `return self.fc(h[-1])` make prediction using the final hidden state and a FC layer\n",
    "    - The shape of `h` is (1, batch_size, hidden_size)\n",
    "    - `h[-1]` delete the first useless dimension, the shape of `h[-1]` is (batch_size, hidden_size)\n",
    "    - The returned values are logits since we have a multi-class classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MO5Bt4v-_z3m"
   },
   "outputs": [],
   "source": [
    "# create the neural network\n",
    "embed_size = 64\n",
    "hidden_size = 32\n",
    "num_class = 4\n",
    "model = LSTMClassifier(vocab_size, embed_size, hidden_size, num_class)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Train the network\n",
    "\n",
    "The code is the same as the previous sessions. We need to:\n",
    "- Define a `train()` function to perform the training process\n",
    "- Specify the training hyper-parameters\n",
    "- Implement the training process\n",
    "- Visualize the loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_gzigRjY_2wS"
   },
   "outputs": [],
   "source": [
    "# define the training function\n",
    "def train(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    early_stopping_patience,\n",
    "    lr_scheduler,\n",
    "    saved_path_prefix\n",
    "):\n",
    "    # initialization\n",
    "    min_val_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    histories = {\n",
    "        'train_batch': [],\n",
    "        'train_epoch': [],\n",
    "        'val_batch': [],\n",
    "        'val_epoch': []\n",
    "    }\n",
    "    saved_path = ''\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        # train set\n",
    "        train_epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for X, y, lens in tqdm(train_dl, desc = f'Training batch\\t'): # tqdm progress bar\n",
    "            X, y, lens = X.to(device), y.to(device), lens.to(device)\n",
    "            logits = model(X, lens)\n",
    "            train_batch_loss = loss_fn(logits, y)\n",
    "            train_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            histories['train_batch'].append(train_batch_loss.item())\n",
    "            train_epoch_loss += train_batch_loss.item()\n",
    "        train_epoch_loss /= len(train_dl)\n",
    "        histories['train_epoch'].append(train_epoch_loss)\n",
    "\n",
    "        # validation set\n",
    "        val_epoch_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, lens in tqdm(val_dl, desc = f'Validation batch'): # tqdm progress bar\n",
    "                X, y, lens = X.to(device), y.to(device), lens.to(device)\n",
    "                logits = model(X, lens)\n",
    "                val_batch_loss = loss_fn(logits, y)\n",
    "                histories['val_batch'].append(val_batch_loss.item())\n",
    "                val_epoch_loss += val_batch_loss.item()\n",
    "            val_epoch_loss /= len(val_dl)\n",
    "            histories['val_epoch'].append(val_epoch_loss)\n",
    "\n",
    "        # print log\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_consumed = str(end_time - start_time).split('.')[0]\n",
    "        print(f\"Epoch {epoch + 1}: train loss = {train_epoch_loss:>5f}, val loss = {val_epoch_loss:>5f}, time consumed = {time_consumed}\")\n",
    "\n",
    "        # learning rate decay\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        lr_scheduler.step(val_epoch_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if current_lr != new_lr:\n",
    "            print(f'Learning rate reduced after epoch {epoch+1}\\n')\n",
    "\n",
    "        # early stopping\n",
    "        if val_epoch_loss < min_val_loss:\n",
    "            min_val_loss = val_epoch_loss\n",
    "            patience_counter = 0\n",
    "            if os.path.exists(saved_path):\n",
    "                os.remove(saved_path)\n",
    "            time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            saved_path = saved_path_prefix + f'_epoch_{epoch+1}_val_loss_{val_epoch_loss:>4f}_{time_str}.pth'\n",
    "            torch.save(model.state_dict(), saved_path)\n",
    "            print(f'Model saved after epoch {epoch+1}\\n')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "    return histories, saved_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aL3uu3uq_8gP"
   },
   "outputs": [],
   "source": [
    "# define the training hyper-parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-1\n",
    "weight_decay = 1e-5\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr = learning_rate,\n",
    "    weight_decay = weight_decay\n",
    ")\n",
    "epochs = 1000\n",
    "early_stopping_patience = 10\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode = 'min',\n",
    "    factor = 0.1,\n",
    "    patience = 5\n",
    ")\n",
    "saved_path_prefix = 'ag_news_classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge5xWWE8ADNR",
    "outputId": "ea72a136-d50b-4559-d94f-4d3db75d5a70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:44<00:00,  3.12it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 1.386079, val loss = 1.379796, time consumed = 0:00:46\n",
      "Model saved after epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.54it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss = 1.374377, val loss = 1.369221, time consumed = 0:01:18\n",
      "Model saved after epoch 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.47it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:00<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train loss = 1.362925, val loss = 1.357936, time consumed = 0:01:50\n",
      "Model saved after epoch 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.38it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train loss = 1.349467, val loss = 1.343544, time consumed = 0:02:23\n",
      "Model saved after epoch 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.50it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train loss = 1.332273, val loss = 1.325275, time consumed = 0:02:55\n",
      "Model saved after epoch 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.52it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train loss = 1.309523, val loss = 1.300395, time consumed = 0:03:27\n",
      "Model saved after epoch 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.52it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train loss = 1.273521, val loss = 1.252114, time consumed = 0:03:59\n",
      "Model saved after epoch 7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train loss = 1.189965, val loss = 1.146528, time consumed = 0:04:30\n",
      "Model saved after epoch 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.55it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train loss = 1.094132, val loss = 1.060579, time consumed = 0:05:02\n",
      "Model saved after epoch 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.48it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train loss = 1.022372, val loss = 0.968861, time consumed = 0:05:34\n",
      "Model saved after epoch 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.52it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train loss = 0.942979, val loss = 0.911890, time consumed = 0:06:06\n",
      "Model saved after epoch 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.49it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train loss = 0.844461, val loss = 0.820700, time consumed = 0:06:39\n",
      "Model saved after epoch 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:32<00:00,  4.29it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train loss = 0.772237, val loss = 0.812158, time consumed = 0:07:12\n",
      "Model saved after epoch 13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:32<00:00,  4.34it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train loss = 0.719617, val loss = 0.750024, time consumed = 0:07:46\n",
      "Model saved after epoch 14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.56it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train loss = 0.675276, val loss = 0.687756, time consumed = 0:08:17\n",
      "Model saved after epoch 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.56it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 27.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train loss = 0.632365, val loss = 0.635950, time consumed = 0:08:49\n",
      "Model saved after epoch 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.55it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train loss = 0.593841, val loss = 0.670181, time consumed = 0:09:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.58it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train loss = 0.570647, val loss = 0.587364, time consumed = 0:09:53\n",
      "Model saved after epoch 18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.52it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train loss = 0.549044, val loss = 0.600315, time consumed = 0:10:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.49it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train loss = 0.527171, val loss = 0.577386, time consumed = 0:10:57\n",
      "Model saved after epoch 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.51it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train loss = 0.511523, val loss = 0.543527, time consumed = 0:11:29\n",
      "Model saved after epoch 21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.58it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train loss = 0.492972, val loss = 0.527264, time consumed = 0:12:01\n",
      "Model saved after epoch 22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train loss = 0.481295, val loss = 0.521947, time consumed = 0:12:32\n",
      "Model saved after epoch 23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.58it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train loss = 0.463374, val loss = 0.512592, time consumed = 0:13:04\n",
      "Model saved after epoch 24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train loss = 0.457538, val loss = 0.576156, time consumed = 0:13:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train loss = 0.449559, val loss = 0.562397, time consumed = 0:14:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.58it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train loss = 0.438788, val loss = 0.494297, time consumed = 0:14:38\n",
      "Model saved after epoch 27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train loss = 0.430823, val loss = 0.510827, time consumed = 0:15:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train loss = 0.421999, val loss = 0.493132, time consumed = 0:15:40\n",
      "Model saved after epoch 29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train loss = 0.414124, val loss = 0.536634, time consumed = 0:16:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train loss = 0.410677, val loss = 0.493186, time consumed = 0:16:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train loss = 0.402038, val loss = 0.476701, time consumed = 0:17:14\n",
      "Model saved after epoch 32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train loss = 0.397320, val loss = 0.475170, time consumed = 0:17:46\n",
      "Model saved after epoch 33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.65it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train loss = 0.391437, val loss = 0.475287, time consumed = 0:18:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train loss = 0.387724, val loss = 0.468569, time consumed = 0:18:48\n",
      "Model saved after epoch 35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.62it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train loss = 0.383133, val loss = 0.482220, time consumed = 0:19:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.57it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train loss = 0.379645, val loss = 0.467662, time consumed = 0:19:51\n",
      "Model saved after epoch 37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.56it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train loss = 0.373533, val loss = 0.463850, time consumed = 0:20:23\n",
      "Model saved after epoch 38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train loss = 0.371287, val loss = 0.460902, time consumed = 0:20:54\n",
      "Model saved after epoch 39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: train loss = 0.367770, val loss = 0.458046, time consumed = 0:21:25\n",
      "Model saved after epoch 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.65it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: train loss = 0.361076, val loss = 0.467955, time consumed = 0:21:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: train loss = 0.358464, val loss = 0.459165, time consumed = 0:22:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.65it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: train loss = 0.354262, val loss = 0.465292, time consumed = 0:22:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: train loss = 0.353115, val loss = 0.455170, time consumed = 0:23:30\n",
      "Model saved after epoch 44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: train loss = 0.349602, val loss = 0.456829, time consumed = 0:24:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: train loss = 0.345510, val loss = 0.478557, time consumed = 0:24:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: train loss = 0.344796, val loss = 0.459409, time consumed = 0:25:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: train loss = 0.339920, val loss = 0.468977, time consumed = 0:25:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.50it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: train loss = 0.338643, val loss = 0.448482, time consumed = 0:26:08\n",
      "Model saved after epoch 49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.58it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: train loss = 0.334618, val loss = 0.446437, time consumed = 0:26:40\n",
      "Model saved after epoch 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.61it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: train loss = 0.332210, val loss = 0.454685, time consumed = 0:27:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: train loss = 0.331166, val loss = 0.456965, time consumed = 0:27:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.60it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: train loss = 0.327671, val loss = 0.454071, time consumed = 0:28:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.61it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: train loss = 0.325300, val loss = 0.446737, time consumed = 0:28:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.66it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: train loss = 0.323042, val loss = 0.452765, time consumed = 0:29:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.49it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: train loss = 0.321604, val loss = 0.453457, time consumed = 0:29:48\n",
      "Learning rate reduced after epoch 56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.64it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: train loss = 0.306704, val loss = 0.448546, time consumed = 0:30:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:31<00:00,  4.44it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 31.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: train loss = 0.305510, val loss = 0.448368, time consumed = 0:30:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.60it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: train loss = 0.304713, val loss = 0.448183, time consumed = 0:31:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch\t: 100%|██████████| 140/140 [00:30<00:00,  4.61it/s]\n",
      "Validation batch: 100%|██████████| 35/35 [00:01<00:00, 33.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: train loss = 0.304344, val loss = 0.448740, time consumed = 0:31:55\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "histories, saved_path = train(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    early_stopping_patience,\n",
    "    lr_scheduler,\n",
    "    saved_path_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "dCFX6pS2AHH9",
    "outputId": "c5f74988-fa72-427c-b115-334f5249e921"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzYUlEQVR4nO3dd3gUVd/G8e9mk2x6QjqhJfRepElRRLqKgCiIKCCWRwULWPG16yP2jqLYfVSaigqIIFIU6b3XhAAhQAjppO68f0xYiEBIQsKm3J/r2ms3szO7v51g9vacM+dYDMMwEBEREakkXJxdgIiIiEhpUrgRERGRSkXhRkRERCoVhRsRERGpVBRuREREpFJRuBEREZFKReFGREREKhWFGxEREalUFG5ERESkUlG4ESmhyMhIRo0a5ewyypUvv/wSi8VCTEyMY9tVV13FVVdddcFjFy9ejMViYfHixaVak8Vi4bnnnivV1yyK5557DovFcsnftzAxMTFYLBbeeOONC+5bHusXKSqFG6m0/vnnH5577jmSkpKcXYqUsblz5zolwEhBcXFxPPfcc2zYsMHZpUgVp3AjldY///zD888/X2bhZufOnUyZMqVMXrsymT9/PvPnzy/T95g7dy7PP//8OZ87efIkTz31VJm+f2X01FNPcfLkyWIdExcXx/PPP69wI07n6uwCRMoDu91OdnY2Hh4eRT7GZrOVYUWVh7u7u1Pfvzi/UznN1dUVV9fy8RWRnp6Ot7e3s8uQCkQtN1IpPffcczz66KMAREVFYbFYCowFsVgsjB07lm+//ZZmzZphs9mYN28eAG+88QadO3cmKCgIT09P2rZty8yZM896j3+PuTk13mTZsmWMHz+ekJAQvL29GTRoEMeOHSu03jfeeAOLxcL+/fvPem7ChAm4u7tz4sQJAHbv3s3gwYMJDw/Hw8ODmjVrcvPNN5OcnFysczRz5kwsFgtLliw567mPP/4Yi8XCli1bANi0aROjRo2ibt26eHh4EB4ezujRozl+/PgF3+dcY24OHjzIwIED8fb2JjQ0lHHjxpGVlXXWsX/99Rc33XQTtWvXxmazUatWLcaNG1egRWHUqFFMmjQJwPF7PnOsyLnG3Kxfv55+/frh5+eHj48PPXr0YMWKFQX2uZjf5/nk5uby4osvUq9ePWw2G5GRkTz55JNnffY1a9bQp08fgoOD8fT0JCoqitGjRxfYZ+rUqbRt2xZfX1/8/Pxo0aIF7777bpFr+eSTTxx1tG/fntWrVxd4/lxjbhYsWEDXrl0JCAjAx8eHRo0a8eSTTwLmmKn27dsDcPvttzt+D19++aXj+BkzZtC2bVs8PT0JDg7m1ltv5dChQwXeY9SoUfj4+LB3716uueYafH19GT58OM8++yxubm7nPPd33303AQEBZGZmFvnzS+VWPmK5SCm74YYb2LVrF99//z1vv/02wcHBAISEhDj2+fPPP5k+fTpjx44lODiYyMhIAN59912uv/56hg8fTnZ2NlOnTuWmm25i9uzZXHvttRd87/vvv59q1arx7LPPEhMTwzvvvMPYsWOZNm3aeY8ZMmQIjz32GNOnT3eEslOmT59O7969qVatGtnZ2fTp04esrCzuv/9+wsPDOXToELNnzyYpKQl/f/8in6Nrr70WHx8fpk+fTrdu3Qo8N23aNJo1a0bz5s0B80tt37593H777YSHh7N161Y++eQTtm7dyooVK4o18PTkyZP06NGD2NhYHnjgASIiIvjmm2/4888/z9p3xowZZGRkcO+99xIUFMSqVat4//33OXjwIDNmzADgP//5D3FxcSxYsIBvvvnmgu+/detWrrjiCvz8/Hjsscdwc3Pj448/5qqrrmLJkiV07NixwP4l+X2ez5133slXX33FjTfeyMMPP8zKlSuZOHEi27dv56effgLg6NGj9O7dm5CQEJ544gkCAgKIiYnhxx9/dLzOggULGDZsGD169ODVV18FYPv27SxbtowHH3zwgnV89913pKam8p///AeLxcJrr73GDTfcwL59+3Bzczvvebvuuuto2bIlL7zwAjabjT179rBs2TIAmjRpwgsvvMAzzzzD3XffzRVXXAFA586dATMs3n777bRv356JEydy5MgR3n33XZYtW8b69esJCAhwvFdubi59+vSha9euvPHGG3h5edGpUydeeOEFpk2bxtixYx37ZmdnM3PmTAYPHqxWOjnNEKmkXn/9dQMwoqOjz3oOMFxcXIytW7ee9VxGRkaBn7Ozs43mzZsbV199dYHtderUMUaOHOn4+YsvvjAAo2fPnobdbndsHzdunGG1Wo2kpKRC6+3UqZPRtm3bAttWrVplAMbXX39tGIZhrF+/3gCMGTNmFPpaRTVs2DAjNDTUyM3NdWw7fPiw4eLiYrzwwguObf8+J4ZhGN9//70BGEuXLnVsO3UOzjzn3bp1M7p16+b4+Z133jEAY/r06Y5t6enpRv369Q3AWLRoUaHvO3HiRMNisRj79+93bBszZoxxvj9ngPHss886fh44cKDh7u5u7N2717EtLi7O8PX1Na688sqzPktJf5/PPvtsgZo2bNhgAMadd95ZYL9HHnnEAIw///zTMAzD+OmnnwzAWL169Xlf+8EHHzT8/PwK/N6KIjo62gCMoKAgIzEx0bH9559/NgDj119/PW/9b7/9tgEYx44dO+/rr1692gCML774osD27OxsIzQ01GjevLlx8uRJx/bZs2cbgPHMM884to0cOdIAjCeeeOKs1+/UqZPRsWPHAtt+/PHHs/7diKhbSqqsbt260bRp07O2e3p6Oh6fOHGC5ORkrrjiCtatW1ek17377rsLtGRcccUV5OXlnbPL6UxDhw5l7dq17N2717Ft2rRp2Gw2BgwYAOBomfn999/JyMgoUj0Xes+jR48WuPx65syZ2O12hg4d6th25jnJzMwkISGByy+/HKDI5+WUuXPnUr16dW688UbHNi8vL+6+++6z9j3zfdPT00lISKBz584YhsH69euL9b4AeXl5zJ8/n4EDB1K3bl3H9urVq3PLLbfw999/k5KSUuCYkv4+/23u3LkAjB8/vsD2hx9+GIA5c+YAOFowZs+eTU5OzjlfKyAggPT0dBYsWFCsGk4ZOnQo1apVc/x8qpVl37595z3mVF0///wzdru9WO+3Zs0ajh49yn333VegdeXaa6+lcePGjs9+pnvvvfesbSNGjGDlypUF/hv59ttvqVWr1lmtj1K1KdxIlRUVFXXO7bNnz+byyy/Hw8ODwMBAQkJC+Oijj4o8pqV27doFfj71JXJqzMz53HTTTbi4uDi6OwzDYMaMGY6xIadqHj9+PJ9++inBwcH06dOHSZMmFXu8zSl9+/bF39+/QBfLtGnTaN26NQ0bNnRsS0xM5MEHHyQsLAxPT09CQkIc56+4771//37q169/VldWo0aNzto3NjaWUaNGERgYiI+PDyEhIY4vsZJ85mPHjpGRkXHO92rSpAl2u50DBw4U2F7S3+e/7d+/HxcXF+rXr19ge3h4OAEBAY6w1K1bNwYPHszzzz9PcHAwAwYM4IsvvigwLue+++6jYcOG9OvXj5o1azJ69GjHmLGiKMlnGjp0KF26dOHOO+8kLCyMm2++menTpxcp6Jz6bOc6740bNz4rKLq6ulKzZs1z1mCz2fj2228B89/A7NmzGT58uObkkQIUbqTKOrNV4JS//vqL66+/Hg8PDz788EPmzp3LggULuOWWWzAMo0iva7Vaz7n9QsdHRERwxRVXMH36dABWrFhBbGxsgRYUgDfffJNNmzbx5JNPcvLkSR544AGaNWvGwYMHi1TfmWw2GwMHDuSnn34iNzeXQ4cOsWzZsrPec8iQIUyZMoV77rmHH3/8kfnz5zu+TIv7f/FFlZeXR69evZgzZw6PP/44s2bNYsGCBY4BqmX1vv9W0t/n+VzoS9hisTBz5kyWL1/O2LFjOXToEKNHj6Zt27akpaUBEBoayoYNG/jll1+4/vrrWbRoEf369WPkyJFFqqEkn8nT05OlS5fyxx9/cNttt7Fp0yaGDh1Kr169yMvLK9L7FpXNZsPF5eyvp2rVqnHdddc5ws3MmTPJysri1ltvLdX3l4pP4UYqrZL8n9wPP/yAh4cHv//+O6NHj6Zfv3707NmzDKo7t6FDh7Jx40Z27tzJtGnT8PLyon///mft16JFC5566imWLl3KX3/9xaFDh5g8eXKJ3zMhIYGFCxcyY8YMDMMoEG5OnDjBwoULeeKJJ3j++ecZNGgQvXr1KtCtUxx16tRh7969Z32R7ty5s8DPmzdvZteuXbz55ps8/vjjDBgwgJ49exIREXHWaxb1dx0SEoKXl9dZ7wWwY8cOXFxcqFWrVjE+TdHVqVMHu93O7t27C2w/cuQISUlJ1KlTp8D2yy+/nP/+97+sWbOGb7/9lq1btzJ16lTH8+7u7vTv358PP/yQvXv38p///Ievv/6aPXv2lEn9AC4uLvTo0YO33nqLbdu28d///pc///yTRYsWAef/PZz6bOc67zt37jzrsxdmxIgR7Nq1i9WrV/Ptt9/Spk0bmjVrVoJPI5WZwo1UWqfmxSjOJH5WqxWLxVLg/0RjYmKYNWtWKVd3boMHD8ZqtfL9998zY8YMrrvuugLze6SkpJCbm1vgmBYtWuDi4lKg2yI2NpYdO3YU6T179uxJYGAg06ZNY9q0aXTo0KFAl92p/8v/dxh55513ivvxALjmmmuIi4srcHl9RkYGn3zySYH9zvW+hmGc83Lnov6urVYrvXv35ueffy6wRMSRI0f47rvv6Nq1q6MLsLRdc801wNnn7a233gJwXIl34sSJs85169atARy/439fgu/i4kLLli0L7FPaEhMTz9r277rO93to164doaGhTJ48uUB9v/32G9u3by/SVYin9OvXj+DgYF599VWWLFmiVhs5J10KLpVW27ZtAfi///s/br75Ztzc3Ojfv3+hk4Fde+21vPXWW/Tt25dbbrmFo0ePMmnSJOrXr8+mTZvKvObQ0FC6d+/OW2+9RWpq6lndQ3/++Sdjx47lpptuomHDhuTm5vLNN99gtVoZPHiwY78RI0awZMmSInWduLm5ccMNNzB16lTS09PPWnfIz8+PK6+8ktdee42cnBxq1KjB/PnziY6OLtFnvOuuu/jggw8YMWIEa9eupXr16nzzzTd4eXkV2K9x48bUq1ePRx55hEOHDuHn58cPP/xwznEhp37XDzzwAH369MFqtXLzzTef8/1feuklx3wt9913H66urnz88cdkZWXx2muvlegzFUWrVq0YOXIkn3zyCUlJSXTr1o1Vq1bx1VdfMXDgQLp37w7AV199xYcffsigQYOoV68eqampTJkyBT8/P0dAuvPOO0lMTOTqq6+mZs2a7N+/n/fff5/WrVvTpEmTMqn/hRdeYOnSpVx77bXUqVOHo0eP8uGHH1KzZk26du0KQL169QgICGDy5Mn4+vri7e1Nx44diYqK4tVXX+X222+nW7duDBs2zHEpeGRkJOPGjStyHW5ubtx888188MEHWK1Whg0bViafVyo4p1yjJXKJvPjii0aNGjUMFxeXApcoA8aYMWPOecxnn31mNGjQwLDZbEbjxo2NL7744qzLYg3j/JeC//sS3kWLFhXrUtUpU6YYgOHr61vgslnDMIx9+/YZo0ePNurVq2d4eHgYgYGBRvfu3Y0//vijwH7dunU776XR57JgwQIDMCwWi3HgwIGznj948KAxaNAgIyAgwPD39zduuukmIy4u7qzLrItyKbhhGMb+/fuN66+/3vDy8jKCg4ONBx980Jg3b95Z52nbtm1Gz549DR8fHyM4ONi46667jI0bN551uXFubq5x//33GyEhIYbFYinw2f9do2EYxrp164w+ffoYPj4+hpeXl9G9e3fjn3/+KbDPxf4+z/VvJicnx3j++eeNqKgow83NzahVq5YxYcIEIzMzs0Btw4YNM2rXrm3YbDYjNDTUuO6664w1a9Y49pk5c6bRu3dvIzQ01HB3dzdq165t/Oc//zEOHz5caE2nLgV//fXXz3ru3+fp3/UvXLjQGDBggBEREWG4u7sbERERxrBhw4xdu3YVeJ2ff/7ZaNq0qeHq6nrW72natGlGmzZtDJvNZgQGBhrDhw83Dh48WOD4kSNHGt7e3oV+jlNTJPTu3bvQ/aTqshhGCUfFiYiIOMHGjRtp3bo1X3/9Nbfddpuzy5FySGNuRESkQpkyZQo+Pj7ccMMNzi5FyimNuRERkQrh119/Zdu2bXzyySeMHTtWi2nKealbSkREKoTIyEiOHDlCnz59+Oabb/D19XV2SVJOKdyIiIhIpaIxNyIiIlKpKNyIiIhIpVLlBhTb7Xbi4uLw9fXVQmsiIiIVhGEYpKamEhERcc61x85U5cJNXFxcma0dIyIiImXrwIED51w1/kxVLtycGl1/4MCBMltDRkREREpXSkoKtWrVKtJVclUu3JzqivLz81O4ERERqWCKMqREA4pFRESkUlG4ERERkUpF4UZEREQqlSo35kZERCq/vLw8cnJynF2GFJO7u/sFL/MuCoUbERGpNAzDID4+nqSkJGeXIiXg4uJCVFQU7u7uF/U6Tg03S5cu5fXXX2ft2rUcPnyYn376iYEDBxbp2GXLltGtWzeaN2/Ohg0byrROERGpGE4Fm9DQULy8vDRZawVyapLdw4cPU7t27Yv63Tk13KSnp9OqVStGjx7NDTfcUOTjkpKSGDFiBD169ODIkSNlWKGIiFQUeXl5jmATFBTk7HKkBEJCQoiLiyM3Nxc3N7cSv45Tw02/fv3o169fsY+75557uOWWW7BarcyaNav0CxMRkQrn1BgbLy8vJ1ciJXWqOyovL++iwk2Fu1rqiy++YN++fTz77LPOLkVERMohdUVVXKX1u6tQA4p3797NE088wV9//YWra9FKz8rKIisry/FzSkpKWZUnIiIi5UCFabnJy8vjlltu4fnnn6dhw4ZFPm7ixIn4+/s7blo0U0REKrPIyEjeeecdp7+GM1WYlpvU1FTWrFnD+vXrGTt2LGCOrDYMA1dXV+bPn8/VV1991nETJkxg/Pjxjp9PLbwlIiJSHlx11VW0bt261MLE6tWr8fb2LpXXqqgqTLjx8/Nj8+bNBbZ9+OGH/Pnnn8ycOZOoqKhzHmez2bDZbJeiRP7Zk0C7yEDcXStMg5iIiFQAhmGQl5dXpCEZISEhl6Ci8s2p38JpaWls2LDBMU9NdHQ0GzZsIDY2FjBbXUaMGAGYE/s0b968wC00NBQPDw+aN2/u9JS671gawz9bSbfXF/H539FkZOc6tR4RESn/Ro0axZIlS3j33XexWCxYLBZiYmJYvHgxFouF3377jbZt22Kz2fj777/Zu3cvAwYMICwsDB8fH9q3b88ff/xR4DX/3aVksVj49NNPGTRoEF5eXjRo0IBffvmlWHXGxsYyYMAAfHx88PPzY8iQIQWmYtm4cSPdu3fH19cXPz8/2rZty5o1awDYv38//fv3p1q1anh7e9OsWTPmzp1b8pNWBE4NN2vWrKFNmza0adMGgPHjx9OmTRueeeYZAA4fPuwIOuXdwRMnGeS1iaTkJF6YvY0ur/zJ+wt3k5yh6b9FRJzBMAwysnOdcjMMo0g1vvvuu3Tq1Im77rqLw4cPc/jw4QJDJ5544gleeeUVtm/fTsuWLUlLS+Oaa65h4cKFrF+/nr59+9K/f/8Lflc+//zzDBkyhE2bNnHNNdcwfPhwEhMTi1Sj3W5nwIABJCYmsmTJEhYsWMC+ffsYOnSoY5/hw4dTs2ZNVq9ezdq1a3niiSccl3KPGTOGrKwsli5dyubNm3n11Vfx8fEp0nuXlFO7pa666qpC/wF8+eWXhR7/3HPP8dxzz5VuUSV0ZbVErsx7hVd8fPmBHkxK786bC3L4eOk+hl9emzu6RhHq6+HsMkVEqoyTOXk0feZ3p7z3thf64OV+4a9Yf39/3N3d8fLyIjw8/KznX3jhBXr16uX4OTAwkFatWjl+fvHFF/npp5/45ZdfHONRz2XUqFEMGzYMgJdffpn33nuPVatW0bdv3wvWuHDhQjZv3kx0dLQjeH399dc0a9aM1atX0759e2JjY3n00Udp3LgxAA0aNHAcHxsby+DBg2nRogUAdevWveB7XiwNDiktqfFQLRL33FSG5c7iL9s4/ufzPs1zNvHxkr10fXURT83azIHEDGdXKiIiFUS7du0K/JyWlsYjjzxCkyZNCAgIwMfHh+3bt1+w5aZly5aOx97e3vj5+XH06NEi1bB9+3Zq1apVoEWpadOmBAQEsH37dsDsebnzzjvp2bMnr7zyCnv37nXs+8ADD/DSSy/RpUsXnn32WTZt2lSk970YFWZAcblXtxvcvw52L4CVk7HsW0TX3OV0dV9OjDWSjzJ7MXNFZ75fdYBrW1Tnnm71aBrh5+yqRUQqLU83K9te6OO09y4N/x5P+sgjj7BgwQLeeOMN6tevj6enJzfeeCPZ2dmFvs6/Z/u1WCzY7fZSqRHMnpRbbrmFOXPm8Ntvv/Hss88ydepUBg0axJ133kmfPn2YM2cO8+fPZ+LEibz55pvcf//9pfb+/6ZwU5pcrNCor3k7ugNWfQIbvycyJ4ZX3abwlG0qX2b34KuNffhlYxxXNgzhnm516VQ3SDNqioiUMovFUqSuIWdzd3cnLy+vSPsuW7aMUaNGMWjQIMBsyYmJiSnD6qBJkyYcOHCAAwcOOFpvtm3bRlJSEk2bNnXs17BhQxo2bMi4ceMYNmwYX3zxhaPOWrVqcc8993DPPfcwYcIEpkyZUqbhRt1SZSW0MVz3FozfDr3/CwF18LWncr/rLJZ7PsDLbp9yYPcmbpmykoGTljFvy2Hy7EUbgCYiIpVHZGQkK1euJCYmhoSEhEJbVBo0aMCPP/7Ihg0b2LhxI7fcckuptsCcS8+ePWnRogXDhw9n3bp1rFq1ihEjRtCtWzfatWvHyZMnGTt2LIsXL2b//v0sW7aM1atX06RJEwAeeughfv/9d6Kjo1m3bh2LFi1yPFdWFG7KmmcAdB4LD6yHId9AjXa4GTncYv2ThbZH+MT9bVwOreGe/62j99tL+H1rfJFH2YuISMX3yCOPYLVaadq0KSEhIYWOn3nrrbeoVq0anTt3pn///vTp04fLLrusTOuzWCz8/PPPVKtWjSuvvJKePXtSt25dpk2bBoDVauX48eOMGDGChg0bMmTIEPr168fzzz8PmCsMjBkzhiZNmtC3b18aNmzIhx9+WLY1G1XsmzQlJQV/f3+Sk5Px83PCmBfDgNjlsOw92PWbY/M6GvN+dn8W2VvTrk4gE65pQts61S59fSIiFVRmZibR0dFERUXh4aGrUyuiwn6Hxfn+VsvNpWaxQJ3OcMtUuG8ltLkVXNy4jB184f4639peISl2M4M/+od7/7eWfcfSnF2xiIhIhaJw40yhjWHAJHhoM3R+AKw2ulg287ttAs+4fsOyLXvp/fZSnvl5CwlpWRd+PREREVG4KRf8qkPvF2HMSmh8HVbyGO36G397Pcpgy5/8b3k03V5bxKd/7cOuQcciIiKFUrgpTwKj4OZv4dYfIbghfvYkXnWbwu/ez9EoZzsvzdnOLZ+u4FDSSWdXKiIiUm4p3JRH9XvAvf9An4lg86NB3h5+tD3Ha7bP2LDvMH3fWcqs9Yd0VZWIiMg5KNyUV1Y36HSfOetxm9sAC0MsC5nv/RzhWTE8NG0DY79fT1JG4bNSioiIVDUKN+WdTwgM+ABG/Aw+YdTO289cz6cZ6rqYOZvi6PvOX/y9O8HZVYqIiJQbCjcVRd1ucM/fULc7bvYsXnX9hCk+n5CacoJbP1vJ879uJSu3aNN3i4iIVGYKNxWJT6g52LjHM2Cx0it3CYv9n6OpJYYvlsUw+svVpGXlOrtKERERp1K4qWhcXOCKh2HUHPCrQUjWAX71fI7R7gtZtieB4VNWkJiucTgiIlVJZGQk77zzznmfHzVqFAMHDrxk9Tibwk1FVaeT2U3VsC9WezbPuHzGix7fs/FgEkM+Xs7hZF0uLiIiVZPCTUXmFQjDpkKvFwC4jdm85D2DPUdTufGj5Vq6QUREqiSFm4rOYoEuD8K1bwFwa94sJvr+wKGkDG6avJwth5KdXKCIiJzPJ598QkREBHa7vcD2AQMGMHr0aAD27t3LgAEDCAsLw8fHh/bt2/PHH39c1PtmZWXxwAMPEBoaioeHB127dmX16tWO50+cOMHw4cMJCQnB09OTBg0a8MUXXwCQnZ3N2LFjqV69Oh4eHtSpU4eJEydeVD2lTeGmsmh/B1zzBgDDcn7k1Wo/czw9i5s/WcGKfcedXJyIiBMYBmSnO+dWxElWb7rpJo4fP86iRYsc2xITE5k3bx7Dhw8HIC0tjWuuuYaFCxeyfv16+vbtS//+/YmNjS3xqXnsscf44Ycf+Oqrr1i3bh3169enT58+JCYmAvD000+zbds2fvvtN7Zv385HH31EcHAwAO+99x6//PIL06dPZ+fOnXz77bdERkaWuJay4OrsAqQUdbgLDDv89hhDT07HNdiVhxOuY8Tnq5h0y2X0ahrm7ApFRC6dnAx4OcI57/1kHLh7X3C3atWq0a9fP7777jt69OgBwMyZMwkODqZ79+4AtGrVilatWjmOefHFF/npp5/45ZdfGDt2bLFLS09P56OPPuLLL7+kX79+AEyZMoUFCxbw2Wef8eijjxIbG0ubNm1o164dQIHwEhsbS4MGDejatSsWi4U6deoUu4ayppabyqbjf8xlG4DBad/xbvjvZOfaue/btWyLS3FycSIi8m/Dhw/nhx9+ICsrC4Bvv/2Wm2++GRcX8ys6LS2NRx55hCZNmhAQEICPjw/bt28vccvN3r17ycnJoUuXLo5tbm5udOjQge3btwNw7733MnXqVFq3bs1jjz3GP//849h31KhRbNiwgUaNGvHAAw8wf/78kn70MqOWm8qo031g5MH8pxiQ9BX2cAvj4nszfvoGfh7bBZur1dkVioiUPTcvswXFWe9dRP3798cwDObMmUP79u3566+/ePvttx3PP/LIIyxYsIA33niD+vXr4+npyY033kh2dtlN+9GvXz/279/P3LlzWbBgAT169GDMmDG88cYbXHbZZURHR/Pbb7/xxx9/MGTIEHr27MnMmTPLrJ7iUriprDrfb3ZRLXiGQUlfcsgzmzfir+OdP3bzeN/Gzq5ORKTsWSxF6hpyNg8PD2644Qa+/fZb9uzZQ6NGjbjssssczy9btoxRo0YxaNAgwGzJiYmJKfH71atXD3d3d5YtW+boUsrJyWH16tU89NBDjv1CQkIYOXIkI0eO5IorruDRRx/ljTfMsZ1+fn4MHTqUoUOHcuONN9K3b18SExMJDAwscV2lSeGmMuvyINjzYOHzjDW+4zdLMz5eAj2bhNK2Tvn4BygiImbX1HXXXcfWrVu59dZbCzzXoEEDfvzxR/r374/FYuHpp58+6+qq4vD29ubee+/l0UcfJTAwkNq1a/Paa6+RkZHBHXfcAcAzzzxD27ZtadasGVlZWcyePZsmTZoA8NZbb1G9enXatGmDi4sLM2bMIDw8nICAgBLXVNo05qayu2I8NB8MwKtBc7Ab8PD0jWRka5kGEZHy4uqrryYwMJCdO3dyyy23FHjurbfeolq1anTu3Jn+/fvTp0+fAi07JfHKK68wePBgbrvtNi677DL27NnD77//TrVq1QBwd3dnwoQJtGzZkiuvvBKr1crUqVMB8PX15bXXXqNdu3a0b9+emJgY5s6d6xgjVB5YDKOI16tVEikpKfj7+5OcnIyfn5+zy7k0EnbDpA5g2LnD7VUWptZiRKc6vDCgubMrExEpNZmZmURHRxMVFYWHh4ezy5ESKOx3WJzv7/ITs6TsBDeAljcD8HrwHAC+Xr6fv3cnOLMqERGRMqFwU1V0exQsVgIPL+XJFuYl4Y/O3EjyyRwnFyYiIlK6FG6qisC60Nrsx70j5zsig7w4nJzJ879udXJhIiIipUvhpiq58lFwccMas5SPrzyJiwV+XHeI37fGO7syERGRUqNwU5VUqwOX3QZAo20fcPcVdQF48sfNJKRlObMyEZFSU8Wuk6lUSut3p3BT1VzxCFjdYf8yxjc4TONwX46nZ/P6vJ3OrkxE5KK4ubkBkJGR4eRKpKROzbpstV7cTPqaxK+q8a8BbW+HVR/jvvQVnr3uO4Z9upJ5W+P576DmuFqVd0WkYrJarQQEBHD06FEAvLy8sFgsTq5Kisput3Ps2DG8vLxwdb24eKJwUxVdMR7WfQUHVtLBvp5qXm6cyMhhXWwSHaI0c7GIVFzh4eEAjoAjFYuLiwu1a9e+6FCqcFMV+YZD+zth+QdYF79MtwZvMmvjYf7ccVThRkQqNIvFQvXq1QkNDSUnR1NdVDTu7u6lMtOxwk1V1eUhWPM5xK1j2OXbmUUAf+44whP9tKimiFR8Vqv1osdtSMWlARZVlU8IdLgbgHb7PsLqAruOpHHwhAbiiYhIxaZwU5V1fgDcfbAe3cw9odsBWLRD/dQiIlKxKdxUZd5B0PEeAIZZfgdgocKNiIhUcAo3VV3zwQBEpG7BlVz+2XucjOxcJxclIiJScgo3VV1IY/DwxyU3g27+R8jOtfPPnuPOrkpERKTEFG6qOhcXqHU5ADcGHwDgz53qmhIRkYpL4UagdkcA2rrsAsxBxVqbRUREKiqFG4HanQAISVyPp5sLh5Mz2X441clFiYiIlIzCjUDEZWB1x5J+hIF1zEXLFqlrSkREKiiFGwE3D6jeGoD+gbEA/KlLwkVEpIJSuBFTbXNQcWv7DgDWxZ4gMT3bmRWJiIiUiMKNmPLH3XjFr6ZJdT8MA5bsUuuNiIhUPAo3YqplXjFFwk6urecOwMLtCjciIlLxKNyIyTsIghsC0NffHHezdNcxcvPszqxKRESk2JwabpYuXUr//v2JiIjAYrEwa9asQvf/8ccf6dWrFyEhIfj5+dGpUyd+//33S1NsVZA/7qbuyc0EeruTkpnL2v0nnFyUiIhI8Tg13KSnp9OqVSsmTZpUpP2XLl1Kr169mDt3LmvXrqV79+7079+f9evXl3GlVUT+uBuXAyu5qmEIoKumRESk4rEY5WQqWovFwk8//cTAgQOLdVyzZs0YOnQozzzzTJH2T0lJwd/fn+TkZPz8/EpQaSV2fC+8b855M+faVYyZvo0GoT4sGN/N2ZWJiEgVV5zv7wo95sZut5OamkpgYKCzS6kcAuuCdyjkZdPN9yBWFwu7j6ZxIDHD2ZWJiIgUWYUON2+88QZpaWkMGTLkvPtkZWWRkpJS4CbnYbE4xt34HFlDuzrVAHVNiYhIxVJhw813333H888/z/Tp0wkNDT3vfhMnTsTf399xq1Wr1iWssgLKDzfEruDqxuZ5VbgREZGKpEKGm6lTp3LnnXcyffp0evbsWei+EyZMIDk52XE7cODAJaqygjoj3PRoHAzA8n3HycjOdWJRIiIiRVfhws3333/P7bffzvfff8+11157wf1tNht+fn4FblKI8Jbg5gWZSdSzxFEr0JPsXDvL9hx3dmUiIiJF4tRwk5aWxoYNG9iwYQMA0dHRbNiwgdhYcxK5CRMmMGLECMf+3333HSNGjODNN9+kY8eOxMfHEx8fT3JysjPKr5ysblCjLQCW2BV0y78k/J+9Cc6sSkREpMicGm7WrFlDmzZtaNOmDQDjx4+nTZs2jsu6Dx8+7Ag6AJ988gm5ubmMGTOG6tWrO24PPvigU+qvtPLnuyF2BZ3r5XdN7VXLjYiIVAyuznzzq666isKm2fnyyy8L/Lx48eKyLUhMp8bdHFjB5X2CANgRn8rxtCyCfGxOLExEROTCKtyYG7kEarYHiwuciCEw7ziNw30BWLEv0cmFiYiIXJjCjZzNww/CmpmPD5zumtK4GxERqQgUbuTcHONuVtKpntk1pXE3IiJSESjcyLnV6mjexy6nQ1QgLhbYl5BOfHKmc+sSERG5AIUbObdTLTfxm/F3yaJFDX8Alu9T15SIiJRvCjdybv41wL82GHlwaA2dTo270WR+IiJSzincyPnVPtU1tcIx7uafvccLvXxfRETE2RRu5Pwc60wtp31kNVxdLBxKOsmBxJPOrUtERKQQCjdyfqfG3Rxcg5cV2tQOADTuRkREyjeFGzm/kCZg84fsNDiy5fS4G10SLiIi5ZjCjZyfi8vpcTfRS+lUV+NuRESk/FO4kcLV62He71lAm9oB2FxdOJaaxd5j6c6tS0RE5DwUbqRwDXqZ9/uX42HPoF1kNQCWaykGEREppxRupHBB9aBaFNhzYN+SAl1TIiIi5ZHCjVxYg97m/Z4FjkHFy/cdx27XuBsRESl/FG7kwk51Te3+g5Y1/PB2t5KUkcOO+FTn1iUiInIOCjdyYZFdwdUDUg7ilriLDlGBAPyjcTciIlIOKdzIhbl5QuQV5uPd8x1LMSzXuBsRESmHFG6kaBxdUwvonD/uZmV0Irl5dicWJSIicjaFGyma+j3N+9gVNAkEf0830rJy2RKX4ty6RERE/kXhRoomqB4E1gV7DtaYpVxeV+NuRESkfFK4kaI7dUn47gWO+W407kZERMobhRspuvr54272/EHn/EHFq2MSycrNc2JRIiIiBSncSNFFdsm/JPwQDYgl2MedzBw7Gw8kO7syERERB4UbKTo3T4i6EgDLnj+43LEUg8bdiIhI+aFwI8VToGvKvCRc60yJiEh5onAjxdPg1CXhy+lSyx2A9bEnSMnMcWJRIiIipyncSPEE1oWg+mDPpXbSShqE+pCTZzB/6xFnVyYiIgIo3EhJ5HdNWfb8Qf9WEQDM3hTnzIpEREQcFG6k+E51Te3+g+tahAPw9+4EEtOznViUiIiISeFGiq9OV3D1hNQ46tr30yzCj1y7wbwt8c6uTEREROFGSsDNw3FJOHsWOLqmft2orikREXE+hRspGccq4X9wbYvqAKyIPs7RlEwnFiUiIqJwIyVV//Ql4bW8crisdgCGAXM3H3ZuXSIiUuUp3EjJBEZBUAMw8mDfYq5rmd81tUnhRkREnEvhRkrO0TW1gGtbVsdigbX7T3DwRIZz6xIRkSpN4UZK7lTX1J4/CPO10TEqEIA5ar0REREnUriRkqvTJf+S8MNwbMfpq6Y0oZ+IiDiRwo2UnJsH1OlkPt67iH7Nq2N1sbDlUArRCenOrU1ERKoshRu5OHW7m/f7FhHo7U6X+uZK4bM1542IiDiJwo1cnHr54SZmGeRm07+lOeeNuqZERMRZFG7k4oQ2A69gyEmHg6vp3Swcd6sLu46ksTM+1dnViYhIFaRwIxfHxQXqXmU+3rcIf083ujUKAbQcg4iIOIfCjVy8U11T+xYDcF1+19TsTXEYhuGkokREpKpSuJGLd6rl5tBaOJlEzyZheLi5EHM8gy2HUpxamoiIVD0KN3Lx/GvmL8Vgh5i/8La50qNJGKCBxSIicukp3Ejp+FfXVP/8taZmb4zDblfXlIiIXDoKN1I6TnVN7V0EwFWNQvCxuRKXnMm62BPOq0tERKochRspHZFdwWKFxL2QFIuHm5XeTc2uqdlaa0pERC4hhRspHR7+ULOd+Ti/9eaaFuZVU/O3xuuqKRERuWQUbqT0OOa7WQxA1wbBeLpZiUvOZGucrpoSEZFLQ+FGSs+pdaail4DdjoeblSsbmmtNzd92xImFiYhIVeLUcLN06VL69+9PREQEFouFWbNmXfCYxYsXc9lll2Gz2ahfvz5ffvllmdcpRVSzHbj7QMZxiN8EQK+m4YDZNSUiInIpODXcpKen06pVKyZNmlSk/aOjo7n22mvp3r07GzZs4KGHHuLOO+/k999/L+NKpUisbubAYnB0TfVoHIqLBXbEp3IgMcN5tYmISJXh1HDTr18/XnrpJQYNGlSk/SdPnkxUVBRvvvkmTZo0YezYsdx44428/fbbZVypFNmprql95qDiat7utI8MBGCBuqZEROQSqFBjbpYvX07Pnj0LbOvTpw/Lly8/7zFZWVmkpKQUuEkZOjWZ3/7lkHMSgF75l4TP36auKRERKXsVKtzEx8cTFhZWYFtYWBgpKSmcPHnynMdMnDgRf39/x61WrVqXotSqK7gh+FaHvCyIXQFA7/xxN6tjTpCUke3M6kREpAqoUOGmJCZMmEBycrLjduDAAWeXVLlZLGd1TdUO8qJxuC95doM/dxx1YnEiIlIVVKhwEx4ezpEjBcdtHDlyBD8/Pzw9Pc95jM1mw8/Pr8BNytiprqn8yfzgjK6prRp3IyIiZatChZtOnTqxcOHCAtsWLFhAp06dnFSRnNOpyfziN0H6ceB019TS3cfIzMlzUmEiIlIVODXcpKWlsWHDBjZs2ACYl3pv2LCB2NhYwOxSGjFihGP/e+65h3379vHYY4+xY8cOPvzwQ6ZPn864ceOcUb6cj08ohDYzH0cvBqB5DT+q+3uQkZ3HP3sTnFebiIhUek4NN2vWrKFNmza0adMGgPHjx9OmTRueeeYZAA4fPuwIOgBRUVHMmTOHBQsW0KpVK958800+/fRT+vTp45T6pRD/6pqyWCz0bKKuKRERKXsWo4qtaJiSkoK/vz/Jyckaf1OWdv8B3w4G/1rw0GawWPhr9zFu+2wVwT42Vj3ZAxcXi7OrFBGRCqI4398VasyNVCB1OoHVHZIPQOI+ADpGBeFrcyUhLYv1B5KcW5+IiFRaCjdSNty9oVZH8/HeP81Nri50bxwKaEI/EREpOwo3UnZOXTW1/RfHplOXhGspBhERKSsKN1J2Wg4BiwtEL4Uj2wC4qlEIblYL+46ls+dompMLFBGRykjhRspOQG1ofK35eNXHAPh6uNGpXjCg1hsRESkbCjdStjreY95vnAYZicCZXVMadyMiIqVP4UbKVp0uENYCck/Cuq8B6JU/3836A0kcTc10ZnUiIlIJKdxI2bJY4PL81ptVUyAvl3B/D1rV9McwYOF2LaQpIiKlS+FGyl7zG8ErCFIOws45gK6aEhGRsqNwI2XPzQPa3m4+XjEZgF75C2n+vSeB9KxcZ1UmIiKVkMKNXBrt7wAXV4j9Bw5vpGGYD3WCvMjOtbNsjxbSFBGR0qNwI5eGXwQ0HWA+XvkxFouFrvXNS8JX7Et0YmEiIlLZKNzIpdPxXvN+8wxIO8bldYMAWLHvuBOLEhGRykbhRi6dmu0g4jLIy4a1X9KxbiAA2+NTSMrIdnJxIiJSWSjcyKVjscDl+a03qz8l1MtKvRBvDANWRatrSkRESofCjVxaTQeCTxikxcO2n8/omlK4ERGR0qFwI5eWqzu0u8N8vHKyxt2IiEipU7iRS6/d7WB1h4Or6eIZA5jjbpIzcpxbl4iIVAoKN3Lp+YRC88EABG7+grqnxt3EqGtKREQunsKNOEfH/5j3W3+iVy0DUNeUiIiUDoUbcY6INlCjHdhzuMZ9PaBwIyIipUPhRpynYR8AGqWtAWDbYY27ERGRi6dwI85TtzsAHgf/pn6wh8bdiIhIqVC4EeeJaAMe/pCZzA3hxwB1TYmIyMVTuBHnsbpC1JUAdHfbCijciIjIxVO4EefK75qql7Ia0LgbERG5eAo34lz1zHDjfngNTYNdNO5GREQumsKNOFdgXQioA/YchobEAuqaEhGRi6NwI86X33rT1WUzoHAjIiIXR+FGnC9/3E2dpFVA/ribkxp3IyIiJaNwI84XdSVgwfX4TjoEZWIYsDpa425ERKRkShRuvvrqK+bMmeP4+bHHHiMgIIDOnTuzf//+UitOqgivQHPOG+CmansBdU2JiEjJlSjcvPzyy3h6egKwfPlyJk2axGuvvUZwcDDjxo0r1QKlisgfd3M5GwBYEa1wIyIiJVOicHPgwAHq168PwKxZsxg8eDB33303EydO5K+//irVAqWKyB93E5G4Egt2tsZp3I2IiJRMicKNj48Px4+b/2c9f/58evXqBYCHhwcnT54sveqk6qjVAdy8sGYk0KNagsbdiIhIiZUo3PTq1Ys777yTO++8k127dnHNNdcAsHXrViIjI0uzPqkqXG0Q2RWAGwJ2ARp3IyIiJVOicDNp0iQ6derEsWPH+OGHHwgKCgJg7dq1DBs2rFQLlCokv2uqXd5GQONuRESkZCyGYRjOLuJSSklJwd/fn+TkZPz8/Jxdjpzp6Hb48HIMqweN0yeTbXFnwzO98fd0c3ZlIiLiZMX5/i5Ry828efP4+++/HT9PmjSJ1q1bc8stt3DixImSvKQIhDQG3+pY8jK5LiBW425ERKREShRuHn30UVJSUgDYvHkzDz/8MNdccw3R0dGMHz++VAuUKsRigbpXAdDfdyegcTciIlJ8JQo30dHRNG3aFIAffviB6667jpdffplJkybx22+/lWqBUsXkj7tpnb0egOUKNyIiUkwlCjfu7u5kZGQA8Mcff9C7d28AAgMDHS06IiWS33Ljn7ydQEsKW+NSiEvS9AIiIlJ0JQo3Xbt2Zfz48bz44ousWrWKa6+9FoBdu3ZRs2bNUi1QqhjfMAhthgWD28LMpTzmbDrs5KJERKQiKVG4+eCDD3B1dWXmzJl89NFH1KhRA4DffvuNvn37lmqBUgXlL8VwnfcOAGZvinNmNSIiUsHoUnApf3b/Ad8OJs+3Bg0SXsNuWFj6aHdqB3k5uzIREXGS4nx/u5b0TfLy8pg1axbbt28HoFmzZlx//fVYrdaSvqSIqU5nsLpjTT3EDbVPMnO/F79uimNM9/rOrkxERCqAEnVL7dmzhyZNmjBixAh+/PFHfvzxR2699VaaNWvG3r17S7tGqWrcvaD25QAMCzL/Pc3WuBsRESmiEoWbBx54gHr16nHgwAHWrVvHunXriI2NJSoqigceeKC0a5SqKP+S8JZpf+Pvksn2wynsPZbm5KJERKQiKNGYG29vb1asWEGLFi0KbN+4cSNdunQhLa38fglpzE0FEbcBPukGQJbFxoLc1tDsRq4bPALcPJxamoiIXHplvvyCzWYjNTX1rO1paWm4u7uX5CVFCqreCnq/BEH1sRlZXGddyXU7HsV4owHMug/2/AF5uc6uUkREyqEShZvrrruOu+++m5UrV2IYBoZhsGLFCu655x6uv/760q5RqiKLBTrfD2PXkDZqIZ/mXUecEYglKwU2fAv/GwxvNYbYFc6uVEREypkShZv33nuPevXq0alTJzw8PPDw8KBz587Ur1+fd955p1ivNWnSJCIjI/Hw8KBjx46sWrWq0P3feecdGjVqhKenJ7Vq1WLcuHFkZmaW5GNIRWCx4BPZjpUNxtEl6z2+b/YxtLsDvIIg/RjMf8rZFYqISDlTokvBAwIC+Pnnn9mzZ4/jUvAmTZpQv37xLtWdNm0a48ePZ/LkyXTs2JF33nmHPn36sHPnTkJDQ8/a/7vvvuOJJ57g888/p3PnzuzatYtRo0ZhsVh46623SvJRpIK4rmV1Fmw7wscxYdz8yJtYrnoC3moCB1fDka0Q1szZJYqISDlR5AHFxVntu6hBo2PHjrRv354PPvgAALvdTq1atbj//vt54oknztp/7NixbN++nYULFzq2Pfzww6xcuZK///67SO+pAcUVU3pWLm1fWkBmjp3Z93eleQ1/mHYbbP8FOvwHrnnN2SWKiEgZKpNJ/NavX1+k/SwWS5H2y87OZu3atUyYMMGxzcXFhZ49e7J8+fJzHtO5c2f+97//sWrVKjp06MC+ffuYO3cut91223nfJysri6ysLMfPWtizYvK2uXJ141Dmbo7n101xZrhpO9IMN5umQq/nwc3T2WWKiEg5UORws2jRolJ944SEBPLy8ggLCyuwPSwsjB07dpzzmFtuuYWEhAS6du2KYRjk5uZyzz338OSTT573fSZOnMjzzz9fqrWLc1zXMoK5m+OZvfEwT/RtjKXu1eBfG5JjYdvP0OpmZ5coIiLlQIkGFDvL4sWLefnll/nwww9Zt24dP/74I3PmzOHFF1887zETJkwgOTnZcTtw4MAlrFhKU/dGoXi7WzmUdJL1B5LAxQUuG2E+ufYrp9YmIiLlh9PCTXBwMFarlSNHjhTYfuTIEcLDw895zNNPP81tt93GnXfeSYsWLRg0aBAvv/wyEydOxG63n/MYm82Gn59fgZtUTJ7uVno2NVv6Zm/MX46hzXCwuEDsP3BslxOrExGR8sJp4cbd3Z22bdsWGBxst9tZuHAhnTp1OucxGRkZuLgULPnUQp1VbHHzKuu6lhEAzN18GLvdAL8IaNDHfHKdWm9ERMTJ3VLjx49nypQpfPXVV2zfvp17772X9PR0br/9dgBGjBhRYMBx//79+eijj5g6dSrR0dEsWLCAp59+mv79+2s18iriyobB+Hq4Ep+SyZr9J8yNbUeZ9xu+g9ys8x4rIiJVQ4nmuSktQ4cO5dixYzzzzDPEx8fTunVr5s2b5xhkHBsbW6Cl5qmnnsJisfDUU09x6NAhQkJC6N+/P//973+d9RHkErO5WundNJwf1h3k141xdIgKhPo9wTcCUuNgx2xoPtjZZYqIiBOVaOHMikzz3FR8i3ceZdQXqwn2cWfFhB64Wl3gz//C0tcg6koY+auzSxQRkVJW5gtnijhTl/rBVPNyIyEtm5XRiebGy24DLBC9FBL3ObU+ERFxLoUbqXDcrC70bW5eUTd9Tf6l/QG1oX4P8/G6r51UmYiIlAcKN1IhDe9YB4DZmw5zIDHD3HjZSPN+/beQl+OkykRExNkUbqRCal7DnysaBJNnN/j0r/xuqEb9wDsU0o/Czt+cW6CIiDiNwo1UWPd2qwfA1NUHSEjLAqubOakfaM4bEZEqTOFGKqxO9YJoVdOfrFw7X/0TY248tRzDnoVwYr/TahMREedRuJEKy2KxcE9+683Xy/eTlpULgXUhqhtgwPr/ObdAERFxCoUbqdB6NwunbrA3ySdzmLoq1tzY9tTA4v9BXq7zihMREadQuJEKzepi4T/d6gLw6V/RZOfaofF14BVkzli8Z4GTKxQRkUtN4UYqvIFtahDmZyM+JZNZGw6Bqw1aDTOfXKuBxSIiVY3CjVR4Nlcrd3SNAmDykr3mauGn5rzZ/TukxDmxOhERudQUbqRSGNahNn4eruw7ls78bUcgpCHU7gyG3ZzUT0REqgyFG6kUfD3cuK2TOWvxR0v2YhjG6YHF674Gu92J1YmIyKWkcCOVxqjOUdhcXdh4IIkV+xKh6QDw8IfkWNj3p7PLExGRS0ThRiqNEF8bQ9rVAszWG9w8oeXN5pMaWCwiUmUo3EilctcVdXGxwNJdx9hyKPl019TOuZB21LnFiYjIJaFwI5VK7SAvrmsZAZhXThHWDGq0A3subPjOydWJiMiloHAjlc6pJRnmbj7M3mNpBQcWG4YTKxMRkUtB4UYqnaYRfvRoHIrdgNfm7YBmN4C7DyTuhZi/nV2eiIiUMYUbqZSe6NcYFwv8vvUIq+KyocWN5hPrNLBYRKSyU7iRSqlBmC83d6gNwH/nbMPeJr9ratvPkJHoxMpERKSsKdxIpfVQzwZ4u1vZeDCZ2QlhEN4S8rJh41RnlyYiImVI4UYqrVBfD8fg4lfn7SSn9QjziXVfaWCxiEglpnAjldqdV9QlzM/GoaST/C+jPbh5wbEdcGCVs0sTEZEyonAjlZqnu5VHejcC4K2lR8hqdL35hAYWi4hUWgo3UundcFlNmlT3IzUzl//ldDc3bvkRMpOdW5iIiJQJhRup9KwuFv7vmiYATNzsS3ZgQ8g9CZtnOLkyEREpCwo3UiV0bRDMVY1CyLXDLEsvc+PqzzWwWESkElK4kSpjQr8muFjgpUOtyHP1hqNbYfcCZ5clIiKlTOFGqoxG4b4MbV+LFHz4xa2vufHvt5xblIiIlDqFG6lSxvVsiJe7lYknribPxQ1il8P+f5xdloiIlCKFG6lSQv08+M+V9ThKNX615F859debzi1KRERKlcKNVDl3XRlFuJ8Hb2X0w44L7PkDDm8s+gv88z7MmwB2e9kVKSIiJaZwI1WOl7srj/drRKwRxlyjk7nxryKOvdnyI8x/ClZ8CPuXlV2RIiJSYgo3UiUNaFWD1rUCeD+7v7lh28+QsKfwg5Ji4deHTv+8a16Z1SciIiWncCNVkouLhWf7N2WnUZsFeZcBBix7+/wH5OXCD3dBVjJ4BJjbdv1+KUoVEZFiUriRKqtN7WoMalODD3MHAGBsnArJB8+9819vwoEV4O4LI38FF1c4vhuO772EFYuISFEo3EiV9ljfRuxwbczyvKZY7Lnwzwdn7xS7Apa8Yj6+9k2o3hLqdDF/VuuNiEi5o3AjVVp1f0/u6VaPSXn5rTdrv4T0hNM7ZCab3VGGHVoMgVZDze0N8ycB1LgbEZFyR+FGqry7r6zLPp92bLTXxZJ7ElZONp8wDJg9DpJjIaAOXPvG6YMa9jHv9y+DzJRLX7SIiJyXwo1UeZ7uVp64tikf5l4PgH3lx2Zg2TgVtvwAFisM/hQ8/E8fFFQPghqAPRf2LnRS5SIici4KNyJA/5bVSazZiz32CFyyUmDBMzD3EfPJqyZArQ5nH3Sq9UbjbkREyhWFGxHAYrHw9PXN+Si/9Ya1X0B2GtTuDFeMP/dBp8bd7J4P9rxLU6iIiFyQwo1IvpY1A7C2HsJBIxgAw8MfbvgEXKznPqD25WZXVcZxOLT2ElYqIiKFUbgROcPDfZvxujGCQ0YQy1v+FwJqnX9nqxvU72k+1lVTIiLlhsKNyBnC/DxodPVwumS9z9i14SSmZxd+gOOScI27EREpLxRuRP7lzq51aRzuS2J6Ni/N2Vb4zvV7gsUFjmyBpAOXpkARESmUwo3Iv7i7ujDxhhZYLPDjukMs3XXs/Dt7BUKtjubj3Wq9EREpDxRuRM6hTe1qjOocCcD/zdpMRnbu+XfWJeEiIuWKwo3IeTzSuxE1Ajw5kHiStxfsOv+Op8bd7FsC2emXpjgRETkvhRuR8/C2ufLSoOYAfPZ3NJsPJp97x5DGEFAb8rIgeuklrFBERM7F6eFm0qRJREZG4uHhQceOHVm1alWh+yclJTFmzBiqV6+OzWajYcOGzJ079xJVK1VN90ahXN8qArsBj/+wiZw8+9k7WSxaSFNEpBxxariZNm0a48eP59lnn2XdunW0atWKPn36cPTo0XPun52dTa9evYiJiWHmzJns3LmTKVOmUKNGjUtcuVQlz/RvSoCXG9sOp/DZ39Hn3unMcTeGcemKExGRszg13Lz11lvcdddd3H777TRt2pTJkyfj5eXF559/fs79P//8cxITE5k1axZdunQhMjKSbt260apVq0tcuVQlwT42nrq2KQBvL9hFTMI5xtXU6Qpu3pB6GOI3Ff6C9nO0/oiISKlxWrjJzs5m7dq19OzZ83QxLi707NmT5cuXn/OYX375hU6dOjFmzBjCwsJo3rw5L7/8Mnl551/XJysri5SUlAI3keIafFkNutYPJivXzpM/bcb4d+uMmwfU624+Pt9VU4fWwTeD4OUIWPNF2RYsIlKFOS3cJCQkkJeXR1hYWIHtYWFhxMfHn/OYffv2MXPmTPLy8pg7dy5PP/00b775Ji+99NJ532fixIn4+/s7brVqFTKdvsh5WCwWXh7UAg83F/7Ze5wZaw+evZOja+pf426O7YRpt8GU7rD3T8g9CbMfgr/eKvO6RUSqIqcPKC4Ou91OaGgon3zyCW3btmXo0KH83//9H5MnTz7vMRMmTCA5OdlxO3BAs8hKydQO8mJ8r4YAvDR7G9vi/tUK2KC3eX9oLaQdhaRYmDUGPrwctv8CWKDlzXD5feZ+C5+HBc9ojI6ISClzddYbBwcHY7VaOXLkSIHtR44cITw8/JzHVK9eHTc3N6zW06s0N2nShPj4eLKzs3F3dz/rGJvNhs1mK93ipcoa3SWK37bEsz42iZs/Wc6XoztwWe1q5pO+4RDRBuLWw/SRcGgN5OWvTdXoWrj6KQhrenrfBc/AsnfhZBJc9/b5Vx8XEZFicVrLjbu7O23btmXhwoWObXa7nYULF9KpU6dzHtOlSxf27NmD/YwBmbt27aJ69ernDDYipc3V6sKXt3egXZ1qpGTmcuunK1m2J+H0DqcuCY/9xww2UVfCnQth2Hengw1Alweh/3vmulTrvoKZoyH3Aot0iohIkTi1W2r8+PFMmTKFr776iu3bt3PvvfeSnp7O7bffDsCIESOYMGGCY/97772XxMREHnzwQXbt2sWcOXN4+eWXGTNmjLM+glRB/p5ufH1HB65oEExGdh63f7GaBdvyWyBb3Qw+4VCjHdw2C0b+CjXbnfuF2o6EG78AFzfYNgu+v1kzHIuIlAKLcdZlH5fWBx98wOuvv058fDytW7fmvffeo2NHcyHCq666isjISL788kvH/suXL2fcuHFs2LCBGjVqcMcdd/D4448X6KoqTEpKCv7+/iQnJ+Pn51cWH0mqiKzcPB74fj2/bz2C1cXCW0NaMaB1CeZc2rMQpt0KORlQ63K4ZRp4BpR6vSIiFVlxvr+dHm4uNYUbKU25eXYe+2ETP647hMUCLw5ozq2X1yn+C8WuhO9ugsxkCG8Jo+eBu3fpF1xSR7ZCzDJocaO5ErqIyCVWnO/vCnW1lEh542p14Y0bWzGiUx0MA56atYWPFu8t/gvV7gij5oJ3iDkJ4LwJFz7mUrHb4fth8Nuj8F4bWD5J44NEpFxTuBG5SC4uFp6/vhljutcD4NV5O3jltx3Y7cVsFA1vDoM/BSzmIOOtP5V+sSURvQSS9puPM5Pg9yfhw46w7Rddxi4i5ZLCjUgpsFgsPNqnMY/3bQzA5CV7GT99A9m5xVxqoe5V0HWc+fiXB825cpxt/TfmfdvbzSu8fMIgcR9Mvw2+uMac10dEpBxRuBEpRfdeVY/XbmyJq4uFWRviGPn5KpJP5hTvRbo/aV5tlZUMP9wJebllU2xRZCTC9tnm47ajzCu87l8HVz4Grp7mJe9TrjbrTD7kvDpFRM6gcCNSyoa0q8Xno9rj7W5l+b7j3DT5H+KSThb9BaxucONnYPODAythyatlV+yFbJ4BeVkQ3gIiWpvbbD5w9f/B/Wuh1bDT+319PdjPv86biMilonAjUgaubBjC9Hs6EeprY9eRNAZ9uIytcclFf4FqkeasxQBLX4fov8qkzkIZBqz72nzcZsTZz/vXgEGT4e4l4OEPx/dAzN+XtkYRkXNQuBEpI80i/PlpTBcahvlwJCWLoR+v4K/dx4r+Ai1uhNa3Agb8eLfZRXQpxa2HI1vAaoOWN51/v4jW0GyQ+XjTtEtSmohIYRRuRMpQjQBPZtzTmU51g0jLyuX2L1YzY00xFm/t9yoE1YfUOPh57KW9OunUQOIm/cGzWuH7thxq3m/7BbIzyrYuEZELULgRKWP+nm58Obo9A1tHkGs3eHTmJt5buJsizZ9p84EbPwerO+ycA6s/LfuCwQwom2eajy+77cL717ocAmpDdirsnFu2tYmIXIDCjcglYHO18vbQ1tx3lTkXzlsLdvHkT5vJzSvCpeLVW0HP583Hv/8fxG8uw0rzbf8FslIgoA5EXnnh/V1coMUQ8/Gm6WVbm4jIBSjciFwiFouFx/o25sWBzXGxwPerDvCfb9aSkV2ES70vvxca9DavXPqsD6yaYs4cXFbW5XdJtbnVDC5Fcapras8fkJ5Q+L4iImVI4UbkErvt8jp8dGtbbK4uLNxxlFumrOR4WlbhB1ksMHAy1O4MOekw9xH4qr85mV5pO74X9v8NWKD1LUU/LqQhRLQBIw+2/FD6dZ2LPQ8Ob9RMySJSgMKNiBP0aRbOd3d1JMDLjQ0Hkhj80T/sP55e+EHeQTBqDvR7Hdy8zADyURdY8VHptuKs/595X78H+Ncs3rEtbzbvL9VVU/MmwMdXwl9vXJr3E5EKQeFGxEna1gnkh3s7U7OaJzHHMxj80T9sOphU+EEuLtDxbrj3H4i8AnIyYN4T8OU1ZovLxcrLhQ3fmY/bFGEg8b81HwwWq7kkQ8Lui6+nMEe2weop5uOlb2qGZBFxULgRcaJ6IT78eF9nmkX4kZCWzc2frGDRjqMXPjAwCkb8Ate+Be4+ELscPuoMf78NidEl76bZ8wekxYNXEDS6pvjH+4SYLT5QtgOLDQPm/x8Y+S1WuSdh4Qtl934iUqEo3Ig4WaivB9P+04krGgSTkZ3H7V+u5smfNpOSeYE1qVxcoP0dcN9yc8HN3Ez44zl4rzW8Xh++GwpLXoe9f0JmEWdHPjUjcath4Opesg90amDxpmllNxZmzx/m57K6m5fKA2yaqkU8RQRQuBEpF3xsrnw+qj23Xl4bgO9WxtLzzSXM23L4wgcH1IbbZsH1H0CNtuDiBhkJsGseLHoJvhkEr9SGDzrA3EfNmYfPFTpSj5jHQMm6pE5pdA24+0LSfnNtrNKWl2NeEg/Q8T9mV9ipsT7zntTgYhFRuBEpL9ysLrw0sAXf33U5UcHeHE3N4p7/rePur9cQn5xZ+MEWiznZ3l1/woSDcMcf0PcVaH6jOVcNQMJOWPUJfHIVTO4Kyz8seMn2xu/NK51qtofQxiX/IO5e0PT6/NecWvLXOZ+1X5qfxSsIrnjE3NbjGXOV8gMrYNus0n9PEalQLEaRpkmtPFJSUvD39yc5ORk/Pz9nlyNyTpk5eXzw5x4mL9lLrt3Ax+bK430bMbxjHVxcLMV/wbRjcHCVeYn29tnmfDlgtvI07GPOZzP/aTi+G/q/B21HXtwH2LcYvh4AHgHwyC5wtV3c651y8gS8dxmcTIRr3oAOd51+btFEWPKK2ZI1ZjW4eZTOe4pIuVCc72+FG5FybEd8Ck/8sJkNB5IAaFunGq8Obkn9UJ+Sv+jJE+bSChu+NbuozuTmDY/sBJtvyV8fzPln3m5urok19H/m+lTnrScJMo5DUL0Lv+7v/wfLP4CQxnDPMrC6nn4uOx3ebwuph6Hnc9B13MV9BhEpV4rz/a1uKZFyrHG4Hz/c25nnr2+Gt7uVtftPcP0Hf/PT+oMlf1HPamaLx92LzUvKLx8DXsHmc61vufhgA+BiNVc1h/PPeWMYZsh6rzW8fxnMfwpys8//msf3wsqPzce9/1sw2AC4e0OPZ83HS9+EtCJcdSYilZJabkQqiLikkzwyYyP/7D0OwM3ta/Hc9c3wcLNe/IvnZsPRbRDatORXSf3bka3m5elWd7Nr6syVxdOOwZxxsP3XgsdUbwWDP4PgBme/3tThsGM21O8Jt55nBmS7HT692myRajsK+r9bOp9FRJxOLTcilVBEgCff3NGRB3s0wGKBqasPMHDSMvYdS7v4F3d1h4jWpRdsAMKaQVhzyMuGrbNOb9/6E3zY0Qw2Lq5w1ZMw5Gsz/BzeaM44vO7rglc9Rf9lBhuL1Wy1OR8XF+jzsvl43ddmwBKRKkfhRqQCsbpYGNerId+M7kiwjzs74lPp//7f/LIxztmlnduZc96kH4cZo8xbxnEIawF3LYKrHoemA8wusqgrzVmXf7kfZow0xwfZ8+D3J83XaXf7ha/kqtPZfD3Dbo7RqVqN0yKCuqWcXY5IiR1JyeSB79ezMjoRgOEda/P0dU1Lp5uqtKTEwVtNAcO8dDvjuNn6cuUj5mXc/24pstvhn/fgzxfBngt+Nc3Lyld8CDZ/eGAdeAdf+H0To2FSB7PV6Jbp5hVhIlKhqVtKpAoI8/Pg2zs7MrZ7fQC+XRnLDR/+w7I9CZSb/2fxi4C63czHGcfNMT13LYTuT567C8zFBbo+BHfMh8C6kHLQDDZgBqKiBBswl6e4/F7z8bwJWndKpIpRy41IJbBk1zHGTdtAYrp5tVGrWgHcd1U9ejUJK9m8OKVp/z9mN1PTAdDt8aLPeZOVBr89Dhv+B0H1zW6r4syXk5kCH7SDtCNg84O+E6H1cHPCQxGpcDTPTSEUbqSyOpqSyYeL9/L9qliycs0FJRuE+nDvVfXo3yoCN2sFbaiN32K2AHkFFv/YhN3w0z1waI35c4Pe5hVUfhGlW6OIlDmFm0Io3Ehll5CWxed/R/PN8v2kZuUCULOaJ/+5si43tatVvsbkXAr2PPjnfVj0sjkzs80f+r1iLg7qrFaclDiI3wz1epw9X4+InJPCTSEUbqSqSMnM4X8r9vPZX9Ecz++uqlnNk3dvbk3bOiVoBanoju6AWfdC3Drz54Z94bp3wK/6pashMwWWvWvOspybaY5B6vcaRF1x6WqoqE7sB58wLatRhSncFELhRqqazJw8pq85wEeL93I4OdO8nLxnA+69qj5WZ4/HudTycs2rsRZPNK+k8vCHxv3BM8B8/O+b+6llLgzz0nLDyH+cv80n1FzLqijvu+4r833Tj5nbrO5mDQDNboDeL4F/jVL/yBWeYcCS12Dxy+Yg8yHfQHhzZ1clTqBwUwiFG6mqUjNzeGrWFn7eYM6J06luEG8PbU24fxX8P+Gj282xOIc3XPxrBdaFelebt8grwOOMvyuGAbt+hwVPQ8Ku/P3rQa8XzPl4Fv0X1nxuBic3L/OKsE5jS2+h0YouLwdmj4P135ze5uoJ/d+BVjc7rSxxDoWbQijcSFVmGAY/rDvEMz9vISM7j2pebrx+Yyt6Ng1zdmmXXl4ubJsFJ2IgMxmyUsz7M29Z+bM/W1zyx+dYzrjHHDtjzz39mhYr1OpgBp2w5uZl7DF/mc95BsJVE8yJCK1up485vAnmPgoHVpg/B9aFvq9Cw95lfgrKtaw0c8LHPQvM89/rBdi7CPYuNJ9vd4d5BVxRgmBSrPm7UctYhaZwUwiFGxHYdyyN+79fz9a4FABGdY7kiX6Nq95g44uVmQIxf8PeP81b4t6z97HazDl3rhhvdnWdi2HApulmC0/aEXNb9VYQ2sxcZyu4oXlfLap0l8g48/3j1sGaLyB6KdRoCy2HmAOei/N+2eng6mEunHoxUo/AdzeZy3G4esKNn0Pja8zB4UteNW8ANdrBkK/Av+bZr5Fz0lziY93XZsB09YABk04v6CoVjsJNIRRuRExZuXm8Nm8nn/0dDUCT6n6M6V6PDpGBhPpVwa6q0nAiJr914U+I2wB1OsHVTxVtXA6YYWnpa7Dio4ItQqdYrFAtMj/oRJpf6v61IKCWee8dUrwrwLJSYfMMM9TEbzr7ec9AaDbIDDq1Op792ukJsH8ZxCwzQ97RreATDm1HwmUjS9ZSkrAb/neD2driFWTOMF2zXcF9ds2HH+80W9e8gszwU/cq87nDG2HdN7B5uvn8v135mNmC5lJBp0aowhRuCqFwI1LQoh1HeXjGRscEgAC1A71oHxlIh6hqtI8MJCrYG4smv7t0kg6Yc/Mk7DHH6iTsMr/0c9ILP87VIz/w1DwdfM587BcBbp5m8Fr7BWyeCdn5XW9WGzQbCE2uNyde3DLzdCsSQEAdaHEThDWF2BX5YWbb+WuxWKFRP2h/B0RdVbQwEbsSvh9qrilWLcpc/T2o3rn3TYyG6beZl9RbXMxV4A+tNcPNKf61oM2t5vic1Z+Zg8nB/IyDJoO794VrknJD4aYQCjciZzuaksnkJftYse842+NTzlprMtjHRseoQHo3C+PqxqH4erid+4Wk7BgGpB4+HXSSD5ghKPmg+Tg1nvzLuArnEQCZSad/DmpgjgNqNazgRIn2PIheYnaXbf/1dAj6t9CmUKcLRHY1xxvFLofVn8P+v0/vE1jXHCPT+hZzjMzJJDPAZCadfpwSB3+/ZV4iX6MtDJsGPiGFf5ackzDnEXMW61Os7tD4Wmhzm9mac2YX2fpv4dcHwZ5jdvvd/H3pjcMxDHPcVtpRMxSmHTVvGcfN1qUzQ6ZXoGbKLgGFm0Io3IgULiUzh7X7T7A6OpE1MSfYcDCJ7PwZjwHcrS50bRBM3+bh9GoSRjXvMhgDIsWXmw0ph06HnpRD+cHnjNuplh8XN3NB0ra3m6HkQl+02Rmwc67Z0pN62AwxkV3NUHO+9b6ObjevBNs41fzSL6qG/eDGz4reqmIYsP5/Zvdaw77mSvTeQefff/9ymDbcDB0+YWbAqdm26PWdkpFohr7tv8CxXWagycsq2rFuXqfDTmA9qN/TXIPNzbPo759z0mw5y84w3zc3/5aXffre1QOqt4SQJmUzVusSU7gphMKNSPFk5uSx+VAyi3ce5bct8ew7drprxOpioVPdIPo2D6df83CCfHQJc7llGGZLSfKhki9nURJZaWYX1+pPzS4kABdX8KxmtiJ5BuTfVzNbUzreU/azNp+Ige+HmeGgOAONMxJhxxzY+hPsWwxG3tn72PzNFiefMHMeJM9qZpA6FTDP7Oo7k6unGXAa9oEGfc5uUcpKg4OrzPFN+5eZXXB52ed+rX+zukNYM6jeGiJam/ehTStc4FG4KYTCjUjJGYbB7qNp/LY5nt+2HGZHfKrjOXdXFwa2juD2LlE0qa7/tuRfDMP8knf1MFtlnN0tk5kCP94Fu+aZP4c0MVuhvIPB69R9kDlIOysFtv1sBpozB3qHtzAHXEdecTrMXKj1JSezYKta3DpzLqTkAwX3C29pBp28bDPQHN5w9iBz7xBz0LerzbxZbWZgcfUwA83JE+Zx5xpYbXU3Q6XFkj/VgcvpKQ8K/OyCOfXBv/bBMOchyss2p1XIy86/5ZjdfjXawe1zivMbuSCFm0Io3IiUnpiEdH7bEs/sTXGOy8oBOtcLYnSXKK5uHOr8VclFzseeB388d3qgcVGEtTAHXjcbdP7BzsVlGGYr0q55sHMeHFzNOcdP+dc2J3+M7GJ2CQbWvXBINAyzperwBnMgedz68wee0lSjHdy1sFRfUuGmEAo3IqXPMAzWxSbx+bJo5m2JJ89u/lmJDPJiVOdIbmxXCx+bFoiUcioxGpL2m5e2pydARoK5TEZ6gtnaZM8zJ1VsOgiC65d9PekJsHuBOWGhq0f+gO0uRZ9S4EIMw7zUPjstf1mR/KVFCtznnfHYzuklSE79jNn6Y3U3J6W0uptjuU49dvMqfOxTCSjcFELhRqRsHUo6ydfLY/h+ZSwpmWYzuq/NlT7543K6NgjG5qrJAkWkeBRuCqFwI3JpZGTn8sO6Q3zxdzT7Ek4PQvaxudK9cSj9modzVaMQvNzVoiMiF6ZwUwiFG5FLy243WBWTyLwt8czbEk98SqbjOQ83F7o1DOGaFtXp1TRMQUdEzkvhphAKNyLOY7cbbDiYxLwt5tVWBxJPOp7zcrfSp1k4A1pH0LV+MK5WTY8vIqcp3BRC4UakfDAMg22HU5i3JZ5fNsax/3iG47lgH3f6t4pgUJsatKjhr6UfREThpjAKNyLlj2EYrD+QxM/rD/HrpsMF1rmqG+JN/5YR9G0eTuNwXwUdkSpK4aYQCjci5VtOnp2/dh/jp/VxzN8aT9YZSz/UCfKib7Nw+jQPp3XNAM2hI1KFKNwUQuFGpOJIzcxh/tYjzNsaz9JdxwoEnTA/G32ahdO7aThNqvsS6O2uVh2RSkzhphAKNyIVU3pWLkt2HWPelnj+3HGUtKyCU9H72lypHeRFZJA3dc64bxjmq8U9RSqBChduJk2axOuvv058fDytWrXi/fffp0OHDhc8burUqQwbNowBAwYwa9asIr2Xwo1IxZeVm8c/e44zb0s8f+9JIC75JOf7S2Z1sdClfjADWkXQu1kYvh5ul7ZYESkVFSrcTJs2jREjRjB58mQ6duzIO++8w4wZM9i5cyehoaHnPS4mJoauXbtSt25dAgMDFW5EqrDMnDwOnsggJiGDmOPpxCZmEHM8g5gE8/EpNlcXejQJ5fpWNbiqUQgebpopWaSiqFDhpmPHjrRv354PPvgAALvdTq1atbj//vt54oknznlMXl4eV155JaNHj+avv/4iKSlJ4UZEzikmIZ1fNsYxa8Mh9h07PVOyr4cr/ZqHc0WDEJpF+BEZ5K0ByiLlWHG+v506HWh2djZr165lwoQJjm0uLi707NmT5cuXn/e4F154gdDQUO644w7++uuvQt8jKyuLrKwsx88pKSmF7C0ilU1ksDcP9GjA/VfXZ2tcCr9sjOOXDXHEp2Qyfc1Bpq85CIC3u5Um1f1oFuFHswh/mkb40TDMF3dXTSYoUtE4NdwkJCSQl5dHWFhYge1hYWHs2LHjnMf8/ffffPbZZ2zYsKFI7zFx4kSef/75iy1VRCo4i8VC8xr+NK/hzxN9G7M6JpG5mw+z4WAyOw6nkJ6dx5r9J1iz/4TjGHerCy1r+tMhKpD2UYG0rVMNP43ZESn3KtRCLqmpqdx2221MmTKF4ODgIh0zYcIExo8f7/g5JSWFWrVqlVWJIlIBuLhY6Fg3iI51gwDIzbOzLyGdrXHJbD2Uwta4FLbGJZOSmXs68Czei4sFGof70SEqkA5RgbSqFUB1Pw91Z4mUM04NN8HBwVitVo4cOVJg+5EjRwgPDz9r/7179xITE0P//v0d2+x2c94LV1dXdu7cSb169QocY7PZsNlsZVC9iFQWrlYXGob50jDMl0FtzG2GYRBzPIPV0YmsiklkdUwi+49nsO1wCtsOp/DlPzEAeLpZiQz2pm6IN3Xz76OCfagb4q1WHhEncWq4cXd3p23btixcuJCBAwcCZlhZuHAhY8eOPWv/xo0bs3nz5gLbnnrqKVJTU3n33XfVIiMipcZisRAV7E1UsDdD2pt/W46kZLI6JpFV0eZtz9E0Tubksf1wCtsPnz2eL8Lfg6YRfjSp7kfT6n40jfCjVjUvtfSIlDGnd0uNHz+ekSNH0q5dOzp06MA777xDeno6t99+OwAjRoygRo0aTJw4EQ8PD5o3b17g+ICAAICztouIlLYwPw+uaxnBdS0jAHOpiIMnTrLvWBr7jqWzLyGdfcfSiE5I52hqFnHJmcQlZ/LH9qOO1/CxudKkui+Nw/2IDPYmKtiLOkHe1KrmpcHLIqXE6eFm6NChHDt2jGeeeYb4+Hhat27NvHnzHIOMY2NjcXHRf/AiUv64WV0crTs9mhR8LiUzhx2HU9l+OIVtcWZX1s4jqaRl5bI65gSrY04U2N/FAhEBnkQGeRMZ7EXjcD8urxtEvRBvLSshUkxOn+fmUtM8NyLiLKcGLm+LM4PO/uPpjokHM7LzznlMsI+NjnUDuTwqkMvrBlE/1EdhR6qkCjWJ36WmcCMi5Y1hGBxLy2J//qzK0QnpbDiQxNr9JwosFgoQ5O1Oh6hAagd5EeJjI8TXRvAZ9wGebhrTI5WSwk0hFG5EpKLIys1j44FkVu47zoro46zdf4LMHHuhx7i6WAjxtVEnyIuoYG/qBHkTGeSd/9hLS05IhaVwUwiFGxGpqLJz7Ww6mMS62BPEJ2eRkJbFsdT8+7QskjJyLvga1f09aBbhxxUNQriiQTBRwRrTIxWDwk0hFG5EpLLKzrWTmJ5NXPJJ9h9PJzohI39cj9nVlZKZe9YxNQI8uaJBMFc0CKFL/SACvNydULnIhSncFELhRkSqqhPp2exLSGNV9An+2n2MNTEnyM473c1lsUCLGv5EBnkT7u9BuJ8H4f4ehOXfh/racLPq6lVxDoWbQijciIiYMrJzWRmdyN+7E/hr9zF2HUkrdH+LBcJ8PWgQ5kOjMF8ahvvSKMyXBmE+eLk7fWYRqeQUbgqhcCMicm7xyZms2Z/I4aRMDidnciQlk/iUTOLzH+faz/91USvQk0ZhvoT4euDtbsXL5lrw3t0VXw9XalXzIiLAA1e1AEkxFef7W1FbREQACPf3cMy+/G92u8Hx9GxiE9PZdSSNnfGp7Dpi3hLSsjmQeJIDiSeL9D5uVgu1qnkRGeztmLTw1BVdNQI8dSm7XDSFGxERuSCX/EvMQ3xttK0TWOC542lZ7DqSxu6jqSRl5JCenUtGVl7B++w8kjKyOXDiJNm55mSG+xLSz3ofL3cr9UN9aBBqdnc1DDMfK/RIcahbSkRELhm73eBwSiYxCenE5F/JFZM/eeH+4xkFBjifydPNSoCXG+6uLthcXfLvrbhbzcc+Hq40DvOleU1/mkf4E+Jru8SfTMqaxtwUQuFGRKR8ys2zE3M8gz1HU/NbgtLYfSSVfcfSzxt6zifcz4PmNfxpXsOPFjX8iQr2xsfmirfNFS93q+b2qYAUbgqhcCMiUrHk5tk5cOIkaZm5ZOflkZVrJyvXTvYZ9yfSs9kal8zmQ8nsS0insG82iwV83M2g422z4uPhRu1ALxqE+pi3MB/qBHnrsvdyRgOKRUSk0nDNX329qNKzctl2OIXNB5PZcsgMPPEpmaRn5WI3wDAgNSuX1KzTkxpuPJBU8D1dLEQGe9Mg1Ie6Id6E+3kQ4utBqJ+N0PyxRzZXLWVRXqnlRkREqgTDMDiZk0daVi7pWXmkZ+WSmplLSmYOMQnpZjfY0TT2HEkl/TyrtJ8pwMuNUF8bAZ7ueLpb8XK3Ou693F3xdLPibbMSEeBJZJC5tpevh9sl+KSVk1puRERE/sViseDl7mpOOOh7/v0Mw+BwcqYZdI6mEZOQztHUTI6mZnE0xVzPKzvPTlJGTpHW8zpTsI+7YzHTyCAvc3V3Xxuh+a1CvjZXjQcqBWq5ERERKQbDMEg+mcORlCyOpmaScjKXjOxcTubkcTI7j4zsPE7m5JGRbbYMHTxxkpiEdI6nZ1/wtT3cXBxhJ8THRqifjWAfsxvs9L07wT62KrfCu1puREREyojFYiHAy50AL3cahRfSBPQvKZk5xB7PIDoh3VzQ9HgGBxIzOJaWxbGULFKzcsnMsRd5QkRfD1f8PNzw9XDNvxV8XDfYm4FtalTJgdFquRERESkHTmbncSzVbA0y780usIS0f99nF/nS+IZhPrwwoDmX1w0q4+rLni4FL4TCjYiIVGSGYZByMpeE9CxSTuaQmpmbf8tx3CefzOHXTYdJzO8KG9SmBhOuaUyor4eTqy85hZtCKNyIiEhVkJSRzeu/7+S7VbEYBvjaXHm4d0NuvbxOhVy4VOGmEAo3IiJSlWw8kMTTP29h08FkAJpW9+PFgc1pW6eakysrHoWbQijciIhIVZNnN/h+VSyvzdtBSqY5eWHDMJ8CS1J421zxPjVzs7sVDzcrNjdzLS8PNyu2/PW8Tq3tZXWxOG6uLi759+bPHm7WUl/fS+GmEAo3IiJSVSWkZfHKbzuYufZgmb5Pm9oB/HRfl1J9TV0KLiIiImcJ9rHxxk2tGNu9PgdPnCQ9O5f0rFzSs80ZmzPyH2dkm5elZ+XmkZVjruGVmXNqXa88snPt5BkGeXkGuXaDPPuZ93Zsrs4d06NwIyIiUsVEBnsTWYz1uiqaijdcWkRERKQQCjciIiJSqSjciIiISKWicCMiIiKVisKNiIiIVCoKNyIiIlKpKNyIiIhIpaJwIyIiIpWKwo2IiIhUKgo3IiIiUqko3IiIiEilonAjIiIilYrCjYiIiFQqCjciIiJSqbg6u4BLzTAMAFJSUpxciYiIiBTVqe/tU9/jhaly4SY1NRWAWrVqObkSERERKa7U1FT8/f0L3cdiFCUCVSJ2u524uDh8fX2xWCyl+topKSnUqlWLAwcO4OfnV6qvXRnpfBWfzlnx6HwVn85Z8eh8Fc/FnC/DMEhNTSUiIgIXl8JH1VS5lhsXFxdq1qxZpu/h5+enf+TFoPNVfDpnxaPzVXw6Z8Wj81U8JT1fF2qxOUUDikVERKRSUbgRERGRSkXhphTZbDaeffZZbDabs0upEHS+ik/nrHh0vopP56x4dL6K51Kdryo3oFhEREQqN7XciIiISKWicCMiIiKVisKNiIiIVCoKNyIiIlKpKNyUkkmTJhEZGYmHhwcdO3Zk1apVzi6p3Fi6dCn9+/cnIiICi8XCrFmzCjxvGAbPPPMM1atXx9PTk549e7J7927nFFsOTJw4kfbt2+Pr60toaCgDBw5k586dBfbJzMxkzJgxBAUF4ePjw+DBgzly5IiTKnaujz76iJYtWzomBevUqRO//fab43mdq8K98sorWCwWHnroIcc2nbOCnnvuOSwWS4Fb48aNHc/rfJ3boUOHuPXWWwkKCsLT05MWLVqwZs0ax/Nl+bdf4aYUTJs2jfHjx/Pss8+ybt06WrVqRZ8+fTh69KizSysX0tPTadWqFZMmTTrn86+99hrvvfcekydPZuXKlXh7e9OnTx8yMzMvcaXlw5IlSxgzZgwrVqxgwYIF5OTk0Lt3b9LT0x37jBs3jl9//ZUZM2awZMkS4uLiuOGGG5xYtfPUrFmTV155hbVr17JmzRquvvpqBgwYwNatWwGdq8KsXr2ajz/+mJYtWxbYrnN2tmbNmnH48GHH7e+//3Y8p/N1thMnTtClSxfc3Nz47bff2LZtG2+++SbVqlVz7FOmf/sNuWgdOnQwxowZ4/g5Ly/PiIiIMCZOnOjEqsonwPjpp58cP9vtdiM8PNx4/fXXHduSkpIMm81mfP/9906osPw5evSoARhLliwxDMM8P25ubsaMGTMc+2zfvt0AjOXLlzurzHKlWrVqxqeffqpzVYjU1FSjQYMGxoIFC4xu3boZDz74oGEY+vd1Ls8++6zRqlWrcz6n83Vujz/+uNG1a9fzPl/Wf/vVcnORsrOzWbt2LT179nRsc3FxoWfPnixfvtyJlVUM0dHRxMfHFzh//v7+dOzYUecvX3JyMgCBgYEArF27lpycnALnrHHjxtSuXbvKn7O8vDymTp1Keno6nTp10rkqxJgxY7j22msLnBvQv6/z2b17NxEREdStW5fhw4cTGxsL6Hydzy+//EK7du246aabCA0NpU2bNkyZMsXxfFn/7Ve4uUgJCQnk5eURFhZWYHtYWBjx8fFOqqriOHWOdP7OzW6389BDD9GlSxeaN28OmOfM3d2dgICAAvtW5XO2efNmfHx8sNls3HPPPfz00080bdpU5+o8pk6dyrp165g4ceJZz+mcna1jx458+eWXzJs3j48++ojo6GiuuOIKUlNTdb7OY9++fXz00Uc0aNCA33//nXvvvZcHHniAr776Cij7v/1VblVwkYpkzJgxbNmypUD/vpytUaNGbNiwgeTkZGbOnMnIkSNZsmSJs8sqlw4cOMCDDz7IggUL8PDwcHY5FUK/fv0cj1u2bEnHjh2pU6cO06dPx9PT04mVlV92u5127drx8ssvA9CmTRu2bNnC5MmTGTlyZJm/v1puLlJwcDBWq/WskfFHjhwhPDzcSVVVHKfOkc7f2caOHcvs2bNZtGgRNWvWdGwPDw8nOzubpKSkAvtX5XPm7u5O/fr1adu2LRMnTqRVq1a8++67OlfnsHbtWo4ePcpll12Gq6srrq6uLFmyhPfeew9XV1fCwsJ0zi4gICCAhg0bsmfPHv0bO4/q1avTtGnTAtuaNGni6M4r67/9CjcXyd3dnbZt27Jw4ULHNrvdzsKFC+nUqZMTK6sYoqKiCA8PL3D+UlJSWLlyZZU9f4ZhMHbsWH766Sf+/PNPoqKiCjzftm1b3NzcCpyznTt3EhsbW2XP2b/Z7XaysrJ0rs6hR48ebN68mQ0bNjhu7dq1Y/jw4Y7HOmeFS0tLY+/evVSvXl3/xs6jS5cuZ01hsWvXLurUqQNcgr/9Fz0kWYypU6caNpvN+PLLL41t27YZd999txEQEGDEx8c7u7RyITU11Vi/fr2xfv16AzDeeustY/369cb+/fsNwzCMV155xQgICDB+/vlnY9OmTcaAAQOMqKgo4+TJk06u3Dnuvfdew9/f31i8eLFx+PBhxy0jI8Oxzz333GPUrl3b+PPPP401a9YYnTp1Mjp16uTEqp3niSeeMJYsWWJER0cbmzZtMp544gnDYrEY8+fPNwxD56oozrxayjB0zv7t4YcfNhYvXmxER0cby5YtM3r27GkEBwcbR48eNQxD5+tcVq1aZbi6uhr//e9/jd27dxvffvut4eXlZfzvf/9z7FOWf/sVbkrJ+++/b9SuXdtwd3c3OnToYKxYscLZJZUbixYtMoCzbiNHjjQMw7wk8OmnnzbCwsIMm81m9OjRw9i5c6dzi3aic50rwPjiiy8c+5w8edK47777jGrVqhleXl7GoEGDjMOHDzuvaCcaPXq0UadOHcPd3d0ICQkxevTo4Qg2hqFzVRT/Djc6ZwUNHTrUqF69uuHu7m7UqFHDGDp0qLFnzx7H8zpf5/brr78azZs3N2w2m9G4cWPjk08+KfB8Wf7ttxiGYVx8+4+IiIhI+aAxNyIiIlKpKNyIiIhIpaJwIyIiIpWKwo2IiIhUKgo3IiIiUqko3IiIiEilonAjIiIilYrCjYhUeYsXL8ZisZy1PpCIVEwKNyIiIlKpKNyIiIhIpaJwIyJOZ7fbmThxIlFRUXh6etKqVStmzpwJnO4ymjNnDi1btsTDw4PLL7+cLVu2FHiNH374gWbNmmGz2YiMjOTNN98s8HxWVhaPP/44tWrVwmazUb9+fT777LMC+6xdu5Z27drh5eVF586dz1rVWEQqBoUbEXG6iRMn8vXXXzN58mS2bt3KuHHjuPXWW1myZIljn0cffZQ333yT1atXExISQv/+/cnJyQHMUDJkyBBuvvlmNm/ezHPPPcfTTz/Nl19+6Th+xIgRfP/997z33nts376djz/+GB8fnwJ1/N///R9vvvkma9aswdXVldGjR1+Szy8ipUsLZ4qIU2VlZREYGMgff/xBp06dHNvvvPNOMjIyuPvuu+nevTtTp05l6NChACQmJlKzZk2+/PJLhgwZwvDhwzl27Bjz5893HP/YY48xZ84ctm7dyq5du2jUqBELFiygZ8+eZ9WwePFiunfvzh9//EGPHj0AmDt3Ltdeey0nT57Ew8OjjM+CiJQmtdyIiFPt2bOHjIwMevXqhY+Pj+P29ddfs3fvXsd+ZwafwMBAGjVqxPbt2wHYvn07Xbp0KfC6Xbp0Yffu3eTl5bFhwwasVivdunUrtJaWLVs6HlevXh2Ao0ePXvRnFJFLy9XZBYhI1ZaWlgbAnDlzqFGjRoHnbDZbgYBTUp6enkXaz83NzfHYYrEA5nggEalY1HIjIk7VtGlTbDYbsbGx1K9fv8CtVq1ajv1WrFjheHzixAl27dpFkyZNAGjSpAnLli0r8LrLli2jYcOGWK1WWrRogd1uLzCGR0QqL7XciIhT+fr68sgjjzBu3Djsdjtdu3YlOTmZZcuW4efnR506dQB44YUXCAoKIiwsjP/7v/8jODiYgQMHAvDwww/Tvn17XnzxRYYOHcry5cv54IMP+PDDDwGIjIxk5MiRjB49mvfee49WrVqxf/9+jh49ypAhQ5z10UWkjCjciIjTvfjii4SEhDBx4kT27dtHQEAAl112GU8++aSjW+iVV17hwQcfZPfu3bRu3Zpff/0Vd3d3AC677DKmT5/OM888w4svvkj16tV54YUXGDVqlOM9PvroI5588knuu+8+jh8/Tu3atXnyySed8XFFpIzpaikRKddOXcl04sQJAgICnF2OiFQAGnMjIiIilYrCjYiIiFQq6pYSERGRSkUtNyIiIlKpKNyIiIhIpaJwIyIiIpWKwo2IiIhUKgo3IiIiUqko3IiIiEilonAjIiIilYrCjYiIiFQqCjciIiJSqfw/aBQxMNNVIPMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train vs. val loss history\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(histories['train_epoch'])), histories['train_epoch'], '-', label = 'train loss')\n",
    "plt.plot(np.arange(len(histories['val_epoch'])), histories['val_epoch'], '-', label = 'val loss')\n",
    "plt.title('train vs. validation loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Reload the best model\n",
    "\n",
    "The final model after training may mot be the best one saved during the training process.\n",
    "\n",
    "To use the best model, we need to reload it from the saved file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(20000, 64)\n",
       "  (lstm): LSTM(64, 32, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload the best model\n",
    "model.load_state_dict(torch.load(saved_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Evaluation using test set\n",
    "\n",
    "The code is the same as the previous sessions. We need to:\n",
    "- Define a `test()` function to make predictions on the test set\n",
    "- Compute the classification report for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0TUNCpaZASuz"
   },
   "outputs": [],
   "source": [
    "# define a function to make predictions on test dataset and evaluate the performance\n",
    "def test(dataloader, model, loss_fn):\n",
    "    logits, probs, preds = [], [], []\n",
    "    with torch.no_grad():\n",
    "        loss = 0.0\n",
    "        for (X, y, lens) in dataloader:\n",
    "            X, y, lens = X.to(device), y.to(device), lens.to(device)\n",
    "            batch_logits = model(X, lens)\n",
    "            batch_loss = loss_fn(batch_logits, y)\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "            batch_probs = torch.softmax(batch_logits, dim = -1)\n",
    "            _, batch_preds = torch.max(batch_logits, 1)\n",
    "\n",
    "            logits.append(batch_logits.cpu().numpy())\n",
    "            probs.append(batch_probs.cpu().numpy())\n",
    "            preds.append(batch_preds.cpu().numpy())\n",
    "        loss /= len(dataloader)\n",
    "        print(f\"test loss = {loss}\")\n",
    "    return np.concatenate(logits), np.concatenate(probs), np.concatenate(preds), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmYq1lgBAUXb",
    "outputId": "cbb02b05-bf47-41bc-cd14-3a4acddd40bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss = 0.4492099642753601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.89      0.82      0.85      9636\n",
      "      Sports       0.89      0.94      0.91      9598\n",
      "    Business       0.83      0.80      0.81      9574\n",
      "     Sci/Tec       0.79      0.83      0.81      9472\n",
      "\n",
      "    accuracy                           0.85     38280\n",
      "   macro avg       0.85      0.85      0.85     38280\n",
      "weighted avg       0.85      0.85      0.85     38280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make prediction on test set and evaluate the performance\n",
    "test_logits, test_prob, test_pred, test_loss = test(test_dl, model, loss_fn)\n",
    "\n",
    "# obtain test labels\n",
    "test_label = []\n",
    "for (_, y, _) in test_dl:\n",
    "    test_label.extend(y.cpu().numpy())\n",
    "\n",
    "print(classification_report(test_label, test_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Make predictions on unseen data\n",
    "\n",
    "We can use the trained model to classify unseen news into one of the pre-defined classes.\n",
    "\n",
    "To do that, we can define a `predict_text()` function:\n",
    "- Take a list of text as inputs\n",
    "- Perform necessary pre-processing steps\n",
    "    - Tokenization\n",
    "    - Encode tokens\n",
    "    - Pad the sequence of encode tokens\n",
    "- Feed the text to the network in batch and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to predict the classes of a list of text\n",
    "def predict_text(model, text_list):\n",
    "    X, lens = [], []\n",
    "    for text in text_list:\n",
    "        tokens = preprocess_text(text)\n",
    "        encoded_tokens = encode_tokens(tokens)\n",
    "        X.append(torch.tensor(encoded_tokens, dtype=torch.int64))\n",
    "        lens.append(len(encoded_tokens))\n",
    "    X = pad_sequence(X, batch_first=True)\n",
    "    lens = torch.tensor(lens, dtype=torch.int64)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X.to(device), lens.to(device))\n",
    "        _, preds = torch.max(logits, 1)\n",
    "    return preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The stock market closed higher today with tech stocks leading the gains.\n",
      "Predicted category: Business\n",
      "\n",
      "Text: The national team won their match and qualified for the finals.\n",
      "Predicted category: Sports\n",
      "\n",
      "Text: A new species of dinosaur was discovered by scientists.\n",
      "Predicted category: Sci/Tec\n",
      "\n",
      "Text: The prime minister met with the president to discuss trade agreements.\n",
      "Predicted category: World\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example texts\n",
    "text_list = [\n",
    "    \"The stock market closed higher today with tech stocks leading the gains.\",\n",
    "    \"The national team won their match and qualified for the finals.\",\n",
    "    \"A new species of dinosaur was discovered by scientists.\",\n",
    "    \"The prime minister met with the president to discuss trade agreements.\"\n",
    "]\n",
    "# make prediction\n",
    "preds = predict_text(model, text_list)\n",
    "# print results\n",
    "for idx in range(len(text_list)):\n",
    "    text = text_list[idx]\n",
    "    pred = preds[idx]\n",
    "    print(f'Text: {text}\\nPredicted category: {classes[pred]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
