{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1625dfbe-822f-4cee-9f57-f5192023fc76",
   "metadata": {},
   "source": [
    "# Exercise 06 CNN for Image Classification - Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717555c-a5f4-48a5-a78d-437547690b15",
   "metadata": {},
   "source": [
    "## Pedagogy\n",
    "\n",
    "This notebook serves as an instruction for implementing CNNs using PyTorch to develop image classification models.\n",
    "\n",
    "Please use this notebook as a reference and guide to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f11bd9-3d90-4920-b97f-c55a0ab34354",
   "metadata": {},
   "source": [
    "### Pre-configure\n",
    "\n",
    "In this notebook we will use several new libraries:\n",
    "- `trochvision.datasets` for obtaining PyTorch built-in datasets\n",
    "- `torchvision.transforms` for data preprocessing using PyTorch built-in transform functions\n",
    "- `torch.utils.data.random_split` for splitting datasets like `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d63c38-76fb-4ba0-a8e0-052aa3a448ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959a1f17-c265-4973-88ce-b84a6039b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d56fd1-b8ae-46f2-9e9c-b45fd74bdeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for computation\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e086def-a09e-45c3-88f6-7b0a9c76dd1d",
   "metadata": {},
   "source": [
    "## Part 1. Hand-written Digits Recognition with <span style=\"color:red\">**ANN**</span>\n",
    "\n",
    "In this part, we will first build a multi-class image classifier using <span style=\"color:red\">**ANN**</span> for comparison.\n",
    "\n",
    "The problem to be solved is to recognize the hand-written digits:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/b/b1/MNIST_dataset_example.png)\n",
    "\n",
    "We will use the [PyTorch built-in MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) (70,000 samples).\n",
    "- Each hand-written digit image contains $28\\times28$ pixels with only one channel (grayscale image).\n",
    "- There are 10 classes, where each class refers to one digit.\n",
    "- Feature scaling has already been done in the pre-processing step, no need to perform feature scaling by ourselves.\n",
    "\n",
    "We will first use this small dataset to illustrate how to implement a CNN. Then we will move to a large dataset (70,000 samples) in the next part.\n",
    "\n",
    "We will first build an image classifier using traditional <span style=\"color:red\">**ANN**</span>. In Part 2, we will build another image classifier using <span style=\"color:red\">**CNN**</span> for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84113ee9-9ce0-4e63-bdea-e705d3c39afb",
   "metadata": {},
   "source": [
    "### Step 1. Build the data pipeline\n",
    "\n",
    "In this step, we need to:\n",
    "- Use `torchvision.datasets.MNIST()` to load the MNIST hand-written digits dataset\n",
    "- Use `torchvision.transforms.ToTensor()` to convert the data to tensors\n",
    "- The MNIST dataset is already divided into the training set and test set\n",
    "- Use `torch.utils.data.random_split()` to further split the training set into the training set and validation set\n",
    "- Create `DataLoader` instance to wrap the dataset as iterable objects\n",
    "    - Decide a proper batch size considering\n",
    "        - The available memory of your computer\n",
    "        - The desired number of batches in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84593cd8-c287-40f0-9a96-95d7740ba8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset\n",
    "train_val_ds = datasets.MNIST(\n",
    "    root = 'data', # root directory for storing data\n",
    "    train = True, # get the train part\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor() # convert to tensor\n",
    ")\n",
    "test_ds = datasets.MNIST(\n",
    "    root = 'data', # root directory for storing data\n",
    "    train = False, # get the test part\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor() # convert to tensor\n",
    ")\n",
    "train_ds, val_ds = random_split(\n",
    "    train_val_ds,\n",
    "    [0.8, 0.2] # [train size, val size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b984a603-d4a0-4bc9-b27d-d44404cf64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "batch_size = 8192 # usually set to 2 to the nth power\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
    "val_dl = DataLoader(val_ds, batch_size = batch_size, shuffle = False)\n",
    "test_dl = DataLoader(test_ds, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2401c226-c0d7-4a71-95ec-ae316ce514e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([8192, 1, 28, 28])\n",
      "Label shape: torch.Size([8192])\n"
     ]
    }
   ],
   "source": [
    "# display the dimensionality of a batch\n",
    "for (X, y) in val_dl:\n",
    "    print('Feature shape:', X.shape)\n",
    "    print('Label shape:', y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab97e3-14a6-4989-9c63-1cc421ec3793",
   "metadata": {},
   "source": [
    "We can see that given a batch of samples, the feature tensor has 4 dimensions:\n",
    "- 1st dimension: the batch size, `8192` samples per batch\n",
    "- 2nd dimension: the number of channels, `1` indicates one channel (grascale image)\n",
    "- 3rd dimension: the height of input image\n",
    "- 4th dimension: the width of input image\n",
    "\n",
    "The label tensor has only 1 dimension, which is the batch size.\n",
    "\n",
    "We can also display one example to check what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac3f45b-a131-4ea7-a18d-e1b060ce6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this hand-written digit is: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display an example\n",
    "plt.imshow(train_ds[0][0].numpy().reshape(28, 28), cmap = 'gray')\n",
    "print('The label of this hand-written digit is:', train_ds[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd8db1-15e9-48f5-b552-5dfe2448f3f3",
   "metadata": {},
   "source": [
    "### Step 2. Create an image classifier using <span style=\"color:red\">**ANN**</span>\n",
    "\n",
    "In this step, we will first create a class that inherits from `torch.nn.Module` to determine the network structure, the activation functions, and the forward method. And then initialize the neural network.\n",
    "\n",
    "To use ANN for image processing, we typically add a `nn.Flatten()` layer in the network as the first layer. This is because:\n",
    "- The shape of the input tensor of the network is `(batch_size, num_of_channels, height, width)`\n",
    "- The `nn.Linear()` layer requires the input tensor of shape `(batch_size, num_of_features)`\n",
    "- `nn.Flatten()` will reshape the input tensor as required by the `nn.Linear()` layer\n",
    "\n",
    "We also include batch normalization layers and dropout layers for regularization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ef1d07-0979-421b-b150-d7e330be2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom neural network class\n",
    "class ANNImageClassifier(nn.Module):\n",
    "    def __init__(self, n_features, n_labels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), # reshape the input tensor\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.BatchNorm1d(128), # batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5), # dropout with 50% probability\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64), # batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5), # dropout with 50% probability\n",
    "            nn.Linear(64, 16),\n",
    "            nn.BatchNorm1d(16), # batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5), # dropout with 50% probability\n",
    "            nn.Linear(16, n_labels)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b1f936-f8d9-4b29-8fb8-a5b9697afe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANNImageClassifier(\n",
       "  (net): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (13): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "ann_model = ANNImageClassifier(\n",
    "    n_features = 784, # 1*28*28=784\n",
    "    n_labels = 10 # 10 classes\n",
    ")\n",
    "ann_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1d1bb-72bc-4009-a4b5-a08f546d6d56",
   "metadata": {},
   "source": [
    "### Step 3. Train the network\n",
    "\n",
    "In this step, we will define a `train()` function to perform the training process.\n",
    "\n",
    "We implement weight decay, learning rate decay, early stopping, automatic model saving for regularization purposes.\n",
    "\n",
    "We also add the time consumed information to the printed log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63099c8-b489-4f6c-b5b0-cb667a07ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training function\n",
    "def train(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    early_stopping_patience,\n",
    "    lr_scheduler,\n",
    "    saved_path_prefix\n",
    "):\n",
    "    # initialization\n",
    "    min_val_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    histories = {\n",
    "        'train_batch': [],\n",
    "        'train_epoch': [],\n",
    "        'val_batch': [],\n",
    "        'val_epoch': []\n",
    "    }\n",
    "    saved_path = ''\n",
    "    start_time = datetime.datetime.now() # record start time\n",
    "    \n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        # train set\n",
    "        train_epoch_loss = 0.0\n",
    "        model.train() # set the model in training mode\n",
    "        for (X, y) in train_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            train_batch_loss = loss_fn(logits, y)\n",
    "            train_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            histories['train_batch'].append(train_batch_loss.item())\n",
    "            train_epoch_loss += train_batch_loss.item()\n",
    "        train_epoch_loss /= len(train_dl)\n",
    "        histories['train_epoch'].append(train_epoch_loss)\n",
    "        \n",
    "        # validation set\n",
    "        val_epoch_loss = 0.0\n",
    "        model.eval() # set the model in evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for (X, y) in val_dl:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                logits = model(X)\n",
    "                val_batch_loss = loss_fn(logits, y)\n",
    "                histories['val_batch'].append(val_batch_loss.item())\n",
    "                val_epoch_loss += val_batch_loss.item()\n",
    "            val_epoch_loss /= len(val_dl)\n",
    "            histories['val_epoch'].append(val_epoch_loss)\n",
    "\n",
    "        # print log\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_consumed = str(end_time - start_time).split('.')[0] # calculate consumed time after completing one epoch\n",
    "        print(f\"Epoch {epoch + 1}: train loss = {train_epoch_loss:>5f}, val loss = {val_epoch_loss:>5f}, time consumed = {time_consumed}\")\n",
    "        \n",
    "        # learning rate decay\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        lr_scheduler.step(val_epoch_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if current_lr != new_lr:\n",
    "            print(f'Learning rate reduced after epoch {epoch+1}\\n')\n",
    "            \n",
    "        # early stopping\n",
    "        if val_epoch_loss < min_val_loss:\n",
    "            min_val_loss = val_epoch_loss\n",
    "            patience_counter = 0\n",
    "            if os.path.exists(saved_path):\n",
    "                os.remove(saved_path)\n",
    "            time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            saved_path = saved_path_prefix + f'_epoch_{epoch+1}_val_loss_{val_epoch_loss:>4f}_{time_str}.pth'\n",
    "            torch.save(model.state_dict(), saved_path)\n",
    "            print(f'Model saved after epoch {epoch+1}\\n')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "    return histories, saved_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a22eb0-65d2-49cf-ae59-ecdbf096d47e",
   "metadata": {},
   "source": [
    "After defining the `train()` function, we also need to specify the hyper-parameters for the training process:\n",
    "- Loss function: use cross entropy loss for multi-class problems\n",
    "- Initial learning rate\n",
    "- Lamda for L2 norm regularization\n",
    "- Optimizer: mini-batch gradient descent\n",
    "    - We need to specify the model parameters we want to optimize\n",
    "- Maximum number of epochs to train\n",
    "- Early stopping patience\n",
    "- Learning rate scheduler: reduce learning rate by monitoring validation loss\n",
    "- Prefix of the saved file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac3d8aa-7dac-4a27-99a9-10db693eb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training hyper-parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-1\n",
    "weight_decay = 1e-5\n",
    "optimizer = torch.optim.SGD(\n",
    "    ann_model.parameters(), # specify which model to optimize\n",
    "    lr = learning_rate,\n",
    "    weight_decay = weight_decay\n",
    ")\n",
    "epochs = 1000\n",
    "early_stopping_patience = 20\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode = 'min',\n",
    "    factor = 0.1,\n",
    "    patience = 5\n",
    ")\n",
    "saved_path_prefix = 'ann_image_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e3854-9687-4de4-9a30-ea83e3ebf4f8",
   "metadata": {},
   "source": [
    "Then we can start the training process.\n",
    "\n",
    "Be sure to pass the correct model to the `train()` function by correctly specifying the name of the model you want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cbd21d-7226-43dd-bbbf-0bb9e3cfed71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 2.300082, val loss = 2.280718, time consumed = 0:00:04\n",
      "Model saved after epoch 1\n",
      "\n",
      "Epoch 2: train loss = 2.101022, val loss = 2.216218, time consumed = 0:00:05\n",
      "Model saved after epoch 2\n",
      "\n",
      "Epoch 3: train loss = 1.987458, val loss = 2.105470, time consumed = 0:00:06\n",
      "Model saved after epoch 3\n",
      "\n",
      "Epoch 4: train loss = 1.895298, val loss = 1.960505, time consumed = 0:00:07\n",
      "Model saved after epoch 4\n",
      "\n",
      "Epoch 5: train loss = 1.816310, val loss = 1.796935, time consumed = 0:00:08\n",
      "Model saved after epoch 5\n",
      "\n",
      "Epoch 6: train loss = 1.746679, val loss = 1.638587, time consumed = 0:00:09\n",
      "Model saved after epoch 6\n",
      "\n",
      "Epoch 7: train loss = 1.688592, val loss = 1.499062, time consumed = 0:00:10\n",
      "Model saved after epoch 7\n",
      "\n",
      "Epoch 8: train loss = 1.632211, val loss = 1.386479, time consumed = 0:00:12\n",
      "Model saved after epoch 8\n",
      "\n",
      "Epoch 9: train loss = 1.578464, val loss = 1.293836, time consumed = 0:00:13\n",
      "Model saved after epoch 9\n",
      "\n",
      "Epoch 10: train loss = 1.536326, val loss = 1.221854, time consumed = 0:00:14\n",
      "Model saved after epoch 10\n",
      "\n",
      "Epoch 11: train loss = 1.499269, val loss = 1.158082, time consumed = 0:00:15\n",
      "Model saved after epoch 11\n",
      "\n",
      "Epoch 12: train loss = 1.458094, val loss = 1.105597, time consumed = 0:00:17\n",
      "Model saved after epoch 12\n",
      "\n",
      "Epoch 13: train loss = 1.419469, val loss = 1.061186, time consumed = 0:00:18\n",
      "Model saved after epoch 13\n",
      "\n",
      "Epoch 14: train loss = 1.393447, val loss = 1.019679, time consumed = 0:00:19\n",
      "Model saved after epoch 14\n",
      "\n",
      "Epoch 15: train loss = 1.363676, val loss = 0.980553, time consumed = 0:00:20\n",
      "Model saved after epoch 15\n",
      "\n",
      "Epoch 16: train loss = 1.338811, val loss = 0.941263, time consumed = 0:00:22\n",
      "Model saved after epoch 16\n",
      "\n",
      "Epoch 17: train loss = 1.318910, val loss = 0.911365, time consumed = 0:00:23\n",
      "Model saved after epoch 17\n",
      "\n",
      "Epoch 18: train loss = 1.294775, val loss = 0.883167, time consumed = 0:00:24\n",
      "Model saved after epoch 18\n",
      "\n",
      "Epoch 19: train loss = 1.281599, val loss = 0.852676, time consumed = 0:00:25\n",
      "Model saved after epoch 19\n",
      "\n",
      "Epoch 20: train loss = 1.259704, val loss = 0.832128, time consumed = 0:00:27\n",
      "Model saved after epoch 20\n",
      "\n",
      "Epoch 21: train loss = 1.241534, val loss = 0.807210, time consumed = 0:00:28\n",
      "Model saved after epoch 21\n",
      "\n",
      "Epoch 22: train loss = 1.227315, val loss = 0.784985, time consumed = 0:00:29\n",
      "Model saved after epoch 22\n",
      "\n",
      "Epoch 23: train loss = 1.205973, val loss = 0.764217, time consumed = 0:00:30\n",
      "Model saved after epoch 23\n",
      "\n",
      "Epoch 24: train loss = 1.196187, val loss = 0.744744, time consumed = 0:00:31\n",
      "Model saved after epoch 24\n",
      "\n",
      "Epoch 25: train loss = 1.181458, val loss = 0.727297, time consumed = 0:00:32\n",
      "Model saved after epoch 25\n",
      "\n",
      "Epoch 26: train loss = 1.164906, val loss = 0.707835, time consumed = 0:00:34\n",
      "Model saved after epoch 26\n",
      "\n",
      "Epoch 27: train loss = 1.155409, val loss = 0.693965, time consumed = 0:00:35\n",
      "Model saved after epoch 27\n",
      "\n",
      "Epoch 28: train loss = 1.144445, val loss = 0.678087, time consumed = 0:00:36\n",
      "Model saved after epoch 28\n",
      "\n",
      "Epoch 29: train loss = 1.128176, val loss = 0.664469, time consumed = 0:00:37\n",
      "Model saved after epoch 29\n",
      "\n",
      "Epoch 30: train loss = 1.123531, val loss = 0.650466, time consumed = 0:00:39\n",
      "Model saved after epoch 30\n",
      "\n",
      "Epoch 31: train loss = 1.109939, val loss = 0.638644, time consumed = 0:00:40\n",
      "Model saved after epoch 31\n",
      "\n",
      "Epoch 32: train loss = 1.099951, val loss = 0.625358, time consumed = 0:00:41\n",
      "Model saved after epoch 32\n",
      "\n",
      "Epoch 33: train loss = 1.095940, val loss = 0.613463, time consumed = 0:00:42\n",
      "Model saved after epoch 33\n",
      "\n",
      "Epoch 34: train loss = 1.089341, val loss = 0.603609, time consumed = 0:00:44\n",
      "Model saved after epoch 34\n",
      "\n",
      "Epoch 35: train loss = 1.075014, val loss = 0.593750, time consumed = 0:00:45\n",
      "Model saved after epoch 35\n",
      "\n",
      "Epoch 36: train loss = 1.066619, val loss = 0.582493, time consumed = 0:00:46\n",
      "Model saved after epoch 36\n",
      "\n",
      "Epoch 37: train loss = 1.059210, val loss = 0.572294, time consumed = 0:00:47\n",
      "Model saved after epoch 37\n",
      "\n",
      "Epoch 38: train loss = 1.044078, val loss = 0.564033, time consumed = 0:00:49\n",
      "Model saved after epoch 38\n",
      "\n",
      "Epoch 39: train loss = 1.046648, val loss = 0.553413, time consumed = 0:00:50\n",
      "Model saved after epoch 39\n",
      "\n",
      "Epoch 40: train loss = 1.037809, val loss = 0.547434, time consumed = 0:00:51\n",
      "Model saved after epoch 40\n",
      "\n",
      "Epoch 41: train loss = 1.030404, val loss = 0.538835, time consumed = 0:00:52\n",
      "Model saved after epoch 41\n",
      "\n",
      "Epoch 42: train loss = 1.013259, val loss = 0.531492, time consumed = 0:00:53\n",
      "Model saved after epoch 42\n",
      "\n",
      "Epoch 43: train loss = 1.013760, val loss = 0.521701, time consumed = 0:00:55\n",
      "Model saved after epoch 43\n",
      "\n",
      "Epoch 44: train loss = 1.006898, val loss = 0.515139, time consumed = 0:00:56\n",
      "Model saved after epoch 44\n",
      "\n",
      "Epoch 45: train loss = 1.005610, val loss = 0.509024, time consumed = 0:00:57\n",
      "Model saved after epoch 45\n",
      "\n",
      "Epoch 46: train loss = 1.001606, val loss = 0.503650, time consumed = 0:00:58\n",
      "Model saved after epoch 46\n",
      "\n",
      "Epoch 47: train loss = 0.997114, val loss = 0.497312, time consumed = 0:01:00\n",
      "Model saved after epoch 47\n",
      "\n",
      "Epoch 48: train loss = 0.987558, val loss = 0.490549, time consumed = 0:01:01\n",
      "Model saved after epoch 48\n",
      "\n",
      "Epoch 49: train loss = 0.979168, val loss = 0.482935, time consumed = 0:01:02\n",
      "Model saved after epoch 49\n",
      "\n",
      "Epoch 50: train loss = 0.972112, val loss = 0.476190, time consumed = 0:01:03\n",
      "Model saved after epoch 50\n",
      "\n",
      "Epoch 51: train loss = 0.967306, val loss = 0.469890, time consumed = 0:01:05\n",
      "Model saved after epoch 51\n",
      "\n",
      "Epoch 52: train loss = 0.961465, val loss = 0.463969, time consumed = 0:01:06\n",
      "Model saved after epoch 52\n",
      "\n",
      "Epoch 53: train loss = 0.957550, val loss = 0.459146, time consumed = 0:01:07\n",
      "Model saved after epoch 53\n",
      "\n",
      "Epoch 54: train loss = 0.953023, val loss = 0.455360, time consumed = 0:01:08\n",
      "Model saved after epoch 54\n",
      "\n",
      "Epoch 55: train loss = 0.947801, val loss = 0.449474, time consumed = 0:01:09\n",
      "Model saved after epoch 55\n",
      "\n",
      "Epoch 56: train loss = 0.952342, val loss = 0.444421, time consumed = 0:01:11\n",
      "Model saved after epoch 56\n",
      "\n",
      "Epoch 57: train loss = 0.937365, val loss = 0.439241, time consumed = 0:01:12\n",
      "Model saved after epoch 57\n",
      "\n",
      "Epoch 58: train loss = 0.929542, val loss = 0.433791, time consumed = 0:01:14\n",
      "Model saved after epoch 58\n",
      "\n",
      "Epoch 59: train loss = 0.928207, val loss = 0.427815, time consumed = 0:01:15\n",
      "Model saved after epoch 59\n",
      "\n",
      "Epoch 60: train loss = 0.926096, val loss = 0.424423, time consumed = 0:01:16\n",
      "Model saved after epoch 60\n",
      "\n",
      "Epoch 61: train loss = 0.919194, val loss = 0.418746, time consumed = 0:01:17\n",
      "Model saved after epoch 61\n",
      "\n",
      "Epoch 62: train loss = 0.918326, val loss = 0.414893, time consumed = 0:01:18\n",
      "Model saved after epoch 62\n",
      "\n",
      "Epoch 63: train loss = 0.914647, val loss = 0.411961, time consumed = 0:01:20\n",
      "Model saved after epoch 63\n",
      "\n",
      "Epoch 64: train loss = 0.903934, val loss = 0.406434, time consumed = 0:01:21\n",
      "Model saved after epoch 64\n",
      "\n",
      "Epoch 65: train loss = 0.907549, val loss = 0.401478, time consumed = 0:01:22\n",
      "Model saved after epoch 65\n",
      "\n",
      "Epoch 66: train loss = 0.907424, val loss = 0.397014, time consumed = 0:01:23\n",
      "Model saved after epoch 66\n",
      "\n",
      "Epoch 67: train loss = 0.902969, val loss = 0.394014, time consumed = 0:01:24\n",
      "Model saved after epoch 67\n",
      "\n",
      "Epoch 68: train loss = 0.891368, val loss = 0.390390, time consumed = 0:01:26\n",
      "Model saved after epoch 68\n",
      "\n",
      "Epoch 69: train loss = 0.886570, val loss = 0.383905, time consumed = 0:01:27\n",
      "Model saved after epoch 69\n",
      "\n",
      "Epoch 70: train loss = 0.880235, val loss = 0.380963, time consumed = 0:01:28\n",
      "Model saved after epoch 70\n",
      "\n",
      "Epoch 71: train loss = 0.877202, val loss = 0.377511, time consumed = 0:01:29\n",
      "Model saved after epoch 71\n",
      "\n",
      "Epoch 72: train loss = 0.880780, val loss = 0.374658, time consumed = 0:01:30\n",
      "Model saved after epoch 72\n",
      "\n",
      "Epoch 73: train loss = 0.873353, val loss = 0.370302, time consumed = 0:01:31\n",
      "Model saved after epoch 73\n",
      "\n",
      "Epoch 74: train loss = 0.872090, val loss = 0.367659, time consumed = 0:01:33\n",
      "Model saved after epoch 74\n",
      "\n",
      "Epoch 75: train loss = 0.863641, val loss = 0.363338, time consumed = 0:01:34\n",
      "Model saved after epoch 75\n",
      "\n",
      "Epoch 76: train loss = 0.865702, val loss = 0.359878, time consumed = 0:01:35\n",
      "Model saved after epoch 76\n",
      "\n",
      "Epoch 77: train loss = 0.863495, val loss = 0.356829, time consumed = 0:01:36\n",
      "Model saved after epoch 77\n",
      "\n",
      "Epoch 78: train loss = 0.855406, val loss = 0.355276, time consumed = 0:01:37\n",
      "Model saved after epoch 78\n",
      "\n",
      "Epoch 79: train loss = 0.852260, val loss = 0.350761, time consumed = 0:01:39\n",
      "Model saved after epoch 79\n",
      "\n",
      "Epoch 80: train loss = 0.850565, val loss = 0.346913, time consumed = 0:01:40\n",
      "Model saved after epoch 80\n",
      "\n",
      "Epoch 81: train loss = 0.849119, val loss = 0.344195, time consumed = 0:01:41\n",
      "Model saved after epoch 81\n",
      "\n",
      "Epoch 82: train loss = 0.845884, val loss = 0.341910, time consumed = 0:01:42\n",
      "Model saved after epoch 82\n",
      "\n",
      "Epoch 83: train loss = 0.840732, val loss = 0.338738, time consumed = 0:01:43\n",
      "Model saved after epoch 83\n",
      "\n",
      "Epoch 84: train loss = 0.844262, val loss = 0.335194, time consumed = 0:01:45\n",
      "Model saved after epoch 84\n",
      "\n",
      "Epoch 85: train loss = 0.838381, val loss = 0.334197, time consumed = 0:01:46\n",
      "Model saved after epoch 85\n",
      "\n",
      "Epoch 86: train loss = 0.831344, val loss = 0.330838, time consumed = 0:01:47\n",
      "Model saved after epoch 86\n",
      "\n",
      "Epoch 87: train loss = 0.825341, val loss = 0.328681, time consumed = 0:01:48\n",
      "Model saved after epoch 87\n",
      "\n",
      "Epoch 88: train loss = 0.827561, val loss = 0.325067, time consumed = 0:01:49\n",
      "Model saved after epoch 88\n",
      "\n",
      "Epoch 89: train loss = 0.827959, val loss = 0.322304, time consumed = 0:01:51\n",
      "Model saved after epoch 89\n",
      "\n",
      "Epoch 90: train loss = 0.814643, val loss = 0.317946, time consumed = 0:01:52\n",
      "Model saved after epoch 90\n",
      "\n",
      "Epoch 91: train loss = 0.814310, val loss = 0.316114, time consumed = 0:01:53\n",
      "Model saved after epoch 91\n",
      "\n",
      "Epoch 92: train loss = 0.811996, val loss = 0.314351, time consumed = 0:01:54\n",
      "Model saved after epoch 92\n",
      "\n",
      "Epoch 93: train loss = 0.806849, val loss = 0.311909, time consumed = 0:01:55\n",
      "Model saved after epoch 93\n",
      "\n",
      "Epoch 94: train loss = 0.813256, val loss = 0.309402, time consumed = 0:01:57\n",
      "Model saved after epoch 94\n",
      "\n",
      "Epoch 95: train loss = 0.806721, val loss = 0.308143, time consumed = 0:01:58\n",
      "Model saved after epoch 95\n",
      "\n",
      "Epoch 96: train loss = 0.804794, val loss = 0.304777, time consumed = 0:01:59\n",
      "Model saved after epoch 96\n",
      "\n",
      "Epoch 97: train loss = 0.794580, val loss = 0.303238, time consumed = 0:02:00\n",
      "Model saved after epoch 97\n",
      "\n",
      "Epoch 98: train loss = 0.797525, val loss = 0.301108, time consumed = 0:02:01\n",
      "Model saved after epoch 98\n",
      "\n",
      "Epoch 99: train loss = 0.797963, val loss = 0.298245, time consumed = 0:02:02\n",
      "Model saved after epoch 99\n",
      "\n",
      "Epoch 100: train loss = 0.795056, val loss = 0.297716, time consumed = 0:02:04\n",
      "Model saved after epoch 100\n",
      "\n",
      "Epoch 101: train loss = 0.793719, val loss = 0.293981, time consumed = 0:02:05\n",
      "Model saved after epoch 101\n",
      "\n",
      "Epoch 102: train loss = 0.787455, val loss = 0.293501, time consumed = 0:02:06\n",
      "Model saved after epoch 102\n",
      "\n",
      "Epoch 103: train loss = 0.777211, val loss = 0.289562, time consumed = 0:02:07\n",
      "Model saved after epoch 103\n",
      "\n",
      "Epoch 104: train loss = 0.778866, val loss = 0.287576, time consumed = 0:02:08\n",
      "Model saved after epoch 104\n",
      "\n",
      "Epoch 105: train loss = 0.779103, val loss = 0.286093, time consumed = 0:02:10\n",
      "Model saved after epoch 105\n",
      "\n",
      "Epoch 106: train loss = 0.780773, val loss = 0.283823, time consumed = 0:02:11\n",
      "Model saved after epoch 106\n",
      "\n",
      "Epoch 107: train loss = 0.777202, val loss = 0.282105, time consumed = 0:02:12\n",
      "Model saved after epoch 107\n",
      "\n",
      "Epoch 108: train loss = 0.770411, val loss = 0.280820, time consumed = 0:02:13\n",
      "Model saved after epoch 108\n",
      "\n",
      "Epoch 109: train loss = 0.772574, val loss = 0.279087, time consumed = 0:02:14\n",
      "Model saved after epoch 109\n",
      "\n",
      "Epoch 110: train loss = 0.767098, val loss = 0.278396, time consumed = 0:02:16\n",
      "Model saved after epoch 110\n",
      "\n",
      "Epoch 111: train loss = 0.767227, val loss = 0.276121, time consumed = 0:02:17\n",
      "Model saved after epoch 111\n",
      "\n",
      "Epoch 112: train loss = 0.771429, val loss = 0.274698, time consumed = 0:02:18\n",
      "Model saved after epoch 112\n",
      "\n",
      "Epoch 113: train loss = 0.757234, val loss = 0.271904, time consumed = 0:02:19\n",
      "Model saved after epoch 113\n",
      "\n",
      "Epoch 114: train loss = 0.759765, val loss = 0.270753, time consumed = 0:02:21\n",
      "Model saved after epoch 114\n",
      "\n",
      "Epoch 115: train loss = 0.761672, val loss = 0.268993, time consumed = 0:02:22\n",
      "Model saved after epoch 115\n",
      "\n",
      "Epoch 116: train loss = 0.747764, val loss = 0.267772, time consumed = 0:02:23\n",
      "Model saved after epoch 116\n",
      "\n",
      "Epoch 117: train loss = 0.754495, val loss = 0.267003, time consumed = 0:02:24\n",
      "Model saved after epoch 117\n",
      "\n",
      "Epoch 118: train loss = 0.751069, val loss = 0.265741, time consumed = 0:02:25\n",
      "Model saved after epoch 118\n",
      "\n",
      "Epoch 119: train loss = 0.747759, val loss = 0.264155, time consumed = 0:02:27\n",
      "Model saved after epoch 119\n",
      "\n",
      "Epoch 120: train loss = 0.750112, val loss = 0.262468, time consumed = 0:02:28\n",
      "Model saved after epoch 120\n",
      "\n",
      "Epoch 121: train loss = 0.745273, val loss = 0.260852, time consumed = 0:02:29\n",
      "Model saved after epoch 121\n",
      "\n",
      "Epoch 122: train loss = 0.741796, val loss = 0.259404, time consumed = 0:02:30\n",
      "Model saved after epoch 122\n",
      "\n",
      "Epoch 123: train loss = 0.744381, val loss = 0.257476, time consumed = 0:02:31\n",
      "Model saved after epoch 123\n",
      "\n",
      "Epoch 124: train loss = 0.742917, val loss = 0.256242, time consumed = 0:02:32\n",
      "Model saved after epoch 124\n",
      "\n",
      "Epoch 125: train loss = 0.741940, val loss = 0.255482, time consumed = 0:02:34\n",
      "Model saved after epoch 125\n",
      "\n",
      "Epoch 126: train loss = 0.738126, val loss = 0.253150, time consumed = 0:02:35\n",
      "Model saved after epoch 126\n",
      "\n",
      "Epoch 127: train loss = 0.735118, val loss = 0.254237, time consumed = 0:02:36\n",
      "Epoch 128: train loss = 0.733642, val loss = 0.251797, time consumed = 0:02:37\n",
      "Model saved after epoch 128\n",
      "\n",
      "Epoch 129: train loss = 0.729774, val loss = 0.249653, time consumed = 0:02:38\n",
      "Model saved after epoch 129\n",
      "\n",
      "Epoch 130: train loss = 0.731487, val loss = 0.248953, time consumed = 0:02:40\n",
      "Model saved after epoch 130\n",
      "\n",
      "Epoch 131: train loss = 0.723857, val loss = 0.247353, time consumed = 0:02:41\n",
      "Model saved after epoch 131\n",
      "\n",
      "Epoch 132: train loss = 0.726966, val loss = 0.245245, time consumed = 0:02:42\n",
      "Model saved after epoch 132\n",
      "\n",
      "Epoch 133: train loss = 0.726500, val loss = 0.243958, time consumed = 0:02:43\n",
      "Model saved after epoch 133\n",
      "\n",
      "Epoch 134: train loss = 0.722409, val loss = 0.243412, time consumed = 0:02:45\n",
      "Model saved after epoch 134\n",
      "\n",
      "Epoch 135: train loss = 0.720355, val loss = 0.242946, time consumed = 0:02:46\n",
      "Model saved after epoch 135\n",
      "\n",
      "Epoch 136: train loss = 0.730326, val loss = 0.241850, time consumed = 0:02:47\n",
      "Model saved after epoch 136\n",
      "\n",
      "Epoch 137: train loss = 0.724214, val loss = 0.241285, time consumed = 0:02:48\n",
      "Model saved after epoch 137\n",
      "\n",
      "Epoch 138: train loss = 0.717687, val loss = 0.240348, time consumed = 0:02:49\n",
      "Model saved after epoch 138\n",
      "\n",
      "Epoch 139: train loss = 0.718145, val loss = 0.239526, time consumed = 0:02:50\n",
      "Model saved after epoch 139\n",
      "\n",
      "Epoch 140: train loss = 0.716749, val loss = 0.237914, time consumed = 0:02:52\n",
      "Model saved after epoch 140\n",
      "\n",
      "Epoch 141: train loss = 0.711710, val loss = 0.237412, time consumed = 0:02:53\n",
      "Model saved after epoch 141\n",
      "\n",
      "Epoch 142: train loss = 0.709180, val loss = 0.236219, time consumed = 0:02:54\n",
      "Model saved after epoch 142\n",
      "\n",
      "Epoch 143: train loss = 0.709960, val loss = 0.234644, time consumed = 0:02:55\n",
      "Model saved after epoch 143\n",
      "\n",
      "Epoch 144: train loss = 0.713511, val loss = 0.233978, time consumed = 0:02:57\n",
      "Model saved after epoch 144\n",
      "\n",
      "Epoch 145: train loss = 0.705037, val loss = 0.232999, time consumed = 0:02:58\n",
      "Model saved after epoch 145\n",
      "\n",
      "Epoch 146: train loss = 0.704561, val loss = 0.232982, time consumed = 0:02:59\n",
      "Model saved after epoch 146\n",
      "\n",
      "Epoch 147: train loss = 0.712857, val loss = 0.231554, time consumed = 0:03:00\n",
      "Model saved after epoch 147\n",
      "\n",
      "Epoch 148: train loss = 0.706881, val loss = 0.230689, time consumed = 0:03:01\n",
      "Model saved after epoch 148\n",
      "\n",
      "Epoch 149: train loss = 0.703736, val loss = 0.229820, time consumed = 0:03:03\n",
      "Model saved after epoch 149\n",
      "\n",
      "Epoch 150: train loss = 0.704047, val loss = 0.227979, time consumed = 0:03:04\n",
      "Model saved after epoch 150\n",
      "\n",
      "Epoch 151: train loss = 0.700684, val loss = 0.228411, time consumed = 0:03:05\n",
      "Epoch 152: train loss = 0.700131, val loss = 0.227514, time consumed = 0:03:06\n",
      "Model saved after epoch 152\n",
      "\n",
      "Epoch 153: train loss = 0.696943, val loss = 0.226514, time consumed = 0:03:07\n",
      "Model saved after epoch 153\n",
      "\n",
      "Epoch 154: train loss = 0.696093, val loss = 0.225658, time consumed = 0:03:09\n",
      "Model saved after epoch 154\n",
      "\n",
      "Epoch 155: train loss = 0.700878, val loss = 0.224777, time consumed = 0:03:10\n",
      "Model saved after epoch 155\n",
      "\n",
      "Epoch 156: train loss = 0.688522, val loss = 0.223972, time consumed = 0:03:11\n",
      "Model saved after epoch 156\n",
      "\n",
      "Epoch 157: train loss = 0.694881, val loss = 0.222075, time consumed = 0:03:12\n",
      "Model saved after epoch 157\n",
      "\n",
      "Epoch 158: train loss = 0.695328, val loss = 0.222465, time consumed = 0:03:13\n",
      "Epoch 159: train loss = 0.692481, val loss = 0.221284, time consumed = 0:03:15\n",
      "Model saved after epoch 159\n",
      "\n",
      "Epoch 160: train loss = 0.692157, val loss = 0.220171, time consumed = 0:03:16\n",
      "Model saved after epoch 160\n",
      "\n",
      "Epoch 161: train loss = 0.688284, val loss = 0.220021, time consumed = 0:03:17\n",
      "Model saved after epoch 161\n",
      "\n",
      "Epoch 162: train loss = 0.683616, val loss = 0.219347, time consumed = 0:03:18\n",
      "Model saved after epoch 162\n",
      "\n",
      "Epoch 163: train loss = 0.682401, val loss = 0.218375, time consumed = 0:03:19\n",
      "Model saved after epoch 163\n",
      "\n",
      "Epoch 164: train loss = 0.690510, val loss = 0.218130, time consumed = 0:03:20\n",
      "Model saved after epoch 164\n",
      "\n",
      "Epoch 165: train loss = 0.676519, val loss = 0.216598, time consumed = 0:03:21\n",
      "Model saved after epoch 165\n",
      "\n",
      "Epoch 166: train loss = 0.685275, val loss = 0.215459, time consumed = 0:03:23\n",
      "Model saved after epoch 166\n",
      "\n",
      "Epoch 167: train loss = 0.678781, val loss = 0.215344, time consumed = 0:03:24\n",
      "Model saved after epoch 167\n",
      "\n",
      "Epoch 168: train loss = 0.687332, val loss = 0.215542, time consumed = 0:03:25\n",
      "Epoch 169: train loss = 0.682291, val loss = 0.214106, time consumed = 0:03:26\n",
      "Model saved after epoch 169\n",
      "\n",
      "Epoch 170: train loss = 0.674582, val loss = 0.214006, time consumed = 0:03:27\n",
      "Model saved after epoch 170\n",
      "\n",
      "Epoch 171: train loss = 0.673619, val loss = 0.212939, time consumed = 0:03:28\n",
      "Model saved after epoch 171\n",
      "\n",
      "Epoch 172: train loss = 0.680230, val loss = 0.211803, time consumed = 0:03:30\n",
      "Model saved after epoch 172\n",
      "\n",
      "Epoch 173: train loss = 0.680276, val loss = 0.211928, time consumed = 0:03:31\n",
      "Epoch 174: train loss = 0.666441, val loss = 0.212056, time consumed = 0:03:32\n",
      "Epoch 175: train loss = 0.671108, val loss = 0.210462, time consumed = 0:03:33\n",
      "Model saved after epoch 175\n",
      "\n",
      "Epoch 176: train loss = 0.673134, val loss = 0.209792, time consumed = 0:03:34\n",
      "Model saved after epoch 176\n",
      "\n",
      "Epoch 177: train loss = 0.667029, val loss = 0.209578, time consumed = 0:03:35\n",
      "Model saved after epoch 177\n",
      "\n",
      "Epoch 178: train loss = 0.669570, val loss = 0.208759, time consumed = 0:03:36\n",
      "Model saved after epoch 178\n",
      "\n",
      "Epoch 179: train loss = 0.661699, val loss = 0.207814, time consumed = 0:03:38\n",
      "Model saved after epoch 179\n",
      "\n",
      "Epoch 180: train loss = 0.662029, val loss = 0.207419, time consumed = 0:03:39\n",
      "Model saved after epoch 180\n",
      "\n",
      "Epoch 181: train loss = 0.669391, val loss = 0.207737, time consumed = 0:03:40\n",
      "Epoch 182: train loss = 0.665575, val loss = 0.207637, time consumed = 0:03:41\n",
      "Epoch 183: train loss = 0.666260, val loss = 0.206674, time consumed = 0:03:42\n",
      "Model saved after epoch 183\n",
      "\n",
      "Epoch 184: train loss = 0.661337, val loss = 0.207103, time consumed = 0:03:43\n",
      "Epoch 185: train loss = 0.664418, val loss = 0.204356, time consumed = 0:03:45\n",
      "Model saved after epoch 185\n",
      "\n",
      "Epoch 186: train loss = 0.660411, val loss = 0.204030, time consumed = 0:03:46\n",
      "Model saved after epoch 186\n",
      "\n",
      "Epoch 187: train loss = 0.659684, val loss = 0.203747, time consumed = 0:03:47\n",
      "Model saved after epoch 187\n",
      "\n",
      "Epoch 188: train loss = 0.661523, val loss = 0.203719, time consumed = 0:03:48\n",
      "Model saved after epoch 188\n",
      "\n",
      "Epoch 189: train loss = 0.659592, val loss = 0.203449, time consumed = 0:03:49\n",
      "Model saved after epoch 189\n",
      "\n",
      "Epoch 190: train loss = 0.655695, val loss = 0.202732, time consumed = 0:03:51\n",
      "Model saved after epoch 190\n",
      "\n",
      "Epoch 191: train loss = 0.654687, val loss = 0.200980, time consumed = 0:03:52\n",
      "Model saved after epoch 191\n",
      "\n",
      "Epoch 192: train loss = 0.656122, val loss = 0.201309, time consumed = 0:03:53\n",
      "Epoch 193: train loss = 0.659873, val loss = 0.199764, time consumed = 0:03:54\n",
      "Model saved after epoch 193\n",
      "\n",
      "Epoch 194: train loss = 0.647608, val loss = 0.200499, time consumed = 0:03:55\n",
      "Epoch 195: train loss = 0.650079, val loss = 0.198045, time consumed = 0:03:56\n",
      "Model saved after epoch 195\n",
      "\n",
      "Epoch 196: train loss = 0.644259, val loss = 0.197590, time consumed = 0:03:58\n",
      "Model saved after epoch 196\n",
      "\n",
      "Epoch 197: train loss = 0.650429, val loss = 0.197760, time consumed = 0:03:59\n",
      "Epoch 198: train loss = 0.651012, val loss = 0.197525, time consumed = 0:04:00\n",
      "Model saved after epoch 198\n",
      "\n",
      "Epoch 199: train loss = 0.648185, val loss = 0.197553, time consumed = 0:04:01\n",
      "Epoch 200: train loss = 0.643579, val loss = 0.195542, time consumed = 0:04:02\n",
      "Model saved after epoch 200\n",
      "\n",
      "Epoch 201: train loss = 0.651825, val loss = 0.195936, time consumed = 0:04:03\n",
      "Epoch 202: train loss = 0.641661, val loss = 0.195507, time consumed = 0:04:05\n",
      "Model saved after epoch 202\n",
      "\n",
      "Epoch 203: train loss = 0.645576, val loss = 0.194914, time consumed = 0:04:06\n",
      "Model saved after epoch 203\n",
      "\n",
      "Epoch 204: train loss = 0.651882, val loss = 0.195850, time consumed = 0:04:07\n",
      "Epoch 205: train loss = 0.641082, val loss = 0.193708, time consumed = 0:04:08\n",
      "Model saved after epoch 205\n",
      "\n",
      "Epoch 206: train loss = 0.647953, val loss = 0.193715, time consumed = 0:04:09\n",
      "Epoch 207: train loss = 0.639875, val loss = 0.193545, time consumed = 0:04:10\n",
      "Model saved after epoch 207\n",
      "\n",
      "Epoch 208: train loss = 0.641205, val loss = 0.193015, time consumed = 0:04:11\n",
      "Model saved after epoch 208\n",
      "\n",
      "Epoch 209: train loss = 0.635082, val loss = 0.193243, time consumed = 0:04:13\n",
      "Epoch 210: train loss = 0.644843, val loss = 0.192043, time consumed = 0:04:14\n",
      "Model saved after epoch 210\n",
      "\n",
      "Epoch 211: train loss = 0.635331, val loss = 0.191349, time consumed = 0:04:15\n",
      "Model saved after epoch 211\n",
      "\n",
      "Epoch 212: train loss = 0.633821, val loss = 0.190093, time consumed = 0:04:16\n",
      "Model saved after epoch 212\n",
      "\n",
      "Epoch 213: train loss = 0.635746, val loss = 0.190146, time consumed = 0:04:17\n",
      "Epoch 214: train loss = 0.635173, val loss = 0.189625, time consumed = 0:04:18\n",
      "Model saved after epoch 214\n",
      "\n",
      "Epoch 215: train loss = 0.628764, val loss = 0.188704, time consumed = 0:04:19\n",
      "Model saved after epoch 215\n",
      "\n",
      "Epoch 216: train loss = 0.633671, val loss = 0.188173, time consumed = 0:04:21\n",
      "Model saved after epoch 216\n",
      "\n",
      "Epoch 217: train loss = 0.635236, val loss = 0.187867, time consumed = 0:04:22\n",
      "Model saved after epoch 217\n",
      "\n",
      "Epoch 218: train loss = 0.628539, val loss = 0.186946, time consumed = 0:04:23\n",
      "Model saved after epoch 218\n",
      "\n",
      "Epoch 219: train loss = 0.632483, val loss = 0.186781, time consumed = 0:04:24\n",
      "Model saved after epoch 219\n",
      "\n",
      "Epoch 220: train loss = 0.628403, val loss = 0.187593, time consumed = 0:04:25\n",
      "Epoch 221: train loss = 0.622066, val loss = 0.186432, time consumed = 0:04:26\n",
      "Model saved after epoch 221\n",
      "\n",
      "Epoch 222: train loss = 0.627548, val loss = 0.185450, time consumed = 0:04:27\n",
      "Model saved after epoch 222\n",
      "\n",
      "Epoch 223: train loss = 0.626958, val loss = 0.185128, time consumed = 0:04:29\n",
      "Model saved after epoch 223\n",
      "\n",
      "Epoch 224: train loss = 0.625021, val loss = 0.185910, time consumed = 0:04:30\n",
      "Epoch 225: train loss = 0.621252, val loss = 0.185203, time consumed = 0:04:31\n",
      "Epoch 226: train loss = 0.626435, val loss = 0.184130, time consumed = 0:04:32\n",
      "Model saved after epoch 226\n",
      "\n",
      "Epoch 227: train loss = 0.623487, val loss = 0.183839, time consumed = 0:04:33\n",
      "Model saved after epoch 227\n",
      "\n",
      "Epoch 228: train loss = 0.624646, val loss = 0.183851, time consumed = 0:04:34\n",
      "Epoch 229: train loss = 0.625789, val loss = 0.182937, time consumed = 0:04:36\n",
      "Model saved after epoch 229\n",
      "\n",
      "Epoch 230: train loss = 0.624504, val loss = 0.183368, time consumed = 0:04:37\n",
      "Epoch 231: train loss = 0.625758, val loss = 0.182749, time consumed = 0:04:38\n",
      "Model saved after epoch 231\n",
      "\n",
      "Epoch 232: train loss = 0.614193, val loss = 0.182514, time consumed = 0:04:39\n",
      "Model saved after epoch 232\n",
      "\n",
      "Epoch 233: train loss = 0.613965, val loss = 0.180859, time consumed = 0:04:40\n",
      "Model saved after epoch 233\n",
      "\n",
      "Epoch 234: train loss = 0.628277, val loss = 0.180963, time consumed = 0:04:41\n",
      "Epoch 235: train loss = 0.621992, val loss = 0.180888, time consumed = 0:04:43\n",
      "Epoch 236: train loss = 0.617827, val loss = 0.179725, time consumed = 0:04:44\n",
      "Model saved after epoch 236\n",
      "\n",
      "Epoch 237: train loss = 0.606023, val loss = 0.180138, time consumed = 0:04:45\n",
      "Epoch 238: train loss = 0.607235, val loss = 0.180971, time consumed = 0:04:46\n",
      "Epoch 239: train loss = 0.618460, val loss = 0.179195, time consumed = 0:04:47\n",
      "Model saved after epoch 239\n",
      "\n",
      "Epoch 240: train loss = 0.613004, val loss = 0.180285, time consumed = 0:04:48\n",
      "Epoch 241: train loss = 0.607322, val loss = 0.179290, time consumed = 0:04:50\n",
      "Epoch 242: train loss = 0.611659, val loss = 0.178580, time consumed = 0:04:51\n",
      "Model saved after epoch 242\n",
      "\n",
      "Epoch 243: train loss = 0.614801, val loss = 0.177902, time consumed = 0:04:52\n",
      "Model saved after epoch 243\n",
      "\n",
      "Epoch 244: train loss = 0.610964, val loss = 0.177366, time consumed = 0:04:53\n",
      "Model saved after epoch 244\n",
      "\n",
      "Epoch 245: train loss = 0.614541, val loss = 0.177268, time consumed = 0:04:54\n",
      "Model saved after epoch 245\n",
      "\n",
      "Epoch 246: train loss = 0.614419, val loss = 0.177618, time consumed = 0:04:55\n",
      "Epoch 247: train loss = 0.610389, val loss = 0.178138, time consumed = 0:04:56\n",
      "Epoch 248: train loss = 0.609800, val loss = 0.177263, time consumed = 0:04:58\n",
      "Model saved after epoch 248\n",
      "\n",
      "Epoch 249: train loss = 0.606938, val loss = 0.176172, time consumed = 0:04:59\n",
      "Model saved after epoch 249\n",
      "\n",
      "Epoch 250: train loss = 0.604182, val loss = 0.176736, time consumed = 0:05:00\n",
      "Epoch 251: train loss = 0.611291, val loss = 0.176288, time consumed = 0:05:01\n",
      "Epoch 252: train loss = 0.607782, val loss = 0.174817, time consumed = 0:05:02\n",
      "Model saved after epoch 252\n",
      "\n",
      "Epoch 253: train loss = 0.601059, val loss = 0.174643, time consumed = 0:05:04\n",
      "Model saved after epoch 253\n",
      "\n",
      "Epoch 254: train loss = 0.614227, val loss = 0.174852, time consumed = 0:05:05\n",
      "Epoch 255: train loss = 0.603849, val loss = 0.175059, time consumed = 0:05:06\n",
      "Epoch 256: train loss = 0.606783, val loss = 0.175286, time consumed = 0:05:07\n",
      "Epoch 257: train loss = 0.605291, val loss = 0.173656, time consumed = 0:05:08\n",
      "Model saved after epoch 257\n",
      "\n",
      "Epoch 258: train loss = 0.607301, val loss = 0.174806, time consumed = 0:05:09\n",
      "Epoch 259: train loss = 0.601225, val loss = 0.172573, time consumed = 0:05:10\n",
      "Model saved after epoch 259\n",
      "\n",
      "Epoch 260: train loss = 0.604591, val loss = 0.173157, time consumed = 0:05:12\n",
      "Epoch 261: train loss = 0.603809, val loss = 0.173301, time consumed = 0:05:13\n",
      "Epoch 262: train loss = 0.597948, val loss = 0.172728, time consumed = 0:05:14\n",
      "Epoch 263: train loss = 0.602566, val loss = 0.171615, time consumed = 0:05:15\n",
      "Model saved after epoch 263\n",
      "\n",
      "Epoch 264: train loss = 0.599470, val loss = 0.171761, time consumed = 0:05:16\n",
      "Epoch 265: train loss = 0.594046, val loss = 0.171709, time consumed = 0:05:17\n",
      "Epoch 266: train loss = 0.591586, val loss = 0.171846, time consumed = 0:05:19\n",
      "Epoch 267: train loss = 0.599674, val loss = 0.172472, time consumed = 0:05:20\n",
      "Epoch 268: train loss = 0.595629, val loss = 0.171847, time consumed = 0:05:21\n",
      "Epoch 269: train loss = 0.597046, val loss = 0.171442, time consumed = 0:05:22\n",
      "Model saved after epoch 269\n",
      "\n",
      "Epoch 270: train loss = 0.590432, val loss = 0.170116, time consumed = 0:05:23\n",
      "Model saved after epoch 270\n",
      "\n",
      "Epoch 271: train loss = 0.597378, val loss = 0.169439, time consumed = 0:05:24\n",
      "Model saved after epoch 271\n",
      "\n",
      "Epoch 272: train loss = 0.596819, val loss = 0.170464, time consumed = 0:05:25\n",
      "Epoch 273: train loss = 0.594181, val loss = 0.168776, time consumed = 0:05:27\n",
      "Model saved after epoch 273\n",
      "\n",
      "Epoch 274: train loss = 0.605439, val loss = 0.168359, time consumed = 0:05:28\n",
      "Model saved after epoch 274\n",
      "\n",
      "Epoch 275: train loss = 0.589305, val loss = 0.168121, time consumed = 0:05:29\n",
      "Model saved after epoch 275\n",
      "\n",
      "Epoch 276: train loss = 0.589630, val loss = 0.168338, time consumed = 0:05:30\n",
      "Epoch 277: train loss = 0.594051, val loss = 0.168144, time consumed = 0:05:31\n",
      "Epoch 278: train loss = 0.588895, val loss = 0.168089, time consumed = 0:05:32\n",
      "Model saved after epoch 278\n",
      "\n",
      "Epoch 279: train loss = 0.589165, val loss = 0.168378, time consumed = 0:05:34\n",
      "Epoch 280: train loss = 0.595326, val loss = 0.167424, time consumed = 0:05:35\n",
      "Model saved after epoch 280\n",
      "\n",
      "Epoch 281: train loss = 0.585425, val loss = 0.166984, time consumed = 0:05:36\n",
      "Model saved after epoch 281\n",
      "\n",
      "Epoch 282: train loss = 0.592350, val loss = 0.168262, time consumed = 0:05:37\n",
      "Epoch 283: train loss = 0.590837, val loss = 0.167150, time consumed = 0:05:38\n",
      "Epoch 284: train loss = 0.588637, val loss = 0.166802, time consumed = 0:05:39\n",
      "Model saved after epoch 284\n",
      "\n",
      "Epoch 285: train loss = 0.579431, val loss = 0.165955, time consumed = 0:05:41\n",
      "Model saved after epoch 285\n",
      "\n",
      "Epoch 286: train loss = 0.581124, val loss = 0.165762, time consumed = 0:05:42\n",
      "Model saved after epoch 286\n",
      "\n",
      "Epoch 287: train loss = 0.586189, val loss = 0.164752, time consumed = 0:05:43\n",
      "Model saved after epoch 287\n",
      "\n",
      "Epoch 288: train loss = 0.585606, val loss = 0.164864, time consumed = 0:05:44\n",
      "Epoch 289: train loss = 0.582309, val loss = 0.165197, time consumed = 0:05:45\n",
      "Epoch 290: train loss = 0.582952, val loss = 0.165506, time consumed = 0:05:46\n",
      "Epoch 291: train loss = 0.586956, val loss = 0.165857, time consumed = 0:05:47\n",
      "Epoch 292: train loss = 0.585044, val loss = 0.164954, time consumed = 0:05:49\n",
      "Epoch 293: train loss = 0.586513, val loss = 0.164014, time consumed = 0:05:50\n",
      "Model saved after epoch 293\n",
      "\n",
      "Epoch 294: train loss = 0.579649, val loss = 0.164007, time consumed = 0:05:51\n",
      "Model saved after epoch 294\n",
      "\n",
      "Epoch 295: train loss = 0.577338, val loss = 0.163737, time consumed = 0:05:52\n",
      "Model saved after epoch 295\n",
      "\n",
      "Epoch 296: train loss = 0.578478, val loss = 0.164008, time consumed = 0:05:53\n",
      "Epoch 297: train loss = 0.571848, val loss = 0.163597, time consumed = 0:05:54\n",
      "Model saved after epoch 297\n",
      "\n",
      "Epoch 298: train loss = 0.576416, val loss = 0.162893, time consumed = 0:05:56\n",
      "Model saved after epoch 298\n",
      "\n",
      "Epoch 299: train loss = 0.577695, val loss = 0.162183, time consumed = 0:05:57\n",
      "Model saved after epoch 299\n",
      "\n",
      "Epoch 300: train loss = 0.580653, val loss = 0.163289, time consumed = 0:05:58\n",
      "Epoch 301: train loss = 0.572261, val loss = 0.162080, time consumed = 0:05:59\n",
      "Model saved after epoch 301\n",
      "\n",
      "Epoch 302: train loss = 0.573553, val loss = 0.161770, time consumed = 0:06:00\n",
      "Model saved after epoch 302\n",
      "\n",
      "Epoch 303: train loss = 0.566361, val loss = 0.161177, time consumed = 0:06:01\n",
      "Model saved after epoch 303\n",
      "\n",
      "Epoch 304: train loss = 0.580531, val loss = 0.161261, time consumed = 0:06:03\n",
      "Epoch 305: train loss = 0.573052, val loss = 0.159545, time consumed = 0:06:04\n",
      "Model saved after epoch 305\n",
      "\n",
      "Epoch 306: train loss = 0.573489, val loss = 0.159833, time consumed = 0:06:05\n",
      "Epoch 307: train loss = 0.573523, val loss = 0.161423, time consumed = 0:06:06\n",
      "Epoch 308: train loss = 0.575158, val loss = 0.161565, time consumed = 0:06:07\n",
      "Epoch 309: train loss = 0.561391, val loss = 0.160181, time consumed = 0:06:08\n",
      "Epoch 310: train loss = 0.573830, val loss = 0.161888, time consumed = 0:06:10\n",
      "Epoch 311: train loss = 0.576864, val loss = 0.161003, time consumed = 0:06:11\n",
      "Learning rate reduced after epoch 311\n",
      "\n",
      "Epoch 312: train loss = 0.571948, val loss = 0.160372, time consumed = 0:06:12\n",
      "Epoch 313: train loss = 0.568764, val loss = 0.160086, time consumed = 0:06:13\n",
      "Epoch 314: train loss = 0.568964, val loss = 0.159999, time consumed = 0:06:14\n",
      "Epoch 315: train loss = 0.562275, val loss = 0.159796, time consumed = 0:06:15\n",
      "Epoch 316: train loss = 0.564129, val loss = 0.159642, time consumed = 0:06:16\n",
      "Epoch 317: train loss = 0.574188, val loss = 0.159579, time consumed = 0:06:18\n",
      "Learning rate reduced after epoch 317\n",
      "\n",
      "Epoch 318: train loss = 0.574330, val loss = 0.159554, time consumed = 0:06:19\n",
      "Epoch 319: train loss = 0.573199, val loss = 0.159456, time consumed = 0:06:20\n",
      "Model saved after epoch 319\n",
      "\n",
      "Epoch 320: train loss = 0.562843, val loss = 0.159413, time consumed = 0:06:21\n",
      "Model saved after epoch 320\n",
      "\n",
      "Epoch 321: train loss = 0.570413, val loss = 0.159440, time consumed = 0:06:22\n",
      "Epoch 322: train loss = 0.571807, val loss = 0.159459, time consumed = 0:06:23\n",
      "Epoch 323: train loss = 0.570518, val loss = 0.159482, time consumed = 0:06:24\n",
      "Epoch 324: train loss = 0.572251, val loss = 0.159628, time consumed = 0:06:26\n",
      "Epoch 325: train loss = 0.569602, val loss = 0.159594, time consumed = 0:06:27\n",
      "Epoch 326: train loss = 0.569030, val loss = 0.159516, time consumed = 0:06:28\n",
      "Learning rate reduced after epoch 326\n",
      "\n",
      "Epoch 327: train loss = 0.567381, val loss = 0.159499, time consumed = 0:06:29\n",
      "Epoch 328: train loss = 0.571748, val loss = 0.159471, time consumed = 0:06:30\n",
      "Epoch 329: train loss = 0.564102, val loss = 0.159494, time consumed = 0:06:31\n",
      "Epoch 330: train loss = 0.574329, val loss = 0.159456, time consumed = 0:06:33\n",
      "Epoch 331: train loss = 0.569880, val loss = 0.159598, time consumed = 0:06:34\n",
      "Epoch 332: train loss = 0.572823, val loss = 0.159509, time consumed = 0:06:35\n",
      "Learning rate reduced after epoch 332\n",
      "\n",
      "Epoch 333: train loss = 0.573437, val loss = 0.159535, time consumed = 0:06:36\n",
      "Epoch 334: train loss = 0.563675, val loss = 0.159522, time consumed = 0:06:37\n",
      "Epoch 335: train loss = 0.566312, val loss = 0.159502, time consumed = 0:06:38\n",
      "Epoch 336: train loss = 0.571121, val loss = 0.159513, time consumed = 0:06:40\n",
      "Epoch 337: train loss = 0.569289, val loss = 0.159478, time consumed = 0:06:41\n",
      "Epoch 338: train loss = 0.568652, val loss = 0.159463, time consumed = 0:06:42\n",
      "Learning rate reduced after epoch 338\n",
      "\n",
      "Epoch 339: train loss = 0.566923, val loss = 0.159478, time consumed = 0:06:43\n",
      "Epoch 340: train loss = 0.562303, val loss = 0.159512, time consumed = 0:06:44\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "histories, saved_path = train(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    ann_model, # specify which model to train\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    early_stopping_patience,\n",
    "    lr_scheduler,\n",
    "    saved_path_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dde1f3-feb0-447a-b44b-ab359331717f",
   "metadata": {},
   "source": [
    "We can see the training process took more than 5 minutes on my laptop.\n",
    "\n",
    "It will take about 30 minutes on Google Colab.\n",
    "\n",
    "It's much longer than the previous exercises we did.\n",
    "\n",
    "One reason is that the data set is already big (70,000 samples).\n",
    "\n",
    "Another reason is that the ANN is already complex.\n",
    "\n",
    "We can calculate the number of learning parameters of the model to check the complexity of the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab6818e-2265-4478-9ece-ceb9abb2a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learning parameters: 110362\n"
     ]
    }
   ],
   "source": [
    "# get the number of learning parameters\n",
    "num_learning_params = sum(p.numel() for p in ann_model.parameters() if p.requires_grad)\n",
    "print(f\"Number of learning parameters: {num_learning_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b6fabf-1e0e-4824-af38-3e8de7ad68e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train vs. val loss history\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(histories['train_epoch'])), histories['train_epoch'], '-', label = 'train loss')\n",
    "plt.plot(np.arange(len(histories['val_epoch'])), histories['val_epoch'], '-', label = 'val loss')\n",
    "plt.title('train vs. validation loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db25b2-7f2e-4eed-94cb-1e3d3a153c0c",
   "metadata": {},
   "source": [
    "By visualizing the changes in the training loss and the validation loss during the training process, we can see that both losses are successfully reduced.\n",
    "\n",
    "Since the training process was stopped when the validation loss stopped improving, we prevent the model from over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d41cef-ff05-4403-b74f-144c10b5714e",
   "metadata": {},
   "source": [
    "### Step 4. Reload the best model\n",
    "\n",
    "The final model after training may not be the best one saved during the training process.\n",
    "\n",
    "To use the best model, we need to reload it from the saved file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47628668-df37-49c7-9329-c7fdb22c5617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANNImageClassifier(\n",
       "  (net): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (13): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "ann_model = ANNImageClassifier(\n",
    "    n_features = 784,\n",
    "    n_labels = 10\n",
    ")\n",
    "ann_model.load_state_dict(torch.load(saved_path))\n",
    "ann_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b43e86-1cc3-4317-96ea-b9d545a94015",
   "metadata": {},
   "source": [
    "### Step 5. Evaluation using test set\n",
    "\n",
    "In this step, we define a `test()` function to use the trained network to make predictions on the test set.\n",
    "\n",
    "Then the predictions are used to calculate evaluation metrics for assessing the generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04c81d1-43e3-471d-a184-a461cba35c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to make predictions on test dataset and evaluate the performance\n",
    "def test(dataloader, model, loss_fn):\n",
    "    batch_logits_list = []\n",
    "    batch_prob_list = []\n",
    "    batch_pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0.0\n",
    "        for (X, y) in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            batch_logits = model(X)\n",
    "            batch_loss = loss_fn(batch_logits, y)\n",
    "            loss += batch_loss.item()\n",
    "            batch_prob = torch.softmax(batch_logits, dim = -1)\n",
    "            _, batch_pred = torch.max(batch_logits, 1)\n",
    "            batch_logits_list.append(batch_logits.cpu().numpy())\n",
    "            batch_prob_list.append(batch_prob.cpu().numpy())\n",
    "            batch_pred_list.append(batch_pred.cpu().numpy())\n",
    "        loss /= len(dataloader)\n",
    "        logits = np.concatenate(batch_logits_list)\n",
    "        prob = np.concatenate(batch_prob_list)\n",
    "        pred = np.concatenate(batch_pred_list)\n",
    "        print(f\"test loss = {loss}\")\n",
    "    return logits, prob, pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e272baa6-53a7-4f27-a78e-af43f26614c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss = 0.12772896885871887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.97      0.96      0.96      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.97      0.96      0.97       982\n",
      "           5       0.96      0.96      0.96       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.96      0.95      0.96      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.95      0.95      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make prediction on test set and evaluate the performance\n",
    "test_logits, test_prob, test_pred, test_loss = test(test_dl, ann_model, loss_fn)\n",
    "\n",
    "# obtain test labels\n",
    "test_label = []\n",
    "for (_, y) in test_dl:\n",
    "    test_label.extend(y.cpu().numpy())\n",
    "\n",
    "# calculate classification report\n",
    "print(classification_report(test_label, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7016cf4a-13d7-4add-816c-5fd47a7e27e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recognized digit is: 7\n",
      "The predicted probability is: 0.992025\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display an example\n",
    "plt.imshow(test_ds[0][0].numpy().reshape(28, 28), cmap = 'gray')\n",
    "print('The recognized digit is:', test_pred[0])\n",
    "print('The predicted probability is:', test_prob[0, test_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca019d8-393b-407d-b670-7ffb88ebbf3e",
   "metadata": {},
   "source": [
    "From the evaluation results, we can see that the performance of the ANN-based image classifier is very good.\n",
    "\n",
    "The F1-scores of all digits are close to 1.\n",
    "\n",
    "For the displayed example, the predicted probability is also close to 1.\n",
    "\n",
    "However, the ANN is already complex (110,362 learning parameters) and the training process is already time-consuming.\n",
    "\n",
    "The digit image has only $28\\times28$ pixels and only one channel.\n",
    "\n",
    "If we want to use ANN to process a 4K resolution image, the number of learning parameters will explode. And the training process will be too time-consuming and infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44840cdb-4fdb-47c0-836c-9b6fe5af2b15",
   "metadata": {},
   "source": [
    "## Part 2. Hand-written Digits Recognition with <span style=\"color:red\">**CNN**</span>\n",
    "\n",
    "Now let's try to build a CNN-based image classifier for the same problem.\n",
    "\n",
    "Let's compare the difference between ANN and CNN in terms of:\n",
    "- The number of learning parameters\n",
    "- Time consumed in the training process\n",
    "- The performance of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f463a81-7b7a-4ab8-a7a9-1dc95ff0883b",
   "metadata": {},
   "source": [
    "### Step 1. Build the data pipeline\n",
    "\n",
    "Let's use the same data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcf94c-6761-44ad-ba12-1e964d618bab",
   "metadata": {},
   "source": [
    "### Step 2. Create an image classifier using <span style=\"color:red\">**CNN**</span>\n",
    "\n",
    "In this step, we will first create a class that inherits from `torch.nn.Module` to determine the network structure, the activation functions, and the forward method. And then initialize the neural network.\n",
    "\n",
    "We will define a multi-layer CNN with 3 convolutional layers and 3 fully connected layers.\n",
    "- Use `nn.Lazy...` to avoid calculating the input size yourself:\n",
    "    - Use `nn.LazyConv2d` instead of `nn.Conv2d`\n",
    "    - Use `nn.LazyBatchNorm2d` instead of `nn.BatchNorm2d`\n",
    "    - Use `nn.LazyLinear` instead of `nn.Linear`\n",
    "- Batch normalization layer is positioned before the activation function layer\n",
    "- Pooling layer is positioned after the activation function layer\n",
    "- Use `nn.Flatten` to flatten the 2D feature map into 1D feature vector\n",
    "- Dropout layer is positioned after the activation function layer and only for fully connected layers\n",
    "    - You can also add `nn.Dropout2d` between convolutional layers, which will randomly drop out the entire channel of the input feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91ad6055-f3aa-4a0a-afee-7ab12e19c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom neural network class\n",
    "class CNNImageClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, n_labels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(out_channels = 3, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(), nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.LazyConv2d(out_channels = 9, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(), nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.LazyConv2d(out_channels = 27, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(), nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(100), nn.LazyBatchNorm1d(), nn.ReLU(), nn.Dropout(p = 0.5),\n",
    "            nn.LazyLinear(10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77b04a14-eb97-470d-8710-369d9136c2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNImageClassifier(\n",
       "  (net): Sequential(\n",
       "    (0): LazyConv2d(0, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): LazyConv2d(0, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): LazyConv2d(0, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): LazyLinear(in_features=0, out_features=100, bias=True)\n",
       "    (14): LazyBatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): Dropout(p=0.5, inplace=False)\n",
       "    (17): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the neural network\n",
    "cnn_model = CNNImageClassifier(\n",
    "    in_channels = train_ds[0][0].shape[0],\n",
    "    n_labels = 10\n",
    ")\n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fa808-b1c0-45e2-b071-60fa1397765b",
   "metadata": {},
   "source": [
    "### Step 3. Train the network\n",
    "\n",
    "We will use the same `train()` function and the same training hyper-parameters for comparison.\n",
    "\n",
    "Since we are going to train a different model, we need to create another optimizer for the cnn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d770c83d-4749-439f-bf4b-92965ae9c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new optimizer for cnn\n",
    "optimizer = torch.optim.SGD(\n",
    "    cnn_model.parameters(), # specify which model to optimize\n",
    "    lr = learning_rate,\n",
    "    weight_decay = weight_decay\n",
    ")\n",
    "\n",
    "# create a new LR scheduler for the new optimizer\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode = 'min',\n",
    "    factor = 0.1,\n",
    "    patience = 5\n",
    ")\n",
    "\n",
    "# set another prefix\n",
    "saved_path_prefix = 'cnn_image_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479309d-8682-42cc-bce4-9d80116dd725",
   "metadata": {},
   "source": [
    "We also need to pass the correct network to the `train()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ea8ab68-a17c-437c-9dd5-f39cf047cdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 1.976297, val loss = 2.288629, time consumed = 0:00:04\n",
      "Model saved after epoch 1\n",
      "\n",
      "Epoch 2: train loss = 1.333094, val loss = 2.262380, time consumed = 0:00:06\n",
      "Model saved after epoch 2\n",
      "\n",
      "Epoch 3: train loss = 1.017969, val loss = 2.128242, time consumed = 0:00:07\n",
      "Model saved after epoch 3\n",
      "\n",
      "Epoch 4: train loss = 0.813642, val loss = 1.796007, time consumed = 0:00:09\n",
      "Model saved after epoch 4\n",
      "\n",
      "Epoch 5: train loss = 0.678032, val loss = 1.284070, time consumed = 0:00:11\n",
      "Model saved after epoch 5\n",
      "\n",
      "Epoch 6: train loss = 0.587320, val loss = 0.821578, time consumed = 0:00:12\n",
      "Model saved after epoch 6\n",
      "\n",
      "Epoch 7: train loss = 0.517993, val loss = 0.549031, time consumed = 0:00:14\n",
      "Model saved after epoch 7\n",
      "\n",
      "Epoch 8: train loss = 0.466347, val loss = 0.414805, time consumed = 0:00:16\n",
      "Model saved after epoch 8\n",
      "\n",
      "Epoch 9: train loss = 0.426684, val loss = 0.336657, time consumed = 0:00:17\n",
      "Model saved after epoch 9\n",
      "\n",
      "Epoch 10: train loss = 0.392771, val loss = 0.293671, time consumed = 0:00:19\n",
      "Model saved after epoch 10\n",
      "\n",
      "Epoch 11: train loss = 0.365546, val loss = 0.269547, time consumed = 0:00:21\n",
      "Model saved after epoch 11\n",
      "\n",
      "Epoch 12: train loss = 0.342337, val loss = 0.246955, time consumed = 0:00:22\n",
      "Model saved after epoch 12\n",
      "\n",
      "Epoch 13: train loss = 0.323055, val loss = 0.229570, time consumed = 0:00:24\n",
      "Model saved after epoch 13\n",
      "\n",
      "Epoch 14: train loss = 0.304203, val loss = 0.215731, time consumed = 0:00:26\n",
      "Model saved after epoch 14\n",
      "\n",
      "Epoch 15: train loss = 0.291156, val loss = 0.203054, time consumed = 0:00:27\n",
      "Model saved after epoch 15\n",
      "\n",
      "Epoch 16: train loss = 0.274219, val loss = 0.192418, time consumed = 0:00:29\n",
      "Model saved after epoch 16\n",
      "\n",
      "Epoch 17: train loss = 0.263286, val loss = 0.180866, time consumed = 0:00:31\n",
      "Model saved after epoch 17\n",
      "\n",
      "Epoch 18: train loss = 0.256682, val loss = 0.175596, time consumed = 0:00:32\n",
      "Model saved after epoch 18\n",
      "\n",
      "Epoch 19: train loss = 0.244453, val loss = 0.168799, time consumed = 0:00:34\n",
      "Model saved after epoch 19\n",
      "\n",
      "Epoch 20: train loss = 0.235685, val loss = 0.162203, time consumed = 0:00:36\n",
      "Model saved after epoch 20\n",
      "\n",
      "Epoch 21: train loss = 0.226935, val loss = 0.160080, time consumed = 0:00:37\n",
      "Model saved after epoch 21\n",
      "\n",
      "Epoch 22: train loss = 0.220526, val loss = 0.151343, time consumed = 0:00:39\n",
      "Model saved after epoch 22\n",
      "\n",
      "Epoch 23: train loss = 0.213982, val loss = 0.147809, time consumed = 0:00:40\n",
      "Model saved after epoch 23\n",
      "\n",
      "Epoch 24: train loss = 0.206367, val loss = 0.145246, time consumed = 0:00:42\n",
      "Model saved after epoch 24\n",
      "\n",
      "Epoch 25: train loss = 0.204637, val loss = 0.139529, time consumed = 0:00:44\n",
      "Model saved after epoch 25\n",
      "\n",
      "Epoch 26: train loss = 0.200013, val loss = 0.135965, time consumed = 0:00:45\n",
      "Model saved after epoch 26\n",
      "\n",
      "Epoch 27: train loss = 0.193322, val loss = 0.131166, time consumed = 0:00:47\n",
      "Model saved after epoch 27\n",
      "\n",
      "Epoch 28: train loss = 0.189915, val loss = 0.127186, time consumed = 0:00:49\n",
      "Model saved after epoch 28\n",
      "\n",
      "Epoch 29: train loss = 0.184331, val loss = 0.125805, time consumed = 0:00:50\n",
      "Model saved after epoch 29\n",
      "\n",
      "Epoch 30: train loss = 0.179980, val loss = 0.122816, time consumed = 0:00:52\n",
      "Model saved after epoch 30\n",
      "\n",
      "Epoch 31: train loss = 0.176408, val loss = 0.119824, time consumed = 0:00:54\n",
      "Model saved after epoch 31\n",
      "\n",
      "Epoch 32: train loss = 0.171814, val loss = 0.117783, time consumed = 0:00:55\n",
      "Model saved after epoch 32\n",
      "\n",
      "Epoch 33: train loss = 0.169366, val loss = 0.116705, time consumed = 0:00:57\n",
      "Model saved after epoch 33\n",
      "\n",
      "Epoch 34: train loss = 0.165256, val loss = 0.113596, time consumed = 0:00:59\n",
      "Model saved after epoch 34\n",
      "\n",
      "Epoch 35: train loss = 0.162518, val loss = 0.111936, time consumed = 0:01:00\n",
      "Model saved after epoch 35\n",
      "\n",
      "Epoch 36: train loss = 0.158593, val loss = 0.109886, time consumed = 0:01:02\n",
      "Model saved after epoch 36\n",
      "\n",
      "Epoch 37: train loss = 0.159562, val loss = 0.108254, time consumed = 0:01:04\n",
      "Model saved after epoch 37\n",
      "\n",
      "Epoch 38: train loss = 0.154136, val loss = 0.108667, time consumed = 0:01:05\n",
      "Epoch 39: train loss = 0.150701, val loss = 0.105521, time consumed = 0:01:07\n",
      "Model saved after epoch 39\n",
      "\n",
      "Epoch 40: train loss = 0.148941, val loss = 0.102106, time consumed = 0:01:09\n",
      "Model saved after epoch 40\n",
      "\n",
      "Epoch 41: train loss = 0.148075, val loss = 0.100079, time consumed = 0:01:10\n",
      "Model saved after epoch 41\n",
      "\n",
      "Epoch 42: train loss = 0.144875, val loss = 0.102686, time consumed = 0:01:12\n",
      "Epoch 43: train loss = 0.144605, val loss = 0.101020, time consumed = 0:01:14\n",
      "Epoch 44: train loss = 0.139187, val loss = 0.096927, time consumed = 0:01:15\n",
      "Model saved after epoch 44\n",
      "\n",
      "Epoch 45: train loss = 0.139544, val loss = 0.099700, time consumed = 0:01:17\n",
      "Epoch 46: train loss = 0.136432, val loss = 0.094808, time consumed = 0:01:19\n",
      "Model saved after epoch 46\n",
      "\n",
      "Epoch 47: train loss = 0.137045, val loss = 0.093768, time consumed = 0:01:21\n",
      "Model saved after epoch 47\n",
      "\n",
      "Epoch 48: train loss = 0.130338, val loss = 0.092828, time consumed = 0:01:22\n",
      "Model saved after epoch 48\n",
      "\n",
      "Epoch 49: train loss = 0.130645, val loss = 0.090413, time consumed = 0:01:24\n",
      "Model saved after epoch 49\n",
      "\n",
      "Epoch 50: train loss = 0.129541, val loss = 0.090213, time consumed = 0:01:26\n",
      "Model saved after epoch 50\n",
      "\n",
      "Epoch 51: train loss = 0.131012, val loss = 0.089824, time consumed = 0:01:27\n",
      "Model saved after epoch 51\n",
      "\n",
      "Epoch 52: train loss = 0.126444, val loss = 0.087319, time consumed = 0:01:29\n",
      "Model saved after epoch 52\n",
      "\n",
      "Epoch 53: train loss = 0.124646, val loss = 0.088632, time consumed = 0:01:31\n",
      "Epoch 54: train loss = 0.122388, val loss = 0.087111, time consumed = 0:01:32\n",
      "Model saved after epoch 54\n",
      "\n",
      "Epoch 55: train loss = 0.120464, val loss = 0.084484, time consumed = 0:01:34\n",
      "Model saved after epoch 55\n",
      "\n",
      "Epoch 56: train loss = 0.119702, val loss = 0.084136, time consumed = 0:01:36\n",
      "Model saved after epoch 56\n",
      "\n",
      "Epoch 57: train loss = 0.121888, val loss = 0.082719, time consumed = 0:01:37\n",
      "Model saved after epoch 57\n",
      "\n",
      "Epoch 58: train loss = 0.116877, val loss = 0.084027, time consumed = 0:01:39\n",
      "Epoch 59: train loss = 0.115431, val loss = 0.082485, time consumed = 0:01:41\n",
      "Model saved after epoch 59\n",
      "\n",
      "Epoch 60: train loss = 0.114483, val loss = 0.081000, time consumed = 0:01:42\n",
      "Model saved after epoch 60\n",
      "\n",
      "Epoch 61: train loss = 0.114240, val loss = 0.080552, time consumed = 0:01:44\n",
      "Model saved after epoch 61\n",
      "\n",
      "Epoch 62: train loss = 0.114039, val loss = 0.080302, time consumed = 0:01:46\n",
      "Model saved after epoch 62\n",
      "\n",
      "Epoch 63: train loss = 0.112549, val loss = 0.081301, time consumed = 0:01:47\n",
      "Epoch 64: train loss = 0.111273, val loss = 0.077893, time consumed = 0:01:49\n",
      "Model saved after epoch 64\n",
      "\n",
      "Epoch 65: train loss = 0.111306, val loss = 0.078669, time consumed = 0:01:51\n",
      "Epoch 66: train loss = 0.108615, val loss = 0.076414, time consumed = 0:01:52\n",
      "Model saved after epoch 66\n",
      "\n",
      "Epoch 67: train loss = 0.107967, val loss = 0.075849, time consumed = 0:01:54\n",
      "Model saved after epoch 67\n",
      "\n",
      "Epoch 68: train loss = 0.106711, val loss = 0.076114, time consumed = 0:01:56\n",
      "Epoch 69: train loss = 0.105110, val loss = 0.074950, time consumed = 0:01:57\n",
      "Model saved after epoch 69\n",
      "\n",
      "Epoch 70: train loss = 0.105425, val loss = 0.074448, time consumed = 0:01:59\n",
      "Model saved after epoch 70\n",
      "\n",
      "Epoch 71: train loss = 0.105093, val loss = 0.074653, time consumed = 0:02:01\n",
      "Epoch 72: train loss = 0.103117, val loss = 0.073307, time consumed = 0:02:02\n",
      "Model saved after epoch 72\n",
      "\n",
      "Epoch 73: train loss = 0.101841, val loss = 0.072508, time consumed = 0:02:04\n",
      "Model saved after epoch 73\n",
      "\n",
      "Epoch 74: train loss = 0.101737, val loss = 0.071984, time consumed = 0:02:06\n",
      "Model saved after epoch 74\n",
      "\n",
      "Epoch 75: train loss = 0.101555, val loss = 0.072940, time consumed = 0:02:07\n",
      "Epoch 76: train loss = 0.097602, val loss = 0.071758, time consumed = 0:02:09\n",
      "Model saved after epoch 76\n",
      "\n",
      "Epoch 77: train loss = 0.099306, val loss = 0.070288, time consumed = 0:02:11\n",
      "Model saved after epoch 77\n",
      "\n",
      "Epoch 78: train loss = 0.098696, val loss = 0.070350, time consumed = 0:02:12\n",
      "Epoch 79: train loss = 0.096134, val loss = 0.070076, time consumed = 0:02:14\n",
      "Model saved after epoch 79\n",
      "\n",
      "Epoch 80: train loss = 0.096152, val loss = 0.070688, time consumed = 0:02:16\n",
      "Epoch 81: train loss = 0.097848, val loss = 0.070634, time consumed = 0:02:17\n",
      "Epoch 82: train loss = 0.095136, val loss = 0.069317, time consumed = 0:02:19\n",
      "Model saved after epoch 82\n",
      "\n",
      "Epoch 83: train loss = 0.093672, val loss = 0.068053, time consumed = 0:02:21\n",
      "Model saved after epoch 83\n",
      "\n",
      "Epoch 84: train loss = 0.092335, val loss = 0.068616, time consumed = 0:02:22\n",
      "Epoch 85: train loss = 0.092652, val loss = 0.068099, time consumed = 0:02:24\n",
      "Epoch 86: train loss = 0.091251, val loss = 0.066866, time consumed = 0:02:25\n",
      "Model saved after epoch 86\n",
      "\n",
      "Epoch 87: train loss = 0.090968, val loss = 0.068115, time consumed = 0:02:27\n",
      "Epoch 88: train loss = 0.091246, val loss = 0.066533, time consumed = 0:02:29\n",
      "Model saved after epoch 88\n",
      "\n",
      "Epoch 89: train loss = 0.088165, val loss = 0.066673, time consumed = 0:02:30\n",
      "Epoch 90: train loss = 0.090720, val loss = 0.066128, time consumed = 0:02:32\n",
      "Model saved after epoch 90\n",
      "\n",
      "Epoch 91: train loss = 0.087708, val loss = 0.065252, time consumed = 0:02:34\n",
      "Model saved after epoch 91\n",
      "\n",
      "Epoch 92: train loss = 0.088514, val loss = 0.064236, time consumed = 0:02:35\n",
      "Model saved after epoch 92\n",
      "\n",
      "Epoch 93: train loss = 0.089217, val loss = 0.065394, time consumed = 0:02:37\n",
      "Epoch 94: train loss = 0.088727, val loss = 0.065467, time consumed = 0:02:39\n",
      "Epoch 95: train loss = 0.086575, val loss = 0.064553, time consumed = 0:02:40\n",
      "Epoch 96: train loss = 0.084297, val loss = 0.063928, time consumed = 0:02:42\n",
      "Model saved after epoch 96\n",
      "\n",
      "Epoch 97: train loss = 0.085472, val loss = 0.063057, time consumed = 0:02:44\n",
      "Model saved after epoch 97\n",
      "\n",
      "Epoch 98: train loss = 0.085826, val loss = 0.064006, time consumed = 0:02:45\n",
      "Epoch 99: train loss = 0.084709, val loss = 0.062090, time consumed = 0:02:47\n",
      "Model saved after epoch 99\n",
      "\n",
      "Epoch 100: train loss = 0.084674, val loss = 0.061907, time consumed = 0:02:49\n",
      "Model saved after epoch 100\n",
      "\n",
      "Epoch 101: train loss = 0.083272, val loss = 0.061800, time consumed = 0:02:50\n",
      "Model saved after epoch 101\n",
      "\n",
      "Epoch 102: train loss = 0.083623, val loss = 0.062831, time consumed = 0:02:52\n",
      "Epoch 103: train loss = 0.081179, val loss = 0.062216, time consumed = 0:02:54\n",
      "Epoch 104: train loss = 0.080657, val loss = 0.061458, time consumed = 0:02:55\n",
      "Model saved after epoch 104\n",
      "\n",
      "Epoch 105: train loss = 0.083048, val loss = 0.061359, time consumed = 0:02:57\n",
      "Model saved after epoch 105\n",
      "\n",
      "Epoch 106: train loss = 0.080829, val loss = 0.060427, time consumed = 0:02:59\n",
      "Model saved after epoch 106\n",
      "\n",
      "Epoch 107: train loss = 0.080248, val loss = 0.060318, time consumed = 0:03:00\n",
      "Model saved after epoch 107\n",
      "\n",
      "Epoch 108: train loss = 0.078351, val loss = 0.061031, time consumed = 0:03:02\n",
      "Epoch 109: train loss = 0.078715, val loss = 0.059684, time consumed = 0:03:04\n",
      "Model saved after epoch 109\n",
      "\n",
      "Epoch 110: train loss = 0.078460, val loss = 0.061174, time consumed = 0:03:05\n",
      "Epoch 111: train loss = 0.077454, val loss = 0.059708, time consumed = 0:03:07\n",
      "Epoch 112: train loss = 0.076622, val loss = 0.060192, time consumed = 0:03:09\n",
      "Epoch 113: train loss = 0.077235, val loss = 0.059541, time consumed = 0:03:10\n",
      "Model saved after epoch 113\n",
      "\n",
      "Epoch 114: train loss = 0.078292, val loss = 0.058547, time consumed = 0:03:12\n",
      "Model saved after epoch 114\n",
      "\n",
      "Epoch 115: train loss = 0.075997, val loss = 0.061397, time consumed = 0:03:14\n",
      "Epoch 116: train loss = 0.077040, val loss = 0.058443, time consumed = 0:03:15\n",
      "Model saved after epoch 116\n",
      "\n",
      "Epoch 117: train loss = 0.076263, val loss = 0.059478, time consumed = 0:03:17\n",
      "Epoch 118: train loss = 0.074973, val loss = 0.057977, time consumed = 0:03:18\n",
      "Model saved after epoch 118\n",
      "\n",
      "Epoch 119: train loss = 0.074199, val loss = 0.059412, time consumed = 0:03:20\n",
      "Epoch 120: train loss = 0.076142, val loss = 0.057464, time consumed = 0:03:22\n",
      "Model saved after epoch 120\n",
      "\n",
      "Epoch 121: train loss = 0.073194, val loss = 0.057568, time consumed = 0:03:23\n",
      "Epoch 122: train loss = 0.074099, val loss = 0.059775, time consumed = 0:03:25\n",
      "Epoch 123: train loss = 0.071723, val loss = 0.056845, time consumed = 0:03:27\n",
      "Model saved after epoch 123\n",
      "\n",
      "Epoch 124: train loss = 0.071721, val loss = 0.056919, time consumed = 0:03:28\n",
      "Epoch 125: train loss = 0.071333, val loss = 0.056684, time consumed = 0:03:30\n",
      "Model saved after epoch 125\n",
      "\n",
      "Epoch 126: train loss = 0.072514, val loss = 0.056360, time consumed = 0:03:32\n",
      "Model saved after epoch 126\n",
      "\n",
      "Epoch 127: train loss = 0.070653, val loss = 0.056726, time consumed = 0:03:33\n",
      "Epoch 128: train loss = 0.071222, val loss = 0.056332, time consumed = 0:03:35\n",
      "Model saved after epoch 128\n",
      "\n",
      "Epoch 129: train loss = 0.068603, val loss = 0.056412, time consumed = 0:03:37\n",
      "Epoch 130: train loss = 0.069521, val loss = 0.057505, time consumed = 0:03:38\n",
      "Epoch 131: train loss = 0.069811, val loss = 0.056724, time consumed = 0:03:40\n",
      "Epoch 132: train loss = 0.069736, val loss = 0.055326, time consumed = 0:03:42\n",
      "Model saved after epoch 132\n",
      "\n",
      "Epoch 133: train loss = 0.069823, val loss = 0.056099, time consumed = 0:03:43\n",
      "Epoch 134: train loss = 0.070447, val loss = 0.056155, time consumed = 0:03:45\n",
      "Epoch 135: train loss = 0.069400, val loss = 0.055212, time consumed = 0:03:47\n",
      "Model saved after epoch 135\n",
      "\n",
      "Epoch 136: train loss = 0.068985, val loss = 0.055369, time consumed = 0:03:48\n",
      "Epoch 137: train loss = 0.067732, val loss = 0.057103, time consumed = 0:03:50\n",
      "Epoch 138: train loss = 0.068345, val loss = 0.054607, time consumed = 0:03:52\n",
      "Model saved after epoch 138\n",
      "\n",
      "Epoch 139: train loss = 0.066993, val loss = 0.055577, time consumed = 0:03:53\n",
      "Epoch 140: train loss = 0.068840, val loss = 0.055395, time consumed = 0:03:55\n",
      "Epoch 141: train loss = 0.067851, val loss = 0.055472, time consumed = 0:03:57\n",
      "Epoch 142: train loss = 0.066606, val loss = 0.055684, time consumed = 0:03:58\n",
      "Epoch 143: train loss = 0.065943, val loss = 0.054991, time consumed = 0:04:00\n",
      "Epoch 144: train loss = 0.065500, val loss = 0.054564, time consumed = 0:04:02\n",
      "Model saved after epoch 144\n",
      "\n",
      "Epoch 145: train loss = 0.066604, val loss = 0.054256, time consumed = 0:04:03\n",
      "Model saved after epoch 145\n",
      "\n",
      "Epoch 146: train loss = 0.063561, val loss = 0.054442, time consumed = 0:04:05\n",
      "Epoch 147: train loss = 0.067493, val loss = 0.054893, time consumed = 0:04:07\n",
      "Epoch 148: train loss = 0.065145, val loss = 0.053686, time consumed = 0:04:08\n",
      "Model saved after epoch 148\n",
      "\n",
      "Epoch 149: train loss = 0.065969, val loss = 0.054357, time consumed = 0:04:10\n",
      "Epoch 150: train loss = 0.064588, val loss = 0.053186, time consumed = 0:04:12\n",
      "Model saved after epoch 150\n",
      "\n",
      "Epoch 151: train loss = 0.064486, val loss = 0.053333, time consumed = 0:04:13\n",
      "Epoch 152: train loss = 0.064013, val loss = 0.053433, time consumed = 0:04:15\n",
      "Epoch 153: train loss = 0.065557, val loss = 0.053624, time consumed = 0:04:17\n",
      "Epoch 154: train loss = 0.064932, val loss = 0.053515, time consumed = 0:04:18\n",
      "Epoch 155: train loss = 0.063268, val loss = 0.053430, time consumed = 0:04:20\n",
      "Epoch 156: train loss = 0.063555, val loss = 0.053234, time consumed = 0:04:22\n",
      "Learning rate reduced after epoch 156\n",
      "\n",
      "Epoch 157: train loss = 0.062020, val loss = 0.052415, time consumed = 0:04:23\n",
      "Model saved after epoch 157\n",
      "\n",
      "Epoch 158: train loss = 0.061720, val loss = 0.052336, time consumed = 0:04:25\n",
      "Model saved after epoch 158\n",
      "\n",
      "Epoch 159: train loss = 0.062114, val loss = 0.052335, time consumed = 0:04:27\n",
      "Model saved after epoch 159\n",
      "\n",
      "Epoch 160: train loss = 0.062368, val loss = 0.052272, time consumed = 0:04:28\n",
      "Model saved after epoch 160\n",
      "\n",
      "Epoch 161: train loss = 0.063067, val loss = 0.052188, time consumed = 0:04:30\n",
      "Model saved after epoch 161\n",
      "\n",
      "Epoch 162: train loss = 0.061466, val loss = 0.052277, time consumed = 0:04:32\n",
      "Epoch 163: train loss = 0.062689, val loss = 0.052164, time consumed = 0:04:33\n",
      "Model saved after epoch 163\n",
      "\n",
      "Epoch 164: train loss = 0.061779, val loss = 0.052154, time consumed = 0:04:35\n",
      "Model saved after epoch 164\n",
      "\n",
      "Epoch 165: train loss = 0.060384, val loss = 0.052176, time consumed = 0:04:36\n",
      "Epoch 166: train loss = 0.061378, val loss = 0.052164, time consumed = 0:04:38\n",
      "Epoch 167: train loss = 0.062702, val loss = 0.052118, time consumed = 0:04:40\n",
      "Model saved after epoch 167\n",
      "\n",
      "Epoch 168: train loss = 0.060378, val loss = 0.052198, time consumed = 0:04:41\n",
      "Epoch 169: train loss = 0.062223, val loss = 0.052179, time consumed = 0:04:43\n",
      "Epoch 170: train loss = 0.061632, val loss = 0.052291, time consumed = 0:04:45\n",
      "Epoch 171: train loss = 0.063033, val loss = 0.052114, time consumed = 0:04:47\n",
      "Model saved after epoch 171\n",
      "\n",
      "Epoch 172: train loss = 0.063010, val loss = 0.052153, time consumed = 0:04:48\n",
      "Epoch 173: train loss = 0.062048, val loss = 0.052198, time consumed = 0:04:50\n",
      "Learning rate reduced after epoch 173\n",
      "\n",
      "Epoch 174: train loss = 0.062527, val loss = 0.052170, time consumed = 0:04:52\n",
      "Epoch 175: train loss = 0.062232, val loss = 0.052156, time consumed = 0:04:53\n",
      "Epoch 176: train loss = 0.062583, val loss = 0.052142, time consumed = 0:04:55\n",
      "Epoch 177: train loss = 0.062574, val loss = 0.052157, time consumed = 0:04:56\n",
      "Epoch 178: train loss = 0.060954, val loss = 0.052160, time consumed = 0:04:58\n",
      "Epoch 179: train loss = 0.061644, val loss = 0.052156, time consumed = 0:05:00\n",
      "Learning rate reduced after epoch 179\n",
      "\n",
      "Epoch 180: train loss = 0.061299, val loss = 0.052142, time consumed = 0:05:01\n",
      "Epoch 181: train loss = 0.061272, val loss = 0.052145, time consumed = 0:05:03\n",
      "Epoch 182: train loss = 0.062703, val loss = 0.052141, time consumed = 0:05:05\n",
      "Epoch 183: train loss = 0.061212, val loss = 0.052143, time consumed = 0:05:06\n",
      "Epoch 184: train loss = 0.063150, val loss = 0.052148, time consumed = 0:05:08\n",
      "Epoch 185: train loss = 0.061829, val loss = 0.052143, time consumed = 0:05:10\n",
      "Learning rate reduced after epoch 185\n",
      "\n",
      "Epoch 186: train loss = 0.062486, val loss = 0.052136, time consumed = 0:05:11\n",
      "Epoch 187: train loss = 0.062477, val loss = 0.052137, time consumed = 0:05:13\n",
      "Epoch 188: train loss = 0.061983, val loss = 0.052131, time consumed = 0:05:15\n",
      "Epoch 189: train loss = 0.061909, val loss = 0.052138, time consumed = 0:05:16\n",
      "Epoch 190: train loss = 0.061881, val loss = 0.052145, time consumed = 0:05:18\n",
      "Epoch 191: train loss = 0.062351, val loss = 0.052152, time consumed = 0:05:19\n",
      "Learning rate reduced after epoch 191\n",
      "\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "histories, saved_path = train(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    cnn_model, # specify which model to train\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    early_stopping_patience,\n",
    "    lr_scheduler,\n",
    "    saved_path_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914fffe-fdd1-4ee5-b9db-b7b035008afb",
   "metadata": {},
   "source": [
    "We can see that we achieve a much lower validation loss with fewer epochs.\n",
    "\n",
    "We can also calculate the number of learning parameters of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9fae8e1-ff01-40e0-81e3-bd173fa2b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learning parameters: 28184\n"
     ]
    }
   ],
   "source": [
    "# get the number of learning parameters\n",
    "num_learning_params = sum(p.numel() for p in cnn_model.parameters() if p.requires_grad)\n",
    "print(f\"Number of learning parameters: {num_learning_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af8787-02c4-4a9b-be3c-58e4376900b3",
   "metadata": {},
   "source": [
    "We can see that the CNN has fewer learning parameters than the previous ANN (110,362 learning parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6518abc-e064-43bf-9e9b-476746e2a7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train vs. val loss history\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(histories['train_epoch'])), histories['train_epoch'], '-', label = 'train loss')\n",
    "plt.plot(np.arange(len(histories['val_epoch'])), histories['val_epoch'], '-', label = 'val loss')\n",
    "plt.title('train vs. validation loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7610f67-545c-47d4-938b-6e9411fe8546",
   "metadata": {},
   "source": [
    "### Step 4. Reload the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a93c46-0ef4-47db-bd42-c776f14aea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNImageClassifier(\n",
       "  (net): Sequential(\n",
       "    (0): LazyConv2d(0, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): LazyConv2d(0, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): LazyConv2d(0, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): LazyLinear(in_features=0, out_features=100, bias=True)\n",
       "    (14): LazyBatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): Dropout(p=0.5, inplace=False)\n",
       "    (17): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload model\n",
    "cnn_model = CNNImageClassifier(\n",
    "    in_channels = train_ds[0][0].shape[0],\n",
    "    n_labels = 10\n",
    ")\n",
    "cnn_model.load_state_dict(torch.load(saved_path))\n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041011ca-c95f-4aff-9baa-f80ebbfdddcf",
   "metadata": {},
   "source": [
    "### Step 5. Evaluation using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4a00a38-75dc-4928-91d5-6967a3598afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss = 0.03934888541698456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.98      0.99       982\n",
      "           5       0.98      0.99      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.98      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make prediction on test set and evaluate the performance\n",
    "test_logits, test_prob, test_pred, test_loss = test(test_dl, cnn_model, loss_fn)\n",
    "\n",
    "# calculate classification report\n",
    "print(classification_report(test_label, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f112806-92e4-47f5-bcb3-5f723ca3268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recognized digit is: 7\n",
      "The predicted probability is: 0.9997688\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display an example\n",
    "plt.imshow(test_ds[0][0].numpy().reshape(28, 28), cmap = 'gray')\n",
    "print('The recognized digit is:', test_pred[0])\n",
    "print('The predicted probability is:', test_prob[0, test_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91537236-125d-476f-b086-b17fc67f54cb",
   "metadata": {},
   "source": [
    "By comparing the evaluation results of CNN with the ones of ANN, we can find that CNN used fewer learning parameters and fewer training epochs but achieved a better performance.\n",
    "\n",
    "That's why we typically use CNN instead of ANN for image processing.\n",
    "\n",
    "The CNN architecture is designed to mimic human vision, thus more suitable for data modalities such as images and videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
